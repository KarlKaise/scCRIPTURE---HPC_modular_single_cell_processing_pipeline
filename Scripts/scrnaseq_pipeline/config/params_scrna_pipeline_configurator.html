<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>scRNA-seq Pipeline Configurator</title>
<style>
/* ============================================================
   CSS CUSTOM PROPERTIES & RESET
   ============================================================ */
:root {
  --bg-primary: #0f1117;
  --bg-secondary: #171923;
  --bg-tertiary: #1e2030;
  --bg-card: #232538;
  --bg-input: #1a1c2e;
  --bg-hover: #2a2d45;
  --border-primary: #2d3055;
  --border-accent: #4a6cf7;
  --border-success: #34d399;
  --border-warning: #fbbf24;
  --border-danger: #f87171;
  --text-primary: #e2e4f0;
  --text-secondary: #9ca3c0;
  --text-muted: #6b7199;
  --text-accent: #7b93fa;
  --accent-primary: #4a6cf7;
  --accent-hover: #5c7bfa;
  --accent-glow: rgba(74, 108, 247, 0.15);
  --success: #34d399;
  --success-bg: rgba(52, 211, 153, 0.08);
  --warning: #fbbf24;
  --warning-bg: rgba(251, 191, 36, 0.08);
  --danger: #f87171;
  --danger-bg: rgba(248, 113, 113, 0.08);
  --info: #60a5fa;
  --info-bg: rgba(96, 165, 250, 0.08);
  --font-body: 'Segoe UI', system-ui, -apple-system, sans-serif;
  --font-mono: 'SF Mono', 'Cascadia Code', 'JetBrains Mono', 'Fira Code', monospace;
  --radius-sm: 6px;
  --radius-md: 10px;
  --radius-lg: 14px;
  --shadow-sm: 0 1px 3px rgba(0,0,0,0.3);
  --shadow-md: 0 4px 12px rgba(0,0,0,0.4);
  --shadow-lg: 0 8px 30px rgba(0,0,0,0.5);
  --transition: 0.2s ease;
}

*, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

html { font-size: 15px; }
body {
  font-family: var(--font-body);
  background: var(--bg-primary);
  color: var(--text-primary);
  line-height: 1.6;
  min-height: 100vh;
  overflow-x: hidden;
}

/* ============================================================
   LAYOUT
   ============================================================ */
.app-layout {
  display: grid;
  grid-template-columns: 260px 1fr;
  grid-template-rows: auto 1fr;
  min-height: 100vh;
}

.app-header {
  grid-column: 1 / -1;
  background: var(--bg-secondary);
  border-bottom: 1px solid var(--border-primary);
  padding: 16px 28px;
  display: flex;
  align-items: center;
  justify-content: space-between;
  position: sticky;
  top: 0;
  z-index: 100;
}

.app-header h1 {
  font-size: 1.2rem;
  font-weight: 600;
  letter-spacing: -0.02em;
  display: flex;
  align-items: center;
  gap: 10px;
}

.app-header h1 .icon {
  width: 32px; height: 32px;
  background: linear-gradient(135deg, var(--accent-primary), #7b93fa);
  border-radius: var(--radius-sm);
  display: flex; align-items: center; justify-content: center;
  font-size: 16px;
}

.header-actions {
  display: flex;
  gap: 10px;
  align-items: center;
}

.progress-bar-container {
  flex: 1;
  max-width: 500px;
  margin: 0 30px;
}

.progress-bar {
  height: 4px;
  background: var(--bg-tertiary);
  border-radius: 2px;
  overflow: hidden;
}

.progress-bar-fill {
  height: 100%;
  background: linear-gradient(90deg, var(--accent-primary), var(--success));
  border-radius: 2px;
  transition: width 0.4s ease;
  width: 0%;
}

.progress-label {
  font-size: 0.72rem;
  color: var(--text-muted);
  margin-top: 4px;
  text-align: center;
}

/* ============================================================
   SIDEBAR
   ============================================================ */
.sidebar {
  background: var(--bg-secondary);
  border-right: 1px solid var(--border-primary);
  padding: 16px 0;
  overflow-y: auto;
  position: sticky;
  top: 60px;
  height: calc(100vh - 60px);
}

.sidebar-section-label {
  font-size: 0.68rem;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.08em;
  color: var(--text-muted);
  padding: 14px 20px 6px;
}

.nav-item {
  display: flex;
  align-items: center;
  gap: 10px;
  padding: 9px 20px;
  cursor: pointer;
  transition: all var(--transition);
  border-left: 3px solid transparent;
  font-size: 0.88rem;
  color: var(--text-secondary);
  user-select: none;
}

.nav-item:hover {
  background: var(--bg-hover);
  color: var(--text-primary);
}

.nav-item.active {
  background: var(--accent-glow);
  color: var(--text-accent);
  border-left-color: var(--accent-primary);
  font-weight: 500;
}

.nav-item.completed .nav-dot { background: var(--success); }
.nav-item.has-warning .nav-dot { background: var(--warning); }
.nav-item.locked { opacity: 0.4; pointer-events: none; }

.nav-dot {
  width: 8px; height: 8px;
  border-radius: 50%;
  background: var(--border-primary);
  flex-shrink: 0;
  transition: background var(--transition);
}

.nav-divider {
  height: 1px;
  background: var(--border-primary);
  margin: 10px 20px;
}

/* ============================================================
   MAIN CONTENT
   ============================================================ */
.main-content {
  padding: 30px 40px;
  max-width: 960px;
  overflow-y: auto;
}

.step-panel { display: none; }
.step-panel.active { display: block; animation: fadeIn 0.3s ease; }

@keyframes fadeIn {
  from { opacity: 0; transform: translateY(8px); }
  to { opacity: 1; transform: translateY(0); }
}

.step-header {
  margin-bottom: 28px;
}

.step-header h2 {
  font-size: 1.5rem;
  font-weight: 700;
  letter-spacing: -0.03em;
  margin-bottom: 6px;
}

.step-header p {
  color: var(--text-secondary);
  font-size: 0.92rem;
  max-width: 640px;
}

.step-navigation {
  display: flex;
  justify-content: space-between;
  margin-top: 36px;
  padding-top: 24px;
  border-top: 1px solid var(--border-primary);
}

/* ============================================================
   BUTTONS
   ============================================================ */
.btn {
  display: inline-flex;
  align-items: center;
  gap: 6px;
  padding: 9px 18px;
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-sm);
  background: var(--bg-tertiary);
  color: var(--text-primary);
  font-size: 0.88rem;
  font-family: inherit;
  cursor: pointer;
  transition: all var(--transition);
  font-weight: 500;
}

.btn:hover { background: var(--bg-hover); border-color: var(--text-muted); }

.btn-primary {
  background: var(--accent-primary);
  border-color: var(--accent-primary);
  color: #fff;
}
.btn-primary:hover { background: var(--accent-hover); }

.btn-success {
  background: rgba(52,211,153,0.12);
  border-color: var(--success);
  color: var(--success);
}
.btn-success:hover { background: rgba(52,211,153,0.2); }

.btn-warning {
  background: var(--warning-bg);
  border-color: var(--warning);
  color: var(--warning);
}

.btn-sm { padding: 5px 12px; font-size: 0.8rem; }
.btn-lg { padding: 12px 24px; font-size: 0.95rem; }

.btn:disabled, .btn.disabled {
  opacity: 0.4;
  pointer-events: none;
}

/* ============================================================
   FILE DROP ZONE
   ============================================================ */
.drop-zone {
  border: 2px dashed var(--border-primary);
  border-radius: var(--radius-lg);
  padding: 50px 30px;
  text-align: center;
  transition: all var(--transition);
  cursor: pointer;
  background: var(--bg-tertiary);
}

.drop-zone:hover, .drop-zone.dragover {
  border-color: var(--accent-primary);
  background: var(--accent-glow);
}

.drop-zone .icon { font-size: 2.5rem; margin-bottom: 12px; }
.drop-zone .label { font-size: 1.05rem; font-weight: 500; margin-bottom: 6px; }
.drop-zone .hint { font-size: 0.82rem; color: var(--text-muted); }

/* ============================================================
   CARDS & ALERTS
   ============================================================ */
.card {
  background: var(--bg-card);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  padding: 20px;
  margin-bottom: 16px;
}

.card-header {
  font-weight: 600;
  margin-bottom: 10px;
  display: flex;
  align-items: center;
  gap: 8px;
}

.alert {
  padding: 14px 18px;
  border-radius: var(--radius-md);
  border: 1px solid;
  margin-bottom: 16px;
  font-size: 0.88rem;
  line-height: 1.5;
}

.alert-info { background: var(--info-bg); border-color: rgba(96,165,250,0.3); color: var(--info); }
.alert-success { background: var(--success-bg); border-color: rgba(52,211,153,0.3); color: var(--success); }
.alert-warning { background: var(--warning-bg); border-color: rgba(251,191,36,0.3); color: var(--warning); }
.alert-danger { background: var(--danger-bg); border-color: rgba(248,113,113,0.3); color: var(--danger); }

/* ============================================================
   DATA TABLE
   ============================================================ */
.table-container {
  overflow-x: auto;
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  margin-bottom: 16px;
}

.data-table {
  width: 100%;
  border-collapse: collapse;
  font-size: 0.85rem;
}

.data-table th {
  background: var(--bg-tertiary);
  padding: 10px 14px;
  text-align: left;
  font-weight: 600;
  font-size: 0.78rem;
  text-transform: uppercase;
  letter-spacing: 0.04em;
  color: var(--text-secondary);
  border-bottom: 1px solid var(--border-primary);
  position: sticky;
  top: 0;
  white-space: nowrap;
}

.data-table td {
  padding: 8px 14px;
  border-bottom: 1px solid var(--border-primary);
  white-space: nowrap;
}

.data-table tr:hover td { background: var(--bg-hover); }

.data-table .cell-edit {
  background: transparent;
  border: 1px solid transparent;
  color: var(--text-primary);
  padding: 4px 6px;
  border-radius: 4px;
  font-family: inherit;
  font-size: inherit;
  width: 100%;
  transition: all var(--transition);
}

.data-table .cell-edit:focus {
  border-color: var(--accent-primary);
  background: var(--bg-input);
  outline: none;
}

/* ============================================================
   PARAMETER ROW
   ============================================================ */
.param-group-title {
  font-size: 1.05rem;
  font-weight: 600;
  color: var(--text-accent);
  margin: 28px 0 14px;
  padding-bottom: 8px;
  border-bottom: 1px solid var(--border-primary);
}

.param-row {
  display: grid;
  grid-template-columns: 1fr auto;
  gap: 12px;
  align-items: start;
  padding: 14px 18px;
  background: var(--bg-card);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  margin-bottom: 10px;
  transition: border-color var(--transition);
}

.param-row:hover { border-color: var(--text-muted); }
.param-row.approved { border-color: var(--success); background: var(--success-bg); }
.param-row.modified { border-color: var(--warning); }
.param-row.has-error { border-color: var(--danger); }

.param-info {
  min-width: 0;
}

.param-name {
  font-family: var(--font-mono);
  font-size: 0.85rem;
  color: var(--text-accent);
  font-weight: 500;
  margin-bottom: 4px;
  display: flex;
  align-items: center;
  gap: 8px;
}

.param-name .status-icon {
  font-size: 0.75rem;
}

.param-desc {
  font-size: 0.82rem;
  color: var(--text-secondary);
  margin-bottom: 10px;
  line-height: 1.5;
}

.param-input-row {
  display: flex;
  align-items: center;
  gap: 10px;
  flex-wrap: wrap;
}

.param-input {
  flex: 1;
  min-width: 200px;
  padding: 8px 12px;
  background: var(--bg-input);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-sm);
  color: var(--text-primary);
  font-family: var(--font-mono);
  font-size: 0.85rem;
  transition: all var(--transition);
}

.param-input:focus {
  outline: none;
  border-color: var(--accent-primary);
  box-shadow: 0 0 0 3px var(--accent-glow);
}

.param-input.select {
  appearance: none;
  background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' viewBox='0 0 12 12'%3E%3Cpath fill='%239ca3c0' d='M6 8L1 3h10z'/%3E%3C/svg%3E");
  background-repeat: no-repeat;
  background-position: right 10px center;
  padding-right: 30px;
  cursor: pointer;
}

.param-actions {
  display: flex;
  flex-direction: column;
  gap: 6px;
  align-items: flex-end;
  padding-top: 22px;
}

.param-warning {
  font-size: 0.8rem;
  color: var(--warning);
  margin-top: 6px;
  padding: 6px 10px;
  background: var(--warning-bg);
  border-radius: var(--radius-sm);
  border: 1px solid rgba(251,191,36,0.2);
}

.param-detail-toggle {
  font-size: 0.78rem;
  color: var(--text-muted);
  cursor: pointer;
  border: none;
  background: none;
  padding: 2px 0;
  text-decoration: underline;
  text-decoration-style: dotted;
  text-underline-offset: 3px;
}

.param-detail-toggle:hover { color: var(--text-accent); }

.param-detail {
  display: none;
  margin-top: 10px;
  padding: 12px 14px;
  background: var(--bg-secondary);
  border-radius: var(--radius-sm);
  font-size: 0.82rem;
  color: var(--text-secondary);
  line-height: 1.6;
  border: 1px solid var(--border-primary);
}

.param-detail.open { display: block; }

/* ============================================================
   MULTI-SELECT CHIPS
   ============================================================ */
.chip-container {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
  margin-top: 6px;
}

.chip {
  display: inline-flex;
  align-items: center;
  gap: 5px;
  padding: 4px 12px;
  background: var(--bg-tertiary);
  border: 1px solid var(--border-primary);
  border-radius: 20px;
  font-size: 0.8rem;
  cursor: pointer;
  transition: all var(--transition);
  user-select: none;
}

.chip:hover { border-color: var(--text-muted); }
.chip.selected {
  background: var(--accent-glow);
  border-color: var(--accent-primary);
  color: var(--text-accent);
}

/* ============================================================
   CROSS-TABULATION
   ============================================================ */
.crosstab {
  border-collapse: collapse;
  font-size: 0.85rem;
  margin: 12px 0;
}

.crosstab th, .crosstab td {
  padding: 8px 14px;
  border: 1px solid var(--border-primary);
  text-align: center;
}

.crosstab th {
  background: var(--bg-tertiary);
  font-weight: 600;
  font-size: 0.78rem;
  text-transform: uppercase;
  letter-spacing: 0.04em;
}

.crosstab td { background: var(--bg-card); }
.crosstab .highlight { background: var(--warning-bg); color: var(--warning); font-weight: 600; }

/* ============================================================
   CODE PREVIEW
   ============================================================ */
.code-preview {
  background: var(--bg-primary);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  padding: 20px;
  font-family: var(--font-mono);
  font-size: 0.82rem;
  line-height: 1.7;
  overflow-x: auto;
  white-space: pre-wrap;
  word-break: break-all;
  max-height: 500px;
  overflow-y: auto;
  color: var(--text-secondary);
}

.code-preview .comment { color: var(--text-muted); }
.code-preview .string { color: var(--success); }
.code-preview .keyword { color: var(--accent-primary); }
.code-preview .number { color: var(--warning); }
.code-preview .param-name-hl { color: var(--text-accent); }

/* ============================================================
   VALIDATION LIST
   ============================================================ */
.validation-list {
  list-style: none;
  padding: 0;
}

.validation-item {
  display: flex;
  align-items: flex-start;
  gap: 10px;
  padding: 8px 0;
  font-size: 0.88rem;
}

.validation-icon { flex-shrink: 0; font-size: 1rem; }
.validation-pass .validation-icon { color: var(--success); }
.validation-warn .validation-icon { color: var(--warning); }
.validation-fail .validation-icon { color: var(--danger); }

/* ============================================================
   TOOLTIP
   ============================================================ */
.tooltip-trigger {
  cursor: help;
  border-bottom: 1px dotted var(--text-muted);
}

/* ============================================================
   COLUMN ROLE SELECTOR
   ============================================================ */
.column-role-card {
  display: flex;
  align-items: center;
  gap: 14px;
  padding: 12px 16px;
  background: var(--bg-card);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  margin-bottom: 8px;
}

.column-role-card .col-name {
  font-family: var(--font-mono);
  font-weight: 600;
  color: var(--text-accent);
  min-width: 140px;
}

.column-role-card .col-values {
  font-size: 0.8rem;
  color: var(--text-muted);
  flex: 1;
}

.column-role-card select {
  padding: 6px 28px 6px 10px;
  background: var(--bg-input);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-sm);
  color: var(--text-primary);
  font-family: inherit;
  font-size: 0.84rem;
  appearance: none;
  background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='12' height='12' viewBox='0 0 12 12'%3E%3Cpath fill='%239ca3c0' d='M6 8L1 3h10z'/%3E%3C/svg%3E");
  background-repeat: no-repeat;
  background-position: right 8px center;
  cursor: pointer;
}

.column-role-card select:focus {
  outline: none;
  border-color: var(--accent-primary);
}

/* ============================================================
   APPROVE ALL BAR
   ============================================================ */
.approve-all-bar {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 12px 18px;
  background: var(--bg-tertiary);
  border: 1px solid var(--border-primary);
  border-radius: var(--radius-md);
  margin-bottom: 20px;
}

.approve-all-bar .status {
  font-size: 0.88rem;
  color: var(--text-secondary);
}

/* ============================================================
   SCROLLBAR
   ============================================================ */
::-webkit-scrollbar { width: 8px; height: 8px; }
::-webkit-scrollbar-track { background: transparent; }
::-webkit-scrollbar-thumb { background: var(--border-primary); border-radius: 4px; }
::-webkit-scrollbar-thumb:hover { background: var(--text-muted); }

/* ============================================================
   RESPONSIVE
   ============================================================ */
@media (max-width: 800px) {
  .app-layout { grid-template-columns: 1fr; }
  .sidebar { display: none; }
  .main-content { padding: 20px; }
}
</style>
</head>
<body>
<div class="app-layout">

  <!-- ========== HEADER ========== -->
  <header class="app-header">
    <h1>
      <span class="icon">üß¨</span>
      scRNA-seq Pipeline Configurator
    </h1>
    <div class="progress-bar-container">
      <div class="progress-bar"><div class="progress-bar-fill" id="progressFill"></div></div>
      <div class="progress-label" id="progressLabel">Step 1 of 15</div>
    </div>
    <div class="header-actions">
      <button class="btn btn-sm" onclick="exportState()" title="Save current session">üíæ Save Session</button>
      <button class="btn btn-sm" onclick="importState()" title="Load saved session">üìÇ Load Session</button>
    </div>
  </header>

  <!-- ========== SIDEBAR ========== -->
  <nav class="sidebar" id="sidebar">
    <div class="sidebar-section-label">Phase A ‚Äî Sample Sheet</div>
    <div class="nav-item active" data-step="a1" onclick="goToStep('a1')">
      <span class="nav-dot"></span> Load Sample Sheet
    </div>
    <div class="nav-item locked" data-step="a2" onclick="goToStep('a2')">
      <span class="nav-dot"></span> Column Roles
    </div>
    <div class="nav-item locked" data-step="a3" onclick="goToStep('a3')">
      <span class="nav-dot"></span> Design Analysis
    </div>
    <div class="nav-item locked" data-step="a4" onclick="goToStep('a4')">
      <span class="nav-dot"></span> Edit & Validate
    </div>
    <div class="nav-item locked" data-step="a5" onclick="goToStep('a5')">
      <span class="nav-dot"></span> Export Sample Sheet
    </div>

    <div class="nav-divider"></div>
    <div class="sidebar-section-label">Phase B ‚Äî params.R</div>
    <div class="nav-item locked" data-step="b0" onclick="goToStep('b0')">
      <span class="nav-dot"></span> Load params.R
    </div>
    <div class="nav-item locked" data-step="b1" onclick="goToStep('b1')">
      <span class="nav-dot"></span> Project & Input
    </div>
    <div class="nav-item locked" data-step="b2" onclick="goToStep('b2')">
      <span class="nav-dot"></span> QC & Filtering
    </div>
    <div class="nav-item locked" data-step="b3" onclick="goToStep('b3')">
      <span class="nav-dot"></span> Normalization
    </div>
    <div class="nav-item locked" data-step="b4" onclick="goToStep('b4')">
      <span class="nav-dot"></span> Imputation
    </div>
    <div class="nav-item locked" data-step="b5" onclick="goToStep('b5')">
      <span class="nav-dot"></span> Integration
    </div>
    <div class="nav-item locked" data-step="b6" onclick="goToStep('b6')">
      <span class="nav-dot"></span> Clustering
    </div>
    <div class="nav-item locked" data-step="b7" onclick="goToStep('b7')">
      <span class="nav-dot"></span> Differential Expression
    </div>
    <div class="nav-item locked" data-step="b8" onclick="goToStep('b8')">
      <span class="nav-dot"></span> Visualization & Paths
    </div>
    <div class="nav-item locked" data-step="b9" onclick="goToStep('b9')">
      <span class="nav-dot"></span> Review & Export
    </div>
  </nav>

  <!-- ========== MAIN CONTENT ========== -->
  <main class="main-content" id="mainContent">

    <!-- ==================== PHASE A ==================== -->

    <!-- A1: Load Sample Sheet -->
    <div class="step-panel active" id="step-a1">
      <div class="step-header">
        <h2>Load Sample Sheet</h2>
        <p>Start by loading your sample sheet CSV file. This file defines your samples, their metadata (sex, batch, condition), and which ones to include in the analysis.</p>
      </div>

      <div class="alert alert-info">
        <strong>Required columns:</strong> <code>sample_name</code>, <code>sex</code>, <code>batch</code><br>
        <strong>Optional columns:</strong> <code>condition</code>, <code>ventricle</code>, <code>include</code>, <code>group_id</code>, and any custom covariates
      </div>

      <div class="drop-zone" id="csvDropZone">
        <div class="icon">üìÑ</div>
        <div class="label">Drop your sample_sheet.csv here</div>
        <div class="hint">or click to browse files</div>
        <input type="file" accept=".csv,.tsv,.txt" id="csvFileInput" style="display:none">
      </div>

      <div id="csvPreviewArea" style="display:none; margin-top: 24px;">
        <div class="card-header">üìã Preview</div>
        <div class="table-container" id="csvPreviewTable"></div>
      </div>

      <div class="step-navigation">
        <span></span>
        <button class="btn btn-primary btn-lg disabled" id="btnToA2" onclick="goToStep('a2')">Continue to Column Roles ‚Üí</button>
      </div>
    </div>

    <!-- A2: Column Roles -->
    <div class="step-panel" id="step-a2">
      <div class="step-header">
        <h2>Assign Column Roles</h2>
        <p>Define what each column in your sample sheet represents. The pipeline uses these roles to determine how samples are integrated, compared, and grouped.</p>
      </div>

      <div class="alert alert-info">
        <strong>Key roles:</strong><br>
        ‚Ä¢ <strong>Sample ID</strong> ‚Äî Unique identifier for each sample (required)<br>
        ‚Ä¢ <strong>Sex</strong> ‚Äî Biological sex, used for DE comparisons (required)<br>
        ‚Ä¢ <strong>Batch</strong> ‚Äî Processing batch, used for batch correction (required)<br>
        ‚Ä¢ <strong>Condition</strong> ‚Äî Experimental condition (e.g., Control vs COVID)<br>
        ‚Ä¢ <strong>Include</strong> ‚Äî Whether to include this sample in analysis (TRUE/FALSE)
      </div>

      <div id="columnRolesContainer"></div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('a1')">‚Üê Back</button>
        <button class="btn btn-primary btn-lg" id="btnToA3" onclick="goToStep('a3')">Continue to Design Analysis ‚Üí</button>
      </div>
    </div>

    <!-- A3: Design Analysis -->
    <div class="step-panel" id="step-a3">
      <div class="step-header">
        <h2>Experimental Design Analysis</h2>
        <p>Analysis of your sample structure to detect confounding, imbalance, and inform integration strategy.</p>
      </div>

      <div id="designAnalysisContent"></div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('a2')">‚Üê Back</button>
        <button class="btn btn-primary btn-lg" onclick="goToStep('a4')">Continue to Edit & Validate ‚Üí</button>
      </div>
    </div>

    <!-- A4: Edit & Validate -->
    <div class="step-panel" id="step-a4">
      <div class="step-header">
        <h2>Edit & Validate Sample Sheet</h2>
        <p>Review and edit your sample sheet. Toggle sample inclusion, fix values, and ensure everything is correct before export.</p>
      </div>

      <div class="table-container" id="editableTableContainer"></div>

      <div id="sampleSheetValidation" style="margin-top: 20px;"></div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('a3')">‚Üê Back</button>
        <button class="btn btn-primary btn-lg" onclick="goToStep('a5')">Continue to Export ‚Üí</button>
      </div>
    </div>

    <!-- A5: Export Sample Sheet -->
    <div class="step-panel" id="step-a5">
      <div class="step-header">
        <h2>Export Sample Sheet</h2>
        <p>Your validated sample sheet is ready. Download it and then continue to configure the analysis parameters.</p>
      </div>

      <div id="exportValidationSummary"></div>

      <div style="display: flex; gap: 12px; margin-top: 24px;">
        <button class="btn btn-success btn-lg" onclick="downloadSampleSheet()">‚¨á Download sample_sheet.csv</button>
      </div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('a4')">‚Üê Back</button>
        <button class="btn btn-primary btn-lg" onclick="goToStep('b0')">Continue to params.R Configuration ‚Üí</button>
      </div>
    </div>

    <!-- ==================== PHASE B ==================== -->

    <!-- B0: Load params.R -->
    <div class="step-panel" id="step-b0">
      <div class="step-header">
        <h2>Load Existing params.R</h2>
        <p>Optionally load an existing params.R file to pre-fill values. Or start from a clean template with recommended defaults.</p>
      </div>

      <div style="display: flex; gap: 16px; margin-bottom: 24px;">
        <div class="drop-zone" id="paramsDropZone" style="flex:1; padding: 30px 20px;">
          <div class="icon">üìú</div>
          <div class="label">Drop params.R here</div>
          <div class="hint">or click to browse</div>
          <input type="file" accept=".R,.r,.txt" id="paramsFileInput" style="display:none">
        </div>
        <div style="display:flex; align-items:center;">
          <span style="color: var(--text-muted); font-size: 0.9rem;">‚Äî or ‚Äî</span>
        </div>
        <div class="drop-zone" style="flex:1; padding: 30px 20px;" onclick="loadDefaultParams()">
          <div class="icon">‚ú®</div>
          <div class="label">Start from Template</div>
          <div class="hint">Uses recommended defaults</div>
        </div>
      </div>

      <div id="paramsLoadStatus" style="display:none;"></div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('a5')">‚Üê Back to Sample Sheet</button>
        <button class="btn btn-primary btn-lg" id="btnToB1" onclick="goToStep('b1')">Configure Parameters ‚Üí</button>
      </div>
    </div>

    <!-- B1‚ÄìB8: Parameter Steps (generated dynamically) -->
    <div class="step-panel" id="step-b1"></div>
    <div class="step-panel" id="step-b2"></div>
    <div class="step-panel" id="step-b3"></div>
    <div class="step-panel" id="step-b4"></div>
    <div class="step-panel" id="step-b5"></div>
    <div class="step-panel" id="step-b6"></div>
    <div class="step-panel" id="step-b7"></div>
    <div class="step-panel" id="step-b8"></div>

    <!-- B9: Review & Export -->
    <div class="step-panel" id="step-b9">
      <div class="step-header">
        <h2>Review & Export params.R</h2>
        <p>Final review of all configured parameters. Your values are injected into the full pipeline template, preserving all infrastructure code, validation logic, and documentation.</p>
      </div>

      <div id="finalValidation"></div>
      <div id="paramsPreview" style="margin-top: 20px;"></div>

      <div style="display: flex; gap: 12px; margin-top: 24px; flex-wrap: wrap;">
        <button class="btn btn-success btn-lg" onclick="downloadFullParamsR()">‚¨á Download Full params.R</button>
        <button class="btn btn-lg" onclick="copyFullParamsR()">üìã Copy Full to Clipboard</button>
        <button class="btn btn-sm" onclick="downloadFlatParamsR()" title="Download a minimal params list without pipeline infrastructure (for reference only)">‚¨á Flat params only</button>
      </div>

      <div class="step-navigation">
        <button class="btn" onclick="goToStep('b8')">‚Üê Back</button>
        <span></span>
      </div>
    </div>

  </main>
</div>

<script type="text/plain" id="paramsTemplate">
# ==============================================================================
# CONFIGURATION PARAMETERS - SCRNASEQ DOWNSTREAM ANALYSIS PIPELINE
# ==============================================================================
#
# This configuration file controls all aspects of the downstream analysis.
# Parameters are organized following the pipeline module structure.
#
# =============================================================================
# PIPELINE MODULE STRUCTURE
# =============================================================================
#
# Module 00: Environment Setup
# Module 01: Load & QC (filtering, doublet removal)
# Module 02: Merge Samples
# Module 02b: Imputation - afMF (optional, counts-based)
# Module 03: Normalization (SCTransform, scran, LogNormalize)
# Module 03b: Imputation - ALRA (optional, normalized-data-based)
# Module 04: Integration & Benchmarking
# Module 05: CHOIR Clustering
# Module 05b: scCobra
# Module 06: scICE Subclustering
# Module 07: Leiden Clustering
# Module 07b: CLTS Re-normalization
# Module 08: Differential Expression
# Module 09: Visualization
#
# =============================================================================
# KEY ANALYSIS PARAMETERS - QUICK REFERENCE
# =============================================================================
#
# IMPUTATION (Modules 02b and 03b):
# ------------------------------------------------------------------------------
# Two imputation methods are available at different pipeline stages:
#
# 1. afMF (Module 02b) - COUNTS-BASED IMPUTATION:
#    - Runs BEFORE normalization on raw counts
#    - Uses Low-rank Full Matrix Factorization
#    - Output: "imputed" assay with imputed counts
#    - Always runs if imputation_method = "afmf" or "both"
#
# 2. ALRA (Module 03b) - NORMALIZED-DATA IMPUTATION:
#    - Runs AFTER normalization on log-normalized data
#    - Uses Adaptively-thresholded Low Rank Approximation
#    - Output: "ALRA" assay with imputed normalized data
#    - ONLY works with LogNormalize and scran (NOT SCTransform)
#    - Automatically SKIPPED if SCTransform wins benchmarking
#
# IMPUTATION METHOD SELECTION:
#   params$imputation_method <- "both"   # Default: run both methods
#
#   Options:
#     "none"  - No imputation (original data only)
#     "afmf"  - Only afMF (counts-based, Module 02b)
#     "alra"  - Only ALRA (normalized-data, Module 03b)*
#     "both"  - Both methods (afMF in 02b, ALRA in 03b)*
#
#   * ALRA automatically skipped if SCTransform is selected as best
#     normalization method from benchmarking.
#
# DOWNSTREAM USAGE:
#   params$use_afmf_for_normalization <- FALSE  # Use imputed counts in Module 03
#   params$use_alra_for_downstream <- FALSE     # Use ALRA data in Module 04+
#
# INTEGRATION METHOD SELECTION (Module 04):
# ------------------------------------------------------------------------------
#   params$integration_selection_mode <- "balanced"  # RECOMMENDED for most studies
#
#   Options:
#     "batch_removal"  - Minimizes batch_variance (most aggressive correction)
#                        Winner criterion: which.min(batch_variance)
#                        Use when: Batches are TECHNICAL replicates (same biology,
#                                  different processing times/labs/technicians)
#                        Risk: May over-correct and remove real biological signal
#                        Example: Same cell line processed on different days
#
#     "balanced"       - Maximizes composite score across ALL metrics
#                        Winner criterion: which.max(mean(batch_var_norm, asw_norm, lisi_norm))
#                        Use when: Batches have BIOLOGICAL meaning (different conditions,
#                                  sexes, timepoints, treatments, genotypes)
#                        Benefit: Removes technical noise while preserving biology
#                        Example: Male vs Female samples, Treatment vs Control
#                        >>> RECOMMENDED FOR MOST BIOLOGICAL COMPARISONS <<<
#
#     "conservative"   - Prioritizes LISI score (moderate mixing)
#                        Winner criterion: which.max(lisi_norm)
#                        Use when: Preserving subtle biological differences is critical
#                        Example: Rare cell populations, subtle disease states
#
# BATCH VARIABLE:
# ------------------------------------------------------------------------------
#   params$batch_variable <- "sample_name"
#
#   This defines what constitutes a "batch" for integration:
#     "sample_name"  - Each sample is a batch (most common)
#     "batch"        - Use explicit batch column from sample sheet
#     "sex"          - NOT recommended (removes sex differences!)
#
# CLTS RE-NORMALIZATION (Module 07b):
# ------------------------------------------------------------------------------
#   params$clts_clustering_source <- "scice"
#
#   Options:
#     "scice"  - Apply CLTS using scICE subclusters (DEFAULT)
#     "leiden" - Apply CLTS using Leiden clusters
#     "choir"  - Apply CLTS using CHOIR clusters
#     "both"   - Apply CLTS to BOTH scICE and Leiden
#     "all"    - Apply CLTS to scICE, Leiden, AND CHOIR
#
# DIFFERENTIAL EXPRESSION SETTINGS (Module 08):
# ------------------------------------------------------------------------------
#   params$de_comparison_variable <- "sex"     # What to compare
#   params$de_group1 <- "Male"                 # Numerator (positive fold change)
#   params$de_group2 <- "Female"               # Denominator (reference)
#   params$de_comparison_scope <- "whole_dataset"  # or "per_cluster"
#   params$de_object_sources <- c("scice", "scice_redeconv")  # Objects for DE
#
# CLUSTERING METHODS:
# ------------------------------------------------------------------------------
#   params$run_choir_clustering <- TRUE        # Hierarchical clustering
#   params$run_scice_subclustering <- TRUE     # Julia-based subclustering
#   params$run_leiden_clustering <- TRUE       # Graph-based clustering
#
# =============================================================================
#
# QUICK START - CONFIGURE THESE SECTIONS:
#   1. INPUT FILES CONFIGURATION (lines ~150-200) - Where are your input files?
#   2. SAMPLE SHEET (auto-loaded from project root or config folder)
#   3. FILTERING OPTIONS (lines ~350-400) - What filtering to apply?
#   4. ANALYSIS OPTIONS (lines ~500+) - What analyses to run?
#
# OUTPUT LOCATION:
#   Output is automatically placed based on environment variables:
#   - PREPROCESS_DIR -> for reading preprocessing outputs
#   - DOWNSTREAM_DIR -> for writing downstream analysis outputs
#
# See Define_input_paths.txt for detailed documentation.
#
# CONFIGURATOR TAGS:
#   Lines marked with # <<CFG:param_name>> are managed by the pipeline
#   configurator. The configurator only modifies values on tagged lines.
#   All infrastructure, logic, and validation code is preserved.
#
# UPDATES:
# - 2026-02-06: Added <<CFG>> configurator tags to all adjustable parameters
# - 2026-02-05: Added norm_benchmark_integration_methods parameter (was referenced
#               by 03_normalization.R but never defined, defaulting to Harmony-only)
# - 2026-01-09: Added unified imputation_method parameter ("none"/"afmf"/"alra"/"both")
# - 2026-01-09: Added Module 03b ALRA imputation (post-normalization)
# - 2026-01-09: ALRA auto-skips if SCTransform selected from benchmarking
# - 2026-01-09: Added CLTS clustering source selection (clts_clustering_source)
# - 2026-01-09: Added DE object source selection (de_object_sources)
# - 2026-01-09: Added cross-object comparison for DE (de_run_cross_object_comparison)
# - 2026-01-07: Added generic GROUP_ID/GROUP_LABEL filtering system
# - 2026-01-06: Moved functions to functions.R (load_sample_sheet, validate_params, etc.)
# - 2026-01-06: Added integration_selection_mode for balanced vs aggressive selection
# - 2026-01-06: Updated to use PREPROCESS_DIR and DOWNSTREAM_DIR environment vars
# - 2026-01-06: Compatible with new Output_dir_<dataset>/Single_cell_* structure
# - 2026-01-05: Made output path relative to script/project location
# - 2026-01-05: Added flexible input path configuration
# - 2026-01-05: Added comprehensive filtering control flags
#
# ==============================================================================


# ==============================================================================
# SECTION 0: PROJECT ROOT AND ENVIRONMENT DETECTION
# ==============================================================================
# The directories are automatically determined based on:
#   1. Environment variables set by submit_all_jobs.sh:
#      - PROJECT_ROOT, PREPROCESS_DIR, DOWNSTREAM_DIR, DATASET_NAME
#      - GROUP_ID, GROUP_LABEL (new generic filtering)
#      - VENTRICLE_FILTER (backward compatible)
#   2. Location of this params.R file (fallback)
#   3. Current working directory (ultimate fallback)
#
# This makes the pipeline portable - just copy the project folder and run.
# ==============================================================================

cat("\n")
cat("================================================================================\n")
cat("LOADING PIPELINE CONFIGURATION\n")
cat("================================================================================\n\n")

# ------------------------------------------------------------------------------
# Set global R options for parallel processing (future package)
# ------------------------------------------------------------------------------
# SCTransform and other functions use the future package for parallelization.
# Large datasets can exceed the default 500 MB globals limit, causing failures.
# This must be set early since params.R is sourced by all modules.
options(future.globals.maxSize = 8 * 1024^3)  # 8 GB

# ------------------------------------------------------------------------------
# 0A. Read Environment Variables
# ------------------------------------------------------------------------------

env_project_root <- Sys.getenv("PROJECT_ROOT", unset = "")
env_preprocess_dir <- Sys.getenv("PREPROCESS_DIR", unset = "")
env_downstream_dir <- Sys.getenv("DOWNSTREAM_DIR", unset = "")
env_dataset_name <- Sys.getenv("DATASET_NAME", unset = "")
env_ventricle_filter <- Sys.getenv("VENTRICLE_FILTER", unset = "")
env_group_id <- Sys.getenv("GROUP_ID", unset = "")
env_group_label <- Sys.getenv("GROUP_LABEL", unset = "")

cat("Environment variables detected:\n")
cat("  PROJECT_ROOT:     ", if (env_project_root != "") env_project_root else "<not set>", "\n")
cat("  PREPROCESS_DIR:   ", if (env_preprocess_dir != "") env_preprocess_dir else "<not set>", "\n")
cat("  DOWNSTREAM_DIR:   ", if (env_downstream_dir != "") env_downstream_dir else "<not set>", "\n")
cat("  DATASET_NAME:     ", if (env_dataset_name != "") env_dataset_name else "<not set>", "\n")
cat("  GROUP_ID:         ", if (env_group_id != "") env_group_id else "<not set>", "\n")
cat("  GROUP_LABEL:      ", if (env_group_label != "") env_group_label else "<not set>", "\n")
cat("  VENTRICLE_FILTER: ", if (env_ventricle_filter != "") env_ventricle_filter else "<not set>", "\n")
cat("\n")

# ------------------------------------------------------------------------------
# 0B. Determine Project Root
# ------------------------------------------------------------------------------

project_root <- env_project_root

if (project_root == "" || !dir.exists(project_root)) {
  # Fallback 1: Derive from this script's location
  # params.R is at: {project}/Scripts/scrnaseq_pipeline/config/params.R
  # So project root is 4 levels up

  script_path <- tryCatch({
    if (sys.nframe() > 0) {
      for (i in seq_len(sys.nframe())) {
        ofile <- sys.frame(i)$ofile
        if (!is.null(ofile) && grepl("params\\.R$", ofile)) {
          normalizePath(ofile)
        }
      }
    }
    NULL
  }, error = function(e) NULL)

  if (!is.null(script_path) && file.exists(script_path)) {
    project_root <- normalizePath(file.path(dirname(script_path), "..", "..", "..", ".."))
  } else {
    # Fallback 2: Try common relative paths from current directory
    possible_roots <- c(
      getwd(),
      file.path(getwd(), ".."),
      file.path(getwd(), "..", ".."),
      file.path(getwd(), "..", "..", "..")
    )

    for (root in possible_roots) {
      if (dir.exists(root)) {
        if (file.exists(file.path(root, "submit_all_jobs.sh")) ||
            file.exists(file.path(root, "samplesheet.csv"))) {
          project_root <- normalizePath(root)
          break
        }
      }
    }

    # Ultimate fallback: use current working directory
    if (project_root == "" || !dir.exists(project_root)) {
      project_root <- getwd()
      cat("WARNING: Could not detect project root. Using current directory.\n")
    }
  }
}

cat("Project root:", project_root, "\n")

# ------------------------------------------------------------------------------
# 0C. Determine Dataset Name
# ------------------------------------------------------------------------------

dataset_name <- env_dataset_name

if (dataset_name == "") {
  # Try to read from samplesheet
  samplesheet_path <- file.path(project_root, "samplesheet.csv")
  if (file.exists(samplesheet_path)) {
    tryCatch({
      ss <- read.csv(samplesheet_path, stringsAsFactors = FALSE, nrows = 2)
      if ("dataset_name" %in% colnames(ss) && nrow(ss) > 0) {
        dataset_name <- ss$dataset_name[1]
        cat("Dataset name from samplesheet:", dataset_name, "\n")
      }
    }, error = function(e) NULL)
  }
}

if (dataset_name == "") {
  # Default dataset name
  dataset_name <- "default"
  cat("WARNING: Dataset name not found, using 'default'\n")
}

# ------------------------------------------------------------------------------
# 0D. Source utility functions (needed for load_sample_sheet, validate_params, etc.)
# ------------------------------------------------------------------------------

scripts_dir <- file.path(project_root, "Scripts")
pipeline_scripts_dir <- file.path(scripts_dir, "scrnaseq_pipeline")

utils_file <- file.path(pipeline_scripts_dir, "utils", "functions.R")
if (file.exists(utils_file)) {
  source(utils_file)
} else {
  # Try alternative paths
  alt_paths <- c(
    file.path(getwd(), "utils", "functions.R"),
    file.path(getwd(), "..", "utils", "functions.R"),
    file.path(dirname(sys.frame(1)$ofile), "..", "utils", "functions.R")
  )
  for (alt_path in alt_paths) {
    if (file.exists(alt_path)) {
      source(alt_path)
      break
    }
  }
}


# ==============================================================================
# SECTION 1: INPUT FILES CONFIGURATION
# ==============================================================================
# Configure where your input files are located and how they are named.
# This is the MOST IMPORTANT section to configure for a new experiment.
# ==============================================================================

# ------------------------------------------------------------------------------
# 1A. INPUT DIRECTORY
# ------------------------------------------------------------------------------
# Priority:
#   1. PREPROCESS_DIR environment variable + step folder
#   2. Derived from project_root + dataset_name
#   3. Legacy hardcoded path (for backward compatibility)
#
# UPDATED 2026-01-15: Now reads from Step 8 (DecontX) instead of Step 7 (scCDC)
# The DecontX output contains scCDC + DecontX corrected counts in the
# 'scCDC_corrected' layer (same layer name, updated contents).

if (env_preprocess_dir != "" && dir.exists(env_preprocess_dir)) {
  # Use environment variable from submit_all_jobs.sh
  input_dir <- file.path(env_preprocess_dir, "8_DecontX_correction")
  cat("Input directory from PREPROCESS_DIR:", input_dir, "\n")
} else if (dataset_name != "" && dataset_name != "default") {
  # Derive from dataset name
  input_dir <- file.path(project_root, paste0("Output_dir_", dataset_name),
                         "Single_cell_preprocessed", "8_DecontX_correction")
  cat("Input directory derived from dataset_name:", input_dir, "\n")
} else {
  # Fallback to legacy hardcoded path for backward compatibility
  input_dir <- "/scicore/home/doetsch/kaiser0001/Revision_NatureComm_Sex/Single_cell_data_expression_analysis/CHOIR_Output/scCDC_Counts/All_Separate"  # <<CFG:legacy_input_dir>>
  cat("WARNING: Using legacy hardcoded input directory\n")
  cat("Input directory:", input_dir, "\n")
}

# ------------------------------------------------------------------------------
# 1B. FILE NAMING PATTERN
# ------------------------------------------------------------------------------
# How are your files named? Use {sample_name} as a placeholder.
# The {sample_name} will be replaced with values from your sample sheet.
#
# For new pipeline structure (Steps 1-8):
#   Files are in: 8_DecontX_correction/<sample_name>/<sample_name>_decontX_corrected.rds
#
# For legacy structure:
#   Files are in: input_dir/<sample_name>_qClus_CHOIR_scCDC_corrected.rds
#
# UPDATED 2026-01-15: New pipeline now reads from DecontX output (Step 8)

# Detect which structure we're using
if (env_preprocess_dir != "" || (dataset_name != "" && dataset_name != "default")) {
  # New pipeline structure - DecontX output
  input_file_pattern <- "{sample_name}_decontX_corrected.rds"
  files_in_subdirectories <- TRUE
  cat("Using NEW pipeline file structure (files in sample subdirectories)\n")
} else {
  # Legacy structure
  input_file_pattern <- "{sample_name}_qClus_CHOIR_scCDC_corrected.rds"  # <<CFG:legacy_input_file_pattern>>
  files_in_subdirectories <- FALSE  # <<CFG:legacy_files_in_subdirectories>>
  cat("Using LEGACY file structure (all files in one directory)\n")
}

# ------------------------------------------------------------------------------
# 1C. COUNTS LAYER TO USE
# ------------------------------------------------------------------------------
# Which layer in the Seurat object contains the counts for analysis?
#
#   "auto"             -> Auto-detect (tries scCDC_corrected, then counts, then data)
#   "scCDC_corrected"  -> Use ambient RNA corrected counts (scCDC + DecontX)
#   "counts"           -> Use raw counts
#
# NOTE: The DecontX output stores scCDC + DecontX corrected counts in the
# 'scCDC_corrected' layer (same layer name as before, but now with additional
# DecontX ambient RNA removal applied).

counts_layer_to_use <- "auto"  # <<CFG:counts_layer_to_use>>


# ==============================================================================
# SECTION 2: OUTPUT CONFIGURATION
# ==============================================================================
# Output is placed based on DOWNSTREAM_DIR or derived from project structure.
# ==============================================================================

# ------------------------------------------------------------------------------
# 2A. OUTPUT BASE DIRECTORY
# ------------------------------------------------------------------------------

if (env_downstream_dir != "") {
  # Use environment variable from submit_all_jobs.sh
  output_base_dir <- env_downstream_dir
  cat("Output base from DOWNSTREAM_DIR:", output_base_dir, "\n")
} else if (dataset_name != "" && dataset_name != "default") {
  # Derive from dataset name
  output_base_dir <- file.path(project_root, paste0("Output_dir_", dataset_name),
                                "Single_cell_clustering")
  cat("Output base derived from dataset_name:", output_base_dir, "\n")
} else {
  # Fallback to project root
  output_base_dir <- project_root
  cat("WARNING: Using project_root as output base\n")
}

# ------------------------------------------------------------------------------
# 2B. GROUP-BASED OR VENTRICLE-SPECIFIC ANALYSIS
# ------------------------------------------------------------------------------
# The pipeline supports two filtering systems:
#   1. NEW: Generic group-based filtering (GROUP_ID + GROUP_LABEL)
#   2. LEGACY: Ventricle-specific filtering (VENTRICLE_FILTER)
#
# Group-based filtering takes priority when GROUP_LABEL is set.

group_id <- env_group_id
group_label <- env_group_label
ventricle_filter <- env_ventricle_filter

# Determine the active filter and output label
if (group_label != "") {
  # New generic system: use group_label for output directory naming
  analysis_label <- group_label
  cat(">>> GROUP-BASED ANALYSIS: Group", group_id, "(", group_label, ") <<<\n")
} else if (ventricle_filter != "") {
  # Backward compatibility: validate and use ventricle for output directory
  if (!ventricle_filter %in% c("LV", "4V", "ALL")) {
    stop("Invalid VENTRICLE_FILTER: '", ventricle_filter, "'. Must be 'LV', '4V', or 'ALL'")
  }
  analysis_label <- ventricle_filter
  cat(">>> VENTRICLE-SPECIFIC ANALYSIS:", ventricle_filter, "<<<\n")
} else {
  # No filter: analyze all samples
  analysis_label <- ""
  cat(">>> FULL DATASET ANALYSIS (all samples) <<<\n")
}

# Set output directory based on analysis label
if (analysis_label != "") {
  out_root <- file.path(output_base_dir, paste0("10_Downstream_Analysis_", analysis_label))
} else {
  out_root <- file.path(output_base_dir, "10_Downstream_Analysis")
}

cat("Output directory:", out_root, "\n\n")


# ==============================================================================
# SECTION 3: SAMPLE SHEET CONFIGURATION
# ==============================================================================

# ------------------------------------------------------------------------------
# 3A. SAMPLE SHEET LOCATION
# ------------------------------------------------------------------------------
# Search for sample sheet in common locations

# Search order for sample sheet
sample_sheet_candidates <- c(
  file.path(pipeline_scripts_dir, "config", "sample_sheet.csv"),
  file.path(project_root, "samplesheet.csv"),
  file.path(project_root, "sample_sheet.csv"),
  file.path(project_root, "config", "sample_sheet.csv")
)

sample_sheet_path <- NULL
for (candidate in sample_sheet_candidates) {
  if (file.exists(candidate)) {
    sample_sheet_path <- candidate
    cat("Found sample sheet:", sample_sheet_path, "\n")
    break
  }
}

if (is.null(sample_sheet_path)) {
  sample_sheet_path <- sample_sheet_candidates[1]  # Default location
  cat("WARNING: Sample sheet not found. Expected at:", sample_sheet_path, "\n")
}

# ------------------------------------------------------------------------------
# 3B. LOAD SAMPLE SHEET
# ------------------------------------------------------------------------------
# Note: load_sample_sheet() function is now in functions.R
# If functions.R doesn't have group filtering support, we handle it here

sample_metadata <- tryCatch({
  # Try loading with the updated function that supports group filtering
  if (exists("load_sample_sheet")) {
    loaded_data <- load_sample_sheet(
      sample_sheet_path = sample_sheet_path,
      input_dir = input_dir,
      input_file_pattern = input_file_pattern,
      files_in_subdirectories = files_in_subdirectories,
      ventricle_filter = ventricle_filter
    )

    # Apply group-based filtering if GROUP_ID is set and not already filtered
    if (group_id != "" && "group_id" %in% colnames(loaded_data)) {
      loaded_data <- loaded_data[as.character(loaded_data$group_id) == group_id, ]
      cat("Applied group_id filter:", group_id, "->", nrow(loaded_data), "samples\n")
    }

    loaded_data
  } else {
    stop("load_sample_sheet function not found")
  }
}, error = function(e) {
  cat("WARNING: Could not load sample sheet:", e$message, "\n")
  cat("Using default Vandebroucke sample metadata...\n")

  # Fallback metadata - MODIFY THIS for your specific dataset
  all_samples <- data.frame(
    sample_name = c("M_22w_LV", "M_22w_4V", "F_7w_LV", "F_7w_4V"),
    sex = c("Male", "Male", "Female", "Female"),
    age = c("22w", "22w", "7w", "7w"),
    batch = c("Batch1", "Batch1", "Batch1", "Batch1"),
    ventricle = c("LV", "4V", "LV", "4V"),
    group_id = c("1", "2", "1", "2"),
    group_label = c("Lateral_Ventricle", "Fourth_Ventricle", "Lateral_Ventricle", "Fourth_Ventricle"),
    include = rep(TRUE, 4),
    stringsAsFactors = FALSE
  )

  # Apply group-based filtering (new generic system)
  if (group_id != "" && "group_id" %in% colnames(all_samples)) {
    all_samples <- all_samples[as.character(all_samples$group_id) == group_id, ]
    cat("Applied group_id filter:", group_id, "->", nrow(all_samples), "samples\n")
  } else if (ventricle_filter != "" && ventricle_filter != "ALL") {
    # Backward compatibility: filter by ventricle
    all_samples <- all_samples[all_samples$ventricle == ventricle_filter, ]
    cat("Applied ventricle filter:", ventricle_filter, "->", nrow(all_samples), "samples\n")
  }

  all_samples$input_file <- sapply(all_samples$sample_name, function(s) {
    filename <- gsub("\\{sample_name\\}", s, input_file_pattern)
    if (files_in_subdirectories) {
      file.path(input_dir, s, filename)
    } else {
      file.path(input_dir, filename)
    }
  })

  all_samples
})


# ==============================================================================
# SECTION 4: MODULE 01 - QC AND FILTERING PARAMETERS
# ==============================================================================

# ------------------------------------------------------------------------------
# 4A. MASTER FILTERING CONTROL
# ------------------------------------------------------------------------------
skip_all_filtering <- FALSE  # <<CFG:skip_all_filtering>>

# ------------------------------------------------------------------------------
# 4B. CELL QC FILTERING
# ------------------------------------------------------------------------------
apply_qc_filtering <- TRUE  # <<CFG:apply_qc_filtering>>
filter_by_min_features <- TRUE  # <<CFG:filter_by_min_features>>
filter_by_max_features <- TRUE  # <<CFG:filter_by_max_features>>
filter_by_percent_mt <- TRUE  # <<CFG:filter_by_percent_mt>>

# ------------------------------------------------------------------------------
# 4C. GENE FILTERING
# ------------------------------------------------------------------------------
filter_genes_by_min_cells <- TRUE  # <<CFG:filter_genes_by_min_cells>>

# ------------------------------------------------------------------------------
# 4D. DOUBLET FILTERING
# ------------------------------------------------------------------------------
filter_doublets <- TRUE  # <<CFG:filter_doublets>>
doublet_column <- "doublet_consensus"  # <<CFG:doublet_column>>
doublet_value_to_remove <- "Doublet"  # <<CFG:doublet_value_to_remove>>
use_doublet_vote_threshold <- FALSE  # <<CFG:use_doublet_vote_threshold>>
doublet_vote_column <- "doublet_votes"  # <<CFG:doublet_vote_column>>
doublet_vote_threshold <- 2  # <<CFG:doublet_vote_threshold>>

# ------------------------------------------------------------------------------
# 4E. HEMOGLOBIN FILTERING
# ------------------------------------------------------------------------------
filter_hemoglobin <- TRUE  # <<CFG:filter_hemoglobin>>
max_percent_hb <- 2  # <<CFG:max_percent_hb>>
hemoglobin_pattern <- "^HB[AB]-"  # <<CFG:hemoglobin_pattern>>

# ------------------------------------------------------------------------------
# 4F. QC THRESHOLDS
# ------------------------------------------------------------------------------
min_features <- 200  # <<CFG:min_features>>
max_features <- 10000  # <<CFG:max_features>>
max_percent_mt <- 25  # <<CFG:max_percent_mt>>
min_cells_per_gene <- 3  # <<CFG:min_cells_per_gene>>


# ==============================================================================
# SECTION 5: MAIN PARAMETERS LIST
# ==============================================================================
# Parameters are organized by pipeline module

params <- list(

  # ===========================================================================
  # PROJECT PATHS AND CONFIGURATION
  # ===========================================================================
  project_root = project_root,
  dataset_name = dataset_name,
  input_dir = input_dir,
  input_file_pattern = input_file_pattern,
  files_in_subdirectories = files_in_subdirectories,
  counts_layer_to_use = counts_layer_to_use,
  output_base_dir = output_base_dir,
  out_root = out_root,
  scripts_dir = scripts_dir,
  pipeline_scripts_dir = pipeline_scripts_dir,
  sample_sheet_path = sample_sheet_path,

  # Environment variables (for reference)
  env_preprocess_dir = env_preprocess_dir,
  env_downstream_dir = env_downstream_dir,

  # Legacy compatibility
  base_dir = output_base_dir,
  sccdc_input_dir = input_dir,

  # ===========================================================================
  # GROUP-BASED ANALYSIS (NEW GENERIC SYSTEM)
  # ===========================================================================
  group_id = group_id,
  group_label = group_label,
  analysis_label = analysis_label,

  # Ventricle analysis (backward compatible)
  ventricle_analysis = if (analysis_label != "") analysis_label else "All",
  ventricle_filter = ventricle_filter,

  # ===========================================================================
  # SAMPLE CONFIGURATION
  # ===========================================================================
  sample_metadata = sample_metadata,

  # ===========================================================================
  # COUNTS LAYER
  # ===========================================================================
  counts_layer = counts_layer_to_use,

  # ===========================================================================
  # MODULE 01: QC AND FILTERING PARAMETERS
  # ===========================================================================
  skip_all_filtering = skip_all_filtering,
  apply_qc_filtering = apply_qc_filtering,
  filter_by_min_features = filter_by_min_features,
  filter_by_max_features = filter_by_max_features,
  filter_by_percent_mt = filter_by_percent_mt,
  filter_genes_by_min_cells = filter_genes_by_min_cells,
  filter_doublets = filter_doublets,
  doublet_column = doublet_column,
  doublet_value_to_remove = doublet_value_to_remove,
  use_doublet_vote_threshold = use_doublet_vote_threshold,
  doublet_vote_column = doublet_vote_column,
  doublet_vote_threshold = doublet_vote_threshold,
  filter_hemoglobin = filter_hemoglobin,
  max_percent_hb = max_percent_hb,
  hemoglobin_pattern = hemoglobin_pattern,
  min_features = min_features,
  max_features = max_features,
  max_percent_mt = max_percent_mt,
  min_cells_per_gene = min_cells_per_gene,

  # ===========================================================================
  # MODULE 02b & 03b: IMPUTATION PARAMETERS
  # ===========================================================================
  # Two imputation methods are available:
  #
  # 1. afMF (Module 02b): Counts-based imputation BEFORE normalization
  #    - Uses Low-rank Full Matrix Factorization
  #    - Works on raw counts
  #    - Output: "imputed" assay
  #
  # 2. ALRA (Module 03b): Normalized-data imputation AFTER normalization
  #    - Uses Adaptively-thresholded Low Rank Approximation
  #    - Works on log-normalized data (LogNormalize or scran only)
  #    - Output: "ALRA" assay
  #    - AUTOMATICALLY SKIPPED if SCTransform wins benchmarking
  #
  # IMPUTATION METHOD SELECTION:
  #   "none"  - No imputation
  #   "afmf"  - Only afMF (Module 02b)
  #   "alra"  - Only ALRA (Module 03b, if compatible normalization)
  #   "both"  - Both methods (DEFAULT)
  # ===========================================================================

  imputation_method = "both",  # Options: "none", "afmf", "alra", "both"  # <<CFG:imputation_method>>

  # ---------------------------------------------------------------------------
  # afMF Parameters (Module 02b - counts-based)
  # ---------------------------------------------------------------------------
  # afMF: Low-rank Full Matrix Factorization for dropout imputation
  # Reference: https://github.com/GO3295/SCImputation
  #
  # afMF runs on RAW COUNTS before normalization.
  # The imputed object is created when imputation_method = "afmf" or "both".
  # use_afmf_for_normalization controls which counts Module 03 uses.
  # ---------------------------------------------------------------------------

  # Use afMF-imputed counts for normalization in Module 03?
  # FALSE = use original scCDC counts (DEFAULT, recommended for DE)
  # TRUE = use afMF-imputed counts
  use_afmf_for_normalization = FALSE,  # <<CFG:use_afmf_for_normalization>>

  # Python environment for afMF (dedicated conda env)
  afmf_python = file.path(Sys.getenv("HOME"), ".conda/envs/afMF_SCImputation_env/bin/python"),  # <<CFG:afmf_python>>

  # afMF algorithm parameters
  afmf_max_iter = 100,              # Maximum iterations for convergence  # <<CFG:afmf_max_iter>>
  afmf_tol = 1e-5,                  # Convergence tolerance  # <<CFG:afmf_tol>>
  afmf_min_cells_expressing = 10,   # Min cells expressing gene for imputation  # <<CFG:afmf_min_cells_expressing>>

  # ---------------------------------------------------------------------------
  # ALRA Parameters (Module 03b - normalized-data-based)
  # ---------------------------------------------------------------------------
  # ALRA: Adaptively-thresholded Low Rank Approximation
  # Reference: https://github.com/KlugerLab/ALRA
  #
  # ALRA runs on LOG-NORMALIZED DATA after Module 03.
  # ONLY compatible with LogNormalize and scran (NOT SCTransform).
  # If SCTransform wins normalization benchmarking, ALRA is automatically skipped.
  #
  # The ALRA-imputed data is stored in "ALRA" assay.
  # use_alra_for_downstream controls which data Module 04+ uses.
  # ---------------------------------------------------------------------------

  # Use ALRA-imputed data for downstream analysis (Module 04+)?
  # FALSE = use original normalized data (DEFAULT, recommended for DE)
  # TRUE = use ALRA-imputed data
  use_alra_for_downstream = FALSE,  # <<CFG:use_alra_for_downstream>>

  # ALRA algorithm parameters
  alra_k = NULL,                    # SVD rank (NULL = auto-detect via choose_k())  # <<CFG:alra_k>>
  alra_q = 10,                      # Number of power iterations for randomized SVD  # <<CFG:alra_q>>
  alra_quantile_prob = 0.001,       # Quantile probability for thresholding  # <<CFG:alra_quantile_prob>>

  # ALRA normalization compatibility
  # ALRA only works with these normalization methods (NOT SCTransform):
  alra_compatible_methods = c("LogNormalize", "scran"),  # <<CFG:alra_compatible_methods>>

  # ===========================================================================
  # BACKWARD COMPATIBILITY - Deprecated parameters (DO NOT USE)
  # ===========================================================================
  # These are kept for backward compatibility but should not be used.
  # Use imputation_method instead.
  run_imputation = NULL,            # Deprecated: use imputation_method
  use_imputed_counts = NULL,        # Deprecated: use use_afmf_for_normalization

  # ===========================================================================
  # MODULE 03: NORMALIZATION PARAMETERS
  # ===========================================================================
  run_sctransform = TRUE,  # <<CFG:run_sctransform>>
  run_scran = TRUE,  # <<CFG:run_scran>>
  run_lognorm = TRUE,  # <<CFG:run_lognorm>>
  run_sckwarn = TRUE,  # <<CFG:run_sckwarn>>
  integration_normalization_method = "auto",  # <<CFG:integration_normalization_method>>
  sct_vars_to_regress = c("percent.mt"),  # <<CFG:sct_vars_to_regress>>
  sct_method = "glmGamPoi",  # <<CFG:sct_method>>
  scran_min_mean = 0.1,  # <<CFG:scran_min_mean>>
  run_normalization_benchmarking = TRUE,  # <<CFG:run_normalization_benchmarking>>
  norm_benchmark_max_cells = 5000,  # <<CFG:norm_benchmark_max_cells>>

  # ---------------------------------------------------------------------------
  # Normalization Benchmarking Integration Methods (NEW 2026-02-05)
  # ---------------------------------------------------------------------------
  # Which integration methods to use when benchmarking normalizations in Module 03.
  # Each normalization is tested with each integration method, then the best
  # normalization is selected by majority vote across integration methods.
  #
  # With only 1 method, majority vote cannot activate and the pipeline falls
  # back to a simple composite score. Use 2+ methods for proper voting.
  #
  # Available options (must also be installed):
  #   "harmony"  - Harmony (R package)
  #   "mnn"      - FastMNN via batchelor + SeuratWrappers (R packages)
  #   "scvi"     - scVI (Python, requires scvi-tools)
  #   "sccobra"  - scCobra (Python)
  #   "concord"  - Concord (Python)
  #
  # Default: c("harmony", "mnn") - enables majority vote with two R-based methods
  # ---------------------------------------------------------------------------
  norm_benchmark_integration_methods = c("harmony", "mnn", "scvi", "sccobra", "concord"),  # <<CFG:norm_benchmark_integration_methods>>

  # ===========================================================================
  # MODULE 04: INTEGRATION PARAMETERS
  # ===========================================================================
  run_batch_integration = TRUE,  # <<CFG:run_batch_integration>>
  batch_variable = "sample_name",      # Instead of "batch",  # <<CFG:batch_variable>>
  vars_to_regress = c("percent.mt"),  # <<CFG:vars_to_regress>>

  # ---------------------------------------------------------------------------
  # Integration Method Selection Mode
  # ---------------------------------------------------------------------------
  # This controls HOW the best integration method is selected from benchmarking.
  #
  # Options:
  #   "batch_removal"  - Minimizes batch_variance (most aggressive correction)
  #                      Criterion: which.min(batch_variance)
  #                      Use when: Batches are TECHNICAL replicates only
  #                      (same biology, different processing)
  #                      Example: Same cell line processed on different days
  #                      WARNING: May remove real biological signal!
  #
  #   "balanced"       - Maximizes composite score across ALL batch metrics
  #                      Criterion: which.max(mean(batch_var_norm, asw_norm, lisi_norm))
  #                      Use when: Batches have BIOLOGICAL meaning
  #                      (different conditions, sexes, timepoints, treatments)
  #                      Example: Male vs Female, Treatment vs Control
  #                      >>> RECOMMENDED FOR MOST BIOLOGICAL STUDIES <<<
  #
  #   "conservative"   - Prioritizes LISI score (moderate mixing)
  #                      Criterion: which.max(lisi_norm)
  #                      Use when: Preserving subtle biological differences is critical
  #                      Example: Rare cell types, subtle disease phenotypes
  #
  # For your Male vs Female choroid plexus comparison, use "balanced"!
  # ---------------------------------------------------------------------------
  integration_selection_mode = "balanced",  # <<CFG:integration_selection_mode>>
  celltype_column = "cluster_name_MapMyCells",  # <<CFG:celltype_column>>
  
  # ---------------------------------------------------------------------------
  # Biological vs Batch Weight for Composite Scoring
  # ---------------------------------------------------------------------------
  # Controls the relative importance of biological conservation vs batch
  # correction in the scIB-style composite score used for method selection.
  #
  # Default: 0.4 bio + 0.6 batch (scIB paper recommendation)
  #
  # Applied in both Module 03 (normalization) and Module 04 (integration).
  # ---------------------------------------------------------------------------
  bio_weight = 0.4,   # <<CFG:bio_weight>>
  batch_weight = 0.6,  # <<CFG:batch_weight>>

  # Integration method settings
  nfeatures_integration = 3000,  # <<CFG:nfeatures_integration>>
  dims_use = 30,  # <<CFG:dims_use>>
  integration_methods_r = c("harmony", "cca", "rpca"),  # <<CFG:integration_methods_r>>
  run_integration_benchmarking = TRUE,  # <<CFG:run_integration_benchmarking>>

  # ===========================================================================
  # MODULE 04: PYTHON INTEGRATION METHODS
  # ===========================================================================
  unified_python = "/scicore/home/doetsch/kaiser0001/miniforge3/envs/kaiser_test_py3.11/bin/python",  # <<CFG:unified_python>>
  run_python_integrations = TRUE,  # <<CFG:run_python_integrations>>
  integration_methods_python = c("scvi", "scanorama", "bbknn"),  # <<CFG:integration_methods_python>>

  # ===========================================================================
  # MODULE 04b: CONCORD PARAMETERS (Nature Biotechnology 2025)
  # ===========================================================================
  run_concord = TRUE,  # <<CFG:run_concord>>
  concord_n_top_features = 2000,  # <<CFG:concord_n_top_features>>
  concord_n_latent = 30,  # <<CFG:concord_n_latent>>
  concord_max_epochs = 200,  # <<CFG:concord_max_epochs>>
  concord_batch_size = 256,  # <<CFG:concord_batch_size>>
  concord_lr = 1e-3,  # <<CFG:concord_lr>>
  concord_early_stopping_patience = 15,  # <<CFG:concord_early_stopping_patience>>
  concord_preload_dense = TRUE,  # <<CFG:concord_preload_dense>>
  concord_device = "auto",  # <<CFG:concord_device>>

  # ===========================================================================
  # MODULE 05: CHOIR CLUSTERING PARAMETERS
  # ===========================================================================
  run_choir_clustering = TRUE,  # <<CFG:run_choir_clustering>>
  choir_alpha = 0.05,  # <<CFG:choir_alpha>>
  choir_use_assay = "RNA",  # <<CFG:choir_use_assay>>

  # ===========================================================================
  # MODULE 05: scAURA CLUSTERING PARAMETERS
  # ===========================================================================
  # scAURA: Graph debiased contrastive learning for unsupervised cell type discovery
  # Reference: https://github.com/bozdaglab/scAURA
  #
  # scAURA runs alongside CHOIR in Module 05. Both methods can be enabled

  # independently. Use scice_clustering_source to select which feeds into
  # downstream analysis (Module 06 scICE subclustering).
  # ===========================================================================

  run_scaura_clustering = TRUE,  # <<CFG:run_scaura_clustering>>

  # Python environment for scAURA
  scaura_python = "/scicore/home/doetsch/kaiser0001/miniforge3/envs/kaiser_test_py3.11/bin/python",  # <<CFG:scaura_python>>

  # scAURA repository path
  scaura_repo_path = "/scicore/home/doetsch/kaiser0001/GITHUB_repositories/scAURA",  # <<CFG:scaura_repo_path>>

  # Number of clusters (K_CLUSTERS in scAURA)
  scaura_k_clusters = 7,  # <<CFG:scaura_k_clusters>>

  # Adaptive k-NN parameters
  scaura_kmax = 40,  # <<CFG:scaura_kmax>>

  # GCN architecture
  scaura_hidden_dim = 64,  # <<CFG:scaura_hidden_dim>>

  # Contrastive learning parameters
  scaura_tau = 0.7,  # <<CFG:scaura_tau>>
  scaura_tau_plus = 0.1,  # <<CFG:scaura_tau_plus>>
  scaura_pe = 0.3,  # <<CFG:scaura_pe>>
  scaura_pf = 0.3,  # <<CFG:scaura_pf>>

  # Training parameters
  scaura_epochs = 100,  # <<CFG:scaura_epochs>>
  scaura_lr = 1e-3,  # <<CFG:scaura_lr>>

  # Self-supervised refinement (SSC)
  scaura_self_train = TRUE,  # <<CFG:scaura_self_train>>

  # Input: number of top HVGs to use
  scaura_n_top_genes = 2000,  # <<CFG:scaura_n_top_genes>>

  # Use GPU if available
  scaura_use_gpu = TRUE,  # <<CFG:scaura_use_gpu>>

  # ===========================================================================
  # CLUSTERING SOURCE SELECTION FOR DOWNSTREAM ANALYSIS
  # ===========================================================================
  # Controls which clustering method is used for scICE subclustering (Module 06)
  # and as the primary "seurat_clusters" identity.
  #
  # Options:
  #   "choir"  - Use CHOIR clusters (default if CHOIR succeeds)
  #   "scaura" - Use scAURA clusters
  #   "auto"   - Automatically select: CHOIR > scAURA > none
  #   "both"   - subcluster BOTH CHOIR and scAURA independently
  #              Creates suffixed columns: scice_subcluster_choir, scice_subcluster_scaura, etc.
  #              Also creates unsuffixed columns from primary source for backward compat
  # ===========================================================================
  scice_clustering_source = "auto",  # <<CFG:scice_clustering_source>>

  # ===========================================================================
  # MODULE 05b: scCobra PARAMETERS
  # ===========================================================================
  run_sccobra = TRUE,  # <<CFG:run_sccobra>>

  # ===========================================================================
  # MODULE 06: scICE SUBCLUSTERING PARAMETERS
  # ===========================================================================
  run_scice_subclustering = TRUE,  # <<CFG:run_scice_subclustering>>
  scice_target_clusters = NULL,  # <<CFG:scice_target_clusters>>
  scice_k_min = 2,  # <<CFG:scice_k_min>>
  scice_k_max = 15,  # <<CFG:scice_k_max>>
  scice_ic_threshold = 1.005,  # <<CFG:scice_ic_threshold>>
  scice_min_cells = 100,  # <<CFG:scice_min_cells>>
  julia_bin = file.path(Sys.getenv("HOME"), "julia", "bin", "julia"),  # <<CFG:julia_bin>>
  scice_env = file.path(Sys.getenv("HOME"), "julia", "julia_envs", "scICE_env"),  # <<CFG:scice_env>>
  scice_pkg_dir = file.path(Sys.getenv("HOME"), "julia", "julia_envs", "scICE_env", "scICE"),  # <<CFG:scice_pkg_dir>>

  # ===========================================================================
  # MODULE 06: IDclust SUBCLUSTERING PARAMETERS
  # ===========================================================================
  # IDclust: Iterative Differential Clustering
  # Reference: Prompsy et al., NAR Genomics and Bioinformatics, 2024
  #
  # IDclust recursively splits clusters, validating each split with

  # differential expression testing. Only biologically meaningful splits
  # (with sufficient DEGs) are retained.
  #
  # Can run alongside or instead of scICE subclustering.
  # Install with: devtools::install_github("vallotlab/IDclust")
  # ===========================================================================

  run_idclust_subclustering = TRUE,  # <<CFG:run_idclust_subclustering>>
  idclust_target_clusters = NULL,      # NULL = all clusters meeting min_cells  # <<CFG:idclust_target_clusters>>
  idclust_logFC_th = log2(1.5),        # Log2 fold-change threshold for DE validation  # <<CFG:idclust_logFC_th>>
  idclust_qval_th = 0.01,             # Adjusted p-value threshold  # <<CFG:idclust_qval_th>>
  idclust_min_DEGs = 5,               # Minimum DEGs required to validate a split  # <<CFG:idclust_min_DEGs>>
  idclust_max_depth = 10,             # Maximum recursion depth  # <<CFG:idclust_max_depth>>
  idclust_min_frac_assigned = 0.1,    # Minimum fraction of cells assigned  # <<CFG:idclust_min_frac_assigned>>
  idclust_n_dims = 50,                # PCA dimensions for subclustering  # <<CFG:idclust_n_dims>>
  idclust_starting_resolution = 0.1,  # Initial Louvain resolution  # <<CFG:idclust_starting_resolution>>
  idclust_resolution = 0.8,           # Subsequent resolution  # <<CFG:idclust_resolution>>
  idclust_starting_k = 100,           # Initial k-nearest neighbors  # <<CFG:idclust_starting_k>>
  idclust_k = 100,                    # Subsequent k neighbors  # <<CFG:idclust_k>>
  idclust_min_cells = 100,            # Minimum cells per cluster to subcluster  # <<CFG:idclust_min_cells>>
  idclust_plotting = TRUE,            # Generate IDclust internal plots  # <<CFG:idclust_plotting>>

  # ===========================================================================
  # UNIFIED SUBCLUSTERING CONTROL (Module 06)
  # ===========================================================================
  # Controls which subclustering methods run and their input source.
  #
  # subclustering_methods: character vector of methods to run
  #   c("scice", "idclust") - run both (default)
  #   c("scice")            - only scICE
  #   c("idclust")          - only IDclust
  #
  # subclustering_source: which primary clustering to subcluster
  #   "auto"   - auto-detect from Module 05 (default)
  #   "choir"  - use CHOIR clusters
  #   "scaura" - use scAURA clusters
  # ===========================================================================
  subclustering_methods = c("scice", "idclust"),  # <<CFG:subclustering_methods>>
  subclustering_source = "both",  # <<CFG:subclustering_source>>

  # ===========================================================================
  # MODULE 07: LEIDEN CLUSTERING PARAMETERS
  # ===========================================================================
  run_leiden_clustering = TRUE,  # <<CFG:run_leiden_clustering>>
  leiden_resolutions = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.0),  # <<CFG:leiden_resolutions>>
  leiden_algorithm = 4,  # <<CFG:leiden_algorithm>>
  leiden_n_neighbors = 20,  # <<CFG:leiden_n_neighbors>>
  final_resolution = 0.5,  # <<CFG:final_resolution>>
  run_clustering_quality = TRUE,  # <<CFG:run_clustering_quality>>

  # ===========================================================================
  # MODULE 07b: CLTS RE-NORMALIZATION PARAMETERS
  # ===========================================================================
  # CLTS (Count based on Linearized Transcriptome Size) preserves biological
  # transcriptome size variation across cell types while correcting technical
  # sequencing depth differences between samples.
  #
  # Module 07b can run after Module 06 (scICE) or Module 07 (Leiden)
  #
  # Reference: Lu et al., Nature Communications 2025
  # DOI: 10.1038/s41467-025-56623-1
  # ===========================================================================

  run_clts_renormalization = TRUE,  # <<CFG:run_clts_renormalization>>

  # ---------------------------------------------------------------------------
  # CLTS CLUSTERING SOURCE - Which clustering to use for CLTS normalization
  # ---------------------------------------------------------------------------
  # Options:
  #   "scice"  - Apply CLTS using scICE subclusters (DEFAULT)
  #   "leiden" - Apply CLTS using Leiden clusters
  #   "choir"  - Apply CLTS using CHOIR clusters
  #   "both"   - Apply CLTS to BOTH scICE and Leiden (creates two _redeconv objects)
  #   "all"    - Apply CLTS to scICE, Leiden, AND CHOIR
  #
  # Output files generated:
  #   "scice"  -> scice_subclustered_object_redeconv.rds
  #   "leiden" -> leiden_clustered_object_redeconv.rds
  #   "choir"  -> choir_clustered_object_redeconv.rds
  #   "both"   -> scice + leiden _redeconv.rds files
  #   "all"    -> all three _redeconv.rds files
  # ---------------------------------------------------------------------------
  clts_clustering_source = "scice",  # <<CFG:clts_clustering_source>>

  # Which cluster column to use (auto-detected if NULL)
  clts_cluster_column = NULL,  # <<CFG:clts_cluster_column>>

  # Minimum cells per cluster to include in regression
  clts_min_cells_per_cluster = 50,  # <<CFG:clts_min_cells_per_cluster>>

  # Baseline sample selection: "auto" (highest correlation) or specific sample name
  clts_baseline_sample = "auto",  # <<CFG:clts_baseline_sample>>

  # Marker detection thresholds for benchmark comparison
  clts_marker_logfc_threshold = 0.5,  # <<CFG:clts_marker_logfc_threshold>>
  clts_marker_pval_threshold = 0.05,  # <<CFG:clts_marker_pval_threshold>>
  clts_marker_min_pct = 0.25,  # <<CFG:clts_marker_min_pct>>

  # Run marker benchmark comparing original vs CLTS normalization
  clts_run_benchmark = TRUE,  # <<CFG:clts_run_benchmark>>

  # ===========================================================================
  # MODULE 08: DIFFERENTIAL EXPRESSION PARAMETERS
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # DE OBJECT SOURCES - Which objects to run DE analysis on
  # ---------------------------------------------------------------------------
  # This is a CHARACTER VECTOR - you can specify multiple objects to run
  # DE analysis on in parallel. Results will be saved in separate subdirectories.
  #
  # Valid options (can combine multiple):
  #   "scice"          - Standard scICE subclustered object
  #   "scice_redeconv" - CLTS-normalized scICE object
  #   "leiden"         - Standard Leiden clustered object
  #   "leiden_redeconv"- CLTS-normalized Leiden object
  #   "choir"          - Standard CHOIR clustered object
  #   "choir_redeconv" - CLTS-normalized CHOIR object
  #
  # DEFAULT: Run DE on both standard scICE and CLTS-normalized scICE
  #
  # Examples:
  #   c("scice", "scice_redeconv")           - Compare standard vs CLTS on scICE
  #   c("leiden", "leiden_redeconv")         - Compare standard vs CLTS on Leiden
  #   c("scice", "scice_redeconv", "leiden") - Three parallel analyses
  #   c("scice_redeconv")                    - Only CLTS-normalized scICE
  # ---------------------------------------------------------------------------
  de_object_sources = c("scice", "scice_redeconv"),  # <<CFG:de_object_sources>>

  # Cross-object comparison (when multiple de_object_sources specified)
  de_run_cross_object_comparison = TRUE,  # <<CFG:de_run_cross_object_comparison>>

  # Comparison settings
  de_comparison_variable = "sex",  # <<CFG:de_comparison_variable>>
  de_group1 = "Male",  # <<CFG:de_group1>>
  de_group2 = "Female",  # <<CFG:de_group2>>
  de_comparison_scope = "whole_dataset",  # <<CFG:de_comparison_scope>>
  de_target_clusters = NULL,  # <<CFG:de_target_clusters>>
  de_covariates = c("percent.mt", "nFeature_RNA", "batch"),  # <<CFG:de_covariates>>

  # DE method flags
  run_mast = TRUE,  # <<CFG:run_mast>>
  run_dream = TRUE,  # <<CFG:run_dream>>
  run_pseudobulk_edger = TRUE,  # <<CFG:run_pseudobulk_edger>>
  run_pseudobulk_deseq2 = TRUE,  # <<CFG:run_pseudobulk_deseq2>>
  run_permutation = TRUE,  # <<CFG:run_permutation>>
  run_negative_control = TRUE,  # <<CFG:run_negative_control>>

  # DE thresholds
  de_logfc_threshold = 0.5,  # <<CFG:de_logfc_threshold>>
  de_pval_threshold = 0.05,  # <<CFG:de_pval_threshold>>
  de_min_pct = 0.1,  # <<CFG:de_min_pct>>

  # ===========================================================================
  # MODULE 09: VISUALIZATION AND GENES OF INTEREST
  # ===========================================================================
  sex_marker_genes = c("Xist", "Tsix", "Ddx3y", "Eif2s3y", "Kdm5d", "Uty"),  # <<CFG:sex_marker_genes>>
  cp_marker_genes = c("Ttr", "Folr1", "Aqp1", "Cldn1", "Otx2", "Enpp2"),  # <<CFG:cp_marker_genes>>
  fibroblast_markers = c("Col1a1", "Col1a2", "Col3a1", "Dcn", "Lum", "Pdgfra", "Vim"),  # <<CFG:fibroblast_markers>>
  genes_of_interest = c("Xist", "Tsix", "Ddx3y", "Eif2s3y", "Kdm5d", "Uty",
                        "Ttr", "Folr1", "Aqp1", "Cldn1", "Otx2",
                        "Col1a1", "Col3a1", "Dcn", "Pdgfra"),  # <<CFG:genes_of_interest>>

  # ===========================================================================
  # PLOT SETTINGS
  # ===========================================================================
  plot_formats = c("png", "pdf"),  # <<CFG:plot_formats>>
  plot_width_in = 7,  # <<CFG:plot_width_in>>
  plot_height_in = 5,  # <<CFG:plot_height_in>>
  plot_dpi = 300,  # <<CFG:plot_dpi>>
  tiff_compression = "lzw",  # <<CFG:tiff_compression>>

  # ===========================================================================
  # MISC SETTINGS
  # ===========================================================================
  max_cells_plot = 50000,  # <<CFG:max_cells_plot>>
  random_seed = 42  # <<CFG:random_seed>>
)


# ==============================================================================
# SECTION 6: DERIVE SAMPLES TO ANALYZE
# ==============================================================================
# Note: get_samples_to_analyze() function is now in functions.R

samples_to_analyze <- get_samples_to_analyze(params)
params$samples_to_analyze <- samples_to_analyze

params$analysis_metadata <- params$sample_metadata[
  params$sample_metadata$sample_name %in% samples_to_analyze,
]


# ==============================================================================
# SECTION 7: GENERATE INPUT FILE PATHS
# ==============================================================================
# Note: get_input_paths() function is now in functions.R

params$input_paths <- get_input_paths(params)


# ==============================================================================
# SECTION 8: PARAMETER VALIDATION
# ==============================================================================
# Note: validate_params() function is now in functions.R
# Additional validation for new parameters

# Validate CLTS and DE parameters
validate_clts_de_params <- function(params) {
  # Validate clts_clustering_source
  valid_clts_sources <- c("scice", "leiden", "choir", "both", "all")
  if (!params$clts_clustering_source %in% valid_clts_sources) {
    cat("  WARNING: Invalid clts_clustering_source '", params$clts_clustering_source,
        "'. Setting to 'scice'.\n", sep = "")
    params$clts_clustering_source <- "scice"
  }

  # Validate de_object_sources
  valid_de_sources <- c("scice", "scice_redeconv", "leiden", "leiden_redeconv",
                        "choir", "choir_redeconv")
  invalid_sources <- setdiff(params$de_object_sources, valid_de_sources)
  if (length(invalid_sources) > 0) {
    cat("  WARNING: Invalid de_object_sources: ", paste(invalid_sources, collapse = ", "),
        ". Removing.\n", sep = "")
    params$de_object_sources <- intersect(params$de_object_sources, valid_de_sources)
  }

  if (length(params$de_object_sources) == 0) {
    cat("  WARNING: No valid de_object_sources. Setting to 'scice'.\n")
    params$de_object_sources <- "scice"
  }

  # Warn about redeconv sources that may not be available
  clts_source <- params$clts_clustering_source
  de_sources <- params$de_object_sources

  if ("scice_redeconv" %in% de_sources && !clts_source %in% c("scice", "both", "all")) {
    cat("  NOTE: 'scice_redeconv' requested for DE but clts_clustering_source='",
        clts_source, "'.\n", sep = "")
    cat("        scice_subclustered_object_redeconv.rds may not be generated.\n")
  }
  if ("leiden_redeconv" %in% de_sources && !clts_source %in% c("leiden", "both", "all")) {
    cat("  NOTE: 'leiden_redeconv' requested for DE but clts_clustering_source='",
        clts_source, "'.\n", sep = "")
    cat("        leiden_clustered_object_redeconv.rds may not be generated.\n")
  }
  if ("choir_redeconv" %in% de_sources && !clts_source %in% c("choir", "all")) {
    cat("  NOTE: 'choir_redeconv' requested for DE but clts_clustering_source='",
        clts_source, "'.\n", sep = "")
    cat("        choir_clustered_object_redeconv.rds may not be generated.\n")
  }

  return(params)
}

# Validate imputation parameters
validate_imputation_params <- function(params) {
  # Validate imputation_method
  valid_methods <- c("none", "afmf", "alra", "both")
  if (is.null(params$imputation_method) || !params$imputation_method %in% valid_methods) {
    cat("  WARNING: Invalid imputation_method. Setting to 'both'.\n")
    params$imputation_method <- "both"
  }

  # Handle backward compatibility for deprecated parameters
  if (!is.null(params$run_imputation) && is.null(params$imputation_method)) {
    if (isTRUE(params$run_imputation)) {
      params$imputation_method <- "afmf"
      cat("  NOTE: Migrated deprecated run_imputation=TRUE to imputation_method='afmf'\n")
    }
  }

  # Check afMF Python path if afMF is enabled
  if (params$imputation_method %in% c("afmf", "both")) {
    if (!file.exists(params$afmf_python)) {
      cat("  WARNING: afMF Python not found at:", params$afmf_python, "\n")
      cat("           Run setup_afMF_env.sh to create the environment.\n")
      cat("           afMF imputation will be skipped if environment is not available.\n")
    }
  }

  # Validate afMF parameters
  if (is.null(params$afmf_max_iter) || params$afmf_max_iter < 1) {
    params$afmf_max_iter <- 100
  }
  if (is.null(params$afmf_tol) || params$afmf_tol <= 0) {
    params$afmf_tol <- 1e-5
  }
  if (is.null(params$afmf_min_cells_expressing) || params$afmf_min_cells_expressing < 1) {
    params$afmf_min_cells_expressing <- 10
  }

  # Validate ALRA parameters
  if (!is.null(params$alra_k) && (!is.numeric(params$alra_k) || params$alra_k < 1)) {
    cat("  WARNING: Invalid alra_k. Setting to NULL (auto-detect).\n")
    params$alra_k <- NULL
  }
  if (is.null(params$alra_q) || params$alra_q < 1) {
    params$alra_q <- 10
  }
  if (is.null(params$alra_quantile_prob) || params$alra_quantile_prob <= 0 || params$alra_quantile_prob >= 1) {
    params$alra_quantile_prob <- 0.001
  }

  # Ensure ALRA compatible methods is set
  if (is.null(params$alra_compatible_methods)) {
    params$alra_compatible_methods <- c("LogNormalize", "scran")
  }

  return(params)
}

params <- validate_params(params)
params <- validate_clts_de_params(params)
params <- validate_imputation_params(params)


# ==============================================================================
# SECTION 9: CONFIGURATION SUMMARY
# ==============================================================================

cat("================================================================================\n")
cat("PIPELINE CONFIGURATION SUMMARY\n")
cat("================================================================================\n\n")

cat("Project root:", params$project_root, "\n")
cat("Dataset name:", params$dataset_name, "\n")

# Show group or ventricle analysis scope
if (params$group_label != "") {
  cat("Analysis scope: Group", params$group_id, "(", params$group_label, ")\n")
} else if (params$ventricle_filter != "") {
  cat("Analysis scope: Ventricle", params$ventricle_filter, "\n")
} else {
  cat("Analysis scope: All samples\n")
}

cat("Sample sheet:", params$sample_sheet_path, "\n")

cat("\nSamples to analyze (", length(params$samples_to_analyze), "):\n", sep = "")
for (s in params$samples_to_analyze) {
  meta <- params$sample_metadata[params$sample_metadata$sample_name == s, ]
  vent <- if ("ventricle" %in% colnames(meta)) meta$ventricle else "-"
  grp <- if ("group_id" %in% colnames(meta) && !is.na(meta$group_id)) paste0("G", meta$group_id) else "-"
  cat("  ", s, " (", meta$sex, ", ", meta$batch, ", ", vent, ", ", grp, ")\n", sep = "")
}

cat("\nInput:", params$input_dir, "\n")
cat("Output:", params$out_root, "\n")

cat("\n--- Imputation Settings ---\n")
cat("  imputation_method:", params$imputation_method, "\n")
if (params$imputation_method %in% c("afmf", "both")) {
  cat("  afMF (Module 02b): ENABLED\n")
  cat("    use_afmf_for_normalization:", params$use_afmf_for_normalization, "\n")
} else {
  cat("  afMF (Module 02b): DISABLED\n")
}
if (params$imputation_method %in% c("alra", "both")) {
  cat("  ALRA (Module 03b): ENABLED (if scran or LogNormalize selected)\n")
  cat("    use_alra_for_downstream:", params$use_alra_for_downstream, "\n")
  cat("    NOTE: ALRA auto-skips if SCTransform wins benchmarking\n")
} else {
  cat("  ALRA (Module 03b): DISABLED\n")
}

cat("\n--- Module 03: Normalization ---\n")
cat("  run_sctransform:", params$run_sctransform, "\n")
cat("  run_scran:", params$run_scran, "\n")
cat("  run_lognorm:", params$run_lognorm, "\n")
cat("  run_sckwarn:", params$run_sckwarn, "\n")
cat("  norm_benchmark_max_cells:",
    if (is.null(params$norm_benchmark_max_cells)) "ALL" else params$norm_benchmark_max_cells, "\n")
cat("  norm_benchmark_integration_methods:",
    paste(params$norm_benchmark_integration_methods, collapse = ", "), "\n")

cat("\n--- Module 04: Integration ---\n")
cat("  Integration selection mode:", params$integration_selection_mode, "\n")
cat("  Batch variable:", params$batch_variable, "\n")
cat("  run_concord:", params$run_concord, "\n")

cat("\n--- Module 05-07: Clustering ---\n")
cat("  run_choir_clustering:", params$run_choir_clustering, "\n")
cat("  run_sccobra:", params$run_sccobra, "\n")
cat("  run_scice_subclustering:", params$run_scice_subclustering, "\n")
cat("  run_idclust_subclustering:", params$run_idclust_subclustering, "\n")
cat("  subclustering_methods:", paste(params$subclustering_methods, collapse = ", "), "\n")
cat("  subclustering_source:", params$subclustering_source, "\n")
cat("  run_leiden_clustering:", params$run_leiden_clustering, "\n")

cat("\n--- Module 07b: CLTS Re-normalization ---\n")
cat("  run_clts_renormalization:", params$run_clts_renormalization, "\n")
cat("  clts_clustering_source:", params$clts_clustering_source, "\n")
cat("  clts_min_cells_per_cluster:", params$clts_min_cells_per_cluster, "\n")
cat("  clts_baseline_sample:", params$clts_baseline_sample, "\n")
cat("  clts_run_benchmark:", params$clts_run_benchmark, "\n")

cat("\n--- Module 08: Differential Expression ---\n")
cat("  de_object_sources:", paste(params$de_object_sources, collapse = ", "), "\n")
cat("  Comparison:", params$de_group1, "vs", params$de_group2, "\n")
cat("  run_mast:", params$run_mast, "\n")
cat("  run_dream:", params$run_dream, "\n")
cat("  run_pseudobulk_edger:", params$run_pseudobulk_edger, "\n")
cat("  run_pseudobulk_deseq2:", params$run_pseudobulk_deseq2, "\n")
cat("  run_permutation:", params$run_permutation, "\n")
cat("  de_run_cross_object_comparison:", params$de_run_cross_object_comparison, "\n")

cat("\n================================================================================\n")
</script>

<script>
// ================================================================
// APPLICATION STATE
// ================================================================
const AppState = {
  currentStep: 'a1',
  stepsOrder: ['a1','a2','a3','a4','a5','b0','b1','b2','b3','b4','b5','b6','b7','b8','b9'],

  // Sample sheet
  sampleSheet: {
    raw: null,
    headers: [],
    rows: [],
    columnRoles: {},
    detected: {
      batchEqualsCondition: false,
      sexImbalance: false,
      singleSampleGroups: [],
      batchColumn: null,
      conditionColumn: null,
    }
  },

  // Parameters
  params: {},
  paramApproved: {},
  paramsLoaded: false,
};

// ================================================================
// STEP NAVIGATION
// ================================================================
function goToStep(stepId) {
  const navItem = document.querySelector(`.nav-item[data-step="${stepId}"]`);
  if (navItem && navItem.classList.contains('locked')) return;

  document.querySelectorAll('.step-panel').forEach(p => p.classList.remove('active'));
  document.querySelectorAll('.nav-item').forEach(n => n.classList.remove('active'));

  const panel = document.getElementById(`step-${stepId}`);
  if (panel) panel.classList.add('active');
  if (navItem) navItem.classList.add('active');

  AppState.currentStep = stepId;
  updateProgress();

  // Trigger step-specific rendering
  if (stepId === 'a3') renderDesignAnalysis();
  if (stepId === 'a4') renderEditableTable();
  if (stepId === 'a5') renderExportValidation();
  if (stepId.startsWith('b') && stepId !== 'b0' && stepId !== 'b9') renderParamStep(stepId);
  if (stepId === 'b9') renderFinalReview();
}

function unlockStep(stepId) {
  const nav = document.querySelector(`.nav-item[data-step="${stepId}"]`);
  if (nav) nav.classList.remove('locked');
}

function completeStep(stepId) {
  const nav = document.querySelector(`.nav-item[data-step="${stepId}"]`);
  if (nav) nav.classList.add('completed');
}

function updateProgress() {
  const idx = AppState.stepsOrder.indexOf(AppState.currentStep);
  const pct = ((idx + 1) / AppState.stepsOrder.length * 100).toFixed(0);
  document.getElementById('progressFill').style.width = pct + '%';
  document.getElementById('progressLabel').textContent = `Step ${idx + 1} of ${AppState.stepsOrder.length}`;
}

// ================================================================
// CSV PARSING
// ================================================================
function parseCSV(text) {
  const lines = text.trim().split(/\r?\n/);
  if (lines.length < 2) throw new Error('CSV must have at least a header and one data row');

  const headers = parseCSVLine(lines[0]);
  const rows = [];
  for (let i = 1; i < lines.length; i++) {
    if (lines[i].trim() === '') continue;
    const values = parseCSVLine(lines[i]);
    const row = {};
    headers.forEach((h, j) => { row[h] = (values[j] || '').trim(); });
    rows.push(row);
  }
  return { headers, rows };
}

function parseCSVLine(line) {
  const result = [];
  let current = '';
  let inQuotes = false;
  for (let i = 0; i < line.length; i++) {
    const ch = line[i];
    if (inQuotes) {
      if (ch === '"' && line[i + 1] === '"') { current += '"'; i++; }
      else if (ch === '"') { inQuotes = false; }
      else { current += ch; }
    } else {
      if (ch === '"') { inQuotes = true; }
      else if (ch === ',') { result.push(current); current = ''; }
      else { current += ch; }
    }
  }
  result.push(current);
  return result;
}

function generateCSV(headers, rows) {
  const escapeField = v => {
    const s = String(v ?? '');
    return (s.includes(',') || s.includes('"') || s.includes('\n')) ? '"' + s.replace(/"/g, '""') + '"' : s;
  };
  const lines = [headers.map(escapeField).join(',')];
  rows.forEach(r => {
    lines.push(headers.map(h => escapeField(r[h])).join(','));
  });
  return lines.join('\n');
}

// ================================================================
// FILE HANDLING ‚Äî CSV
// ================================================================
const csvDropZone = document.getElementById('csvDropZone');
const csvFileInput = document.getElementById('csvFileInput');

csvDropZone.addEventListener('click', () => csvFileInput.click());
csvDropZone.addEventListener('dragover', e => { e.preventDefault(); csvDropZone.classList.add('dragover'); });
csvDropZone.addEventListener('dragleave', () => csvDropZone.classList.remove('dragover'));
csvDropZone.addEventListener('drop', e => {
  e.preventDefault(); csvDropZone.classList.remove('dragover');
  if (e.dataTransfer.files.length) handleCSVFile(e.dataTransfer.files[0]);
});
csvFileInput.addEventListener('change', e => { if (e.target.files.length) handleCSVFile(e.target.files[0]); });

function handleCSVFile(file) {
  const reader = new FileReader();
  reader.onload = e => {
    try {
      const { headers, rows } = parseCSV(e.target.result);
      AppState.sampleSheet.raw = e.target.result;
      AppState.sampleSheet.headers = headers;
      AppState.sampleSheet.rows = rows;
      autoDetectColumnRoles(headers, rows);
      renderCSVPreview(headers, rows);
      document.getElementById('csvPreviewArea').style.display = 'block';
      document.getElementById('btnToA2').classList.remove('disabled');
      unlockStep('a2');
      completeStep('a1');
    } catch (err) {
      alert('Error parsing CSV: ' + err.message);
    }
  };
  reader.readAsText(file);
}

function autoDetectColumnRoles(headers, rows) {
  const roles = {};
  const lowerHeaders = headers.map(h => h.toLowerCase());
  headers.forEach((h, i) => {
    const lh = lowerHeaders[i];
    if (['sample_name','sample_id','samplename','sampleid'].includes(lh)) roles[h] = 'sample_id';
    else if (['sex','gender'].includes(lh)) roles[h] = 'sex';
    else if (['batch','processing_batch','run'].includes(lh)) roles[h] = 'batch';
    else if (['condition','treatment','disease','group'].includes(lh)) roles[h] = 'condition';
    else if (['ventricle','region','area'].includes(lh)) roles[h] = 'ventricle';
    else if (['include','included'].includes(lh)) roles[h] = 'include';
    else if (['group_id','group'].includes(lh)) roles[h] = 'group_id';
    else roles[h] = 'custom';
  });
  AppState.sampleSheet.columnRoles = roles;
}

function renderCSVPreview(headers, rows) {
  const container = document.getElementById('csvPreviewTable');
  let html = '<table class="data-table"><thead><tr>';
  headers.forEach(h => { html += `<th>${esc(h)}</th>`; });
  html += '</tr></thead><tbody>';
  rows.forEach(r => {
    html += '<tr>';
    headers.forEach(h => { html += `<td>${esc(r[h])}</td>`; });
    html += '</tr>';
  });
  html += '</tbody></table>';
  container.innerHTML = html;
}

// ================================================================
// A2: COLUMN ROLES
// ================================================================
function renderColumnRoles() {
  const container = document.getElementById('columnRolesContainer');
  const { headers, rows, columnRoles } = AppState.sampleSheet;
  const roleOptions = [
    { value: 'sample_id', label: 'Sample ID (required)' },
    { value: 'sex', label: 'Sex (required)' },
    { value: 'batch', label: 'Batch (required)' },
    { value: 'condition', label: 'Condition' },
    { value: 'ventricle', label: 'Ventricle/Region' },
    { value: 'include', label: 'Include (TRUE/FALSE)' },
    { value: 'group_id', label: 'Group ID' },
    { value: 'custom', label: 'Custom Covariate' },
    { value: 'unused', label: 'Unused (ignore)' },
  ];

  let html = '';
  headers.forEach(h => {
    const uniqueVals = [...new Set(rows.map(r => r[h]))].slice(0, 8);
    const valsStr = uniqueVals.join(', ') + (uniqueVals.length >= 8 ? '‚Ä¶' : '');
    const currentRole = columnRoles[h] || 'custom';

    html += `<div class="column-role-card">
      <span class="col-name">${esc(h)}</span>
      <span class="col-values">Values: ${esc(valsStr)}</span>
      <select onchange="updateColumnRole('${esc(h)}', this.value)">
        ${roleOptions.map(o => `<option value="${o.value}" ${currentRole === o.value ? 'selected' : ''}>${o.label}</option>`).join('')}
      </select>
    </div>`;
  });
  container.innerHTML = html;
  unlockStep('a3');
}

function updateColumnRole(colName, role) {
  AppState.sampleSheet.columnRoles[colName] = role;
}

// Render column roles when step A2 is activated
const origGoToStep = goToStep;
goToStep = function(stepId) {
  origGoToStep(stepId);
  if (stepId === 'a2') renderColumnRoles();
};

// ================================================================
// A3: DESIGN ANALYSIS
// ================================================================
function renderDesignAnalysis() {
  const { headers, rows, columnRoles } = AppState.sampleSheet;
  const detected = AppState.sampleSheet.detected;
  let html = '';

  // Find key columns by role
  const batchCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'batch');
  const condCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'condition');
  const sexCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'sex');
  const sampleCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'sample_id');

  detected.batchColumn = batchCol;
  detected.conditionColumn = condCol;

  if (!batchCol || !sexCol || !sampleCol) {
    html += '<div class="alert alert-danger">Please assign Sample ID, Sex, and Batch roles in the previous step.</div>';
    document.getElementById('designAnalysisContent').innerHTML = html;
    return;
  }

  // Sample summary
  const nSamples = rows.length;
  const sexCounts = {};
  const batchCounts = {};
  rows.forEach(r => {
    const s = r[sexCol]; sexCounts[s] = (sexCounts[s] || 0) + 1;
    const b = r[batchCol]; batchCounts[b] = (batchCounts[b] || 0) + 1;
  });

  html += `<div class="card"><div class="card-header">üìä Sample Summary</div>
    <p style="font-size:0.9rem; color:var(--text-secondary);">
      <strong>${nSamples}</strong> samples across <strong>${Object.keys(batchCounts).length}</strong> batch(es)<br>
      Sex: ${Object.entries(sexCounts).map(([k,v]) => `${v} ${k}`).join(', ')}
    </p></div>`;

  // Cross-tabulation: Batch √ó Sex
  const batches = [...new Set(rows.map(r => r[batchCol]))].sort();
  const sexes = [...new Set(rows.map(r => r[sexCol]))].sort();

  html += `<div class="card"><div class="card-header">üîÄ Batch √ó Sex Distribution</div>
    <table class="crosstab"><thead><tr><th>Batch \\ Sex</th>`;
  sexes.forEach(s => { html += `<th>${esc(s)}</th>`; });
  html += `<th>Total</th></tr></thead><tbody>`;
  batches.forEach(b => {
    html += `<tr><td><strong>${esc(b)}</strong></td>`;
    let batchTotal = 0;
    sexes.forEach(s => {
      const count = rows.filter(r => r[batchCol] === b && r[sexCol] === s).length;
      batchTotal += count;
      const cls = count === 0 ? 'highlight' : '';
      html += `<td class="${cls}">${count}</td>`;
    });
    html += `<td><strong>${batchTotal}</strong></td></tr>`;
  });
  html += '</tbody></table></div>';

  // Batch √ó Condition (if condition exists)
  if (condCol) {
    const conditions = [...new Set(rows.map(r => r[condCol]))].sort();

    html += `<div class="card"><div class="card-header">üîÄ Batch √ó Condition Distribution</div>
      <table class="crosstab"><thead><tr><th>Batch \\ Condition</th>`;
    conditions.forEach(c => { html += `<th>${esc(c)}</th>`; });
    html += `</tr></thead><tbody>`;

    let batchCondMap = {};
    batches.forEach(b => {
      html += `<tr><td><strong>${esc(b)}</strong></td>`;
      const conditionsInBatch = new Set();
      conditions.forEach(c => {
        const count = rows.filter(r => r[batchCol] === b && r[condCol] === c).length;
        if (count > 0) conditionsInBatch.add(c);
        html += `<td>${count}</td>`;
      });
      batchCondMap[b] = conditionsInBatch;
      html += '</tr>';
    });
    html += '</tbody></table>';

    // Check confounding
    const batchCondPairs = batches.map(b => {
      return [...batchCondMap[b]].sort().join('+');
    });
    const allBatchesSingleCondition = Object.values(batchCondMap).every(s => s.size === 1);
    const allDifferent = new Set(batchCondPairs).size === batchCondPairs.length && allBatchesSingleCondition;

    if (allDifferent && batches.length > 1) {
      detected.batchEqualsCondition = true;
      html += `<div class="alert alert-danger" style="margin-top:12px;">
        <strong>‚ö† CRITICAL: Batch is perfectly confounded with Condition</strong><br>
        Each batch contains only one condition. Integrating by "batch" will remove the biological signal
        of your condition along with technical noise.<br><br>
        <strong>Recommendation:</strong> Use <code>batch_variable = "sample_name"</code> for integration instead of <code>"batch"</code>.
        This integrates per-sample, preserving more biological signal while still correcting per-sample technical variation.
      </div>`;
    } else {
      detected.batchEqualsCondition = false;
    }
    html += '</div>';
  }

  // Sex balance check
  const sexPerBatch = {};
  batches.forEach(b => {
    sexPerBatch[b] = {};
    sexes.forEach(s => {
      sexPerBatch[b][s] = rows.filter(r => r[batchCol] === b && r[sexCol] === s).length;
    });
  });

  const totalPerSex = {};
  sexes.forEach(s => { totalPerSex[s] = rows.filter(r => r[sexCol] === s).length; });
  const maxSex = Math.max(...Object.values(totalPerSex));
  const minSex = Math.min(...Object.values(totalPerSex));
  if (maxSex > minSex * 2) {
    detected.sexImbalance = true;
    html += `<div class="alert alert-warning">
      <strong>‚ö† Sex imbalance detected:</strong> ${Object.entries(totalPerSex).map(([k,v]) => `${k}: ${v}`).join(', ')}<br>
      This may reduce statistical power for sex-based differential expression. Consider this when interpreting results.
    </div>`;
  }

  // Integration recommendation
  html += `<div class="card"><div class="card-header">üí° Integration Recommendations</div>
    <p style="font-size:0.9rem; color:var(--text-secondary); line-height:1.6;">`;

  if (detected.batchEqualsCondition) {
    html += `Given the batch-condition confounding, we recommend:<br>
      ‚Ä¢ <code>batch_variable = "sample_name"</code> ‚Äî integrates each sample individually<br>
      ‚Ä¢ <code>integration_selection_mode = "balanced"</code> ‚Äî preserves biological signal<br>
      ‚Ä¢ Include <code>"condition"</code> in DE covariates to control for disease effects<br>
      ‚Ä¢ Prioritize <strong>DREAM</strong> for differential expression (handles small n better)`;
  } else {
    html += `Your design is not perfectly confounded. Standard integration by batch should work well:<br>
      ‚Ä¢ <code>batch_variable = "batch"</code> should be appropriate<br>
      ‚Ä¢ <code>integration_selection_mode = "balanced"</code> is recommended for most studies`;
  }
  html += '</p></div>';

  unlockStep('a4');
  completeStep('a3');
  document.getElementById('designAnalysisContent').innerHTML = html;
}

// ================================================================
// A4: EDITABLE TABLE
// ================================================================
function renderEditableTable() {
  const { headers, rows } = AppState.sampleSheet;
  const container = document.getElementById('editableTableContainer');

  let html = '<table class="data-table"><thead><tr>';
  headers.forEach(h => { html += `<th>${esc(h)}</th>`; });
  html += '</tr></thead><tbody>';
  rows.forEach((r, ri) => {
    html += '<tr>';
    headers.forEach(h => {
      html += `<td><input class="cell-edit" value="${esc(r[h])}" onchange="updateCell(${ri},'${esc(h)}',this.value)"></td>`;
    });
    html += '</tr>';
  });
  html += '</tbody></table>';
  container.innerHTML = html;

  // Validation
  const valHtml = validateSampleSheet();
  document.getElementById('sampleSheetValidation').innerHTML = valHtml;
  unlockStep('a5');
  completeStep('a4');
}

function updateCell(rowIdx, colName, value) {
  AppState.sampleSheet.rows[rowIdx][colName] = value;
  const valHtml = validateSampleSheet();
  document.getElementById('sampleSheetValidation').innerHTML = valHtml;
}

function validateSampleSheet() {
  const { headers, rows, columnRoles } = AppState.sampleSheet;
  const checks = [];

  const sampleCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'sample_id');
  const sexCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'sex');
  const batchCol = Object.keys(columnRoles).find(k => columnRoles[k] === 'batch');

  // Required columns assigned
  checks.push({ pass: !!sampleCol, msg: 'Sample ID column assigned', level: sampleCol ? 'pass' : 'fail' });
  checks.push({ pass: !!sexCol, msg: 'Sex column assigned', level: sexCol ? 'pass' : 'fail' });
  checks.push({ pass: !!batchCol, msg: 'Batch column assigned', level: batchCol ? 'pass' : 'fail' });

  // Unique sample names
  if (sampleCol) {
    const names = rows.map(r => r[sampleCol]);
    const unique = new Set(names).size === names.length;
    checks.push({ pass: unique, msg: 'Sample names are unique', level: unique ? 'pass' : 'fail' });
  }

  // Sex values valid
  if (sexCol) {
    const validSex = ['Male', 'Female', 'male', 'female', 'M', 'F', 'm', 'f'];
    const allValid = rows.every(r => validSex.includes(r[sexCol]));
    checks.push({ pass: allValid, msg: 'Sex values are valid (Male/Female)', level: allValid ? 'pass' : 'warn' });
  }

  // No empty required cells
  [sampleCol, sexCol, batchCol].filter(Boolean).forEach(col => {
    const noEmpty = rows.every(r => r[col] && r[col].trim() !== '');
    checks.push({ pass: noEmpty, msg: `No empty values in "${col}"`, level: noEmpty ? 'pass' : 'fail' });
  });

  // At least 2 samples
  checks.push({ pass: rows.length >= 2, msg: `At least 2 samples present (found ${rows.length})`, level: rows.length >= 2 ? 'pass' : 'fail' });

  const icons = { pass: '‚úÖ', warn: '‚ö†Ô∏è', fail: '‚ùå' };
  let html = '<ul class="validation-list">';
  checks.forEach(c => {
    html += `<li class="validation-item validation-${c.level}">
      <span class="validation-icon">${icons[c.level]}</span>
      <span>${c.msg}</span></li>`;
  });
  html += '</ul>';
  return html;
}

// ================================================================
// A5: EXPORT
// ================================================================
function renderExportValidation() {
  document.getElementById('exportValidationSummary').innerHTML = validateSampleSheet();
}

function downloadSampleSheet() {
  const { headers, rows } = AppState.sampleSheet;
  const csv = generateCSV(headers, rows);
  downloadFile(csv, 'sample_sheet.csv', 'text/csv');
  completeStep('a5');
  unlockStep('b0');
}

// ================================================================
// B0: LOAD / TEMPLATE params.R
// ================================================================
const paramsDropZone = document.getElementById('paramsDropZone');
const paramsFileInput = document.getElementById('paramsFileInput');

paramsDropZone.addEventListener('click', () => paramsFileInput.click());
paramsDropZone.addEventListener('dragover', e => { e.preventDefault(); paramsDropZone.classList.add('dragover'); });
paramsDropZone.addEventListener('dragleave', () => paramsDropZone.classList.remove('dragover'));
paramsDropZone.addEventListener('drop', e => {
  e.preventDefault(); paramsDropZone.classList.remove('dragover');
  if (e.dataTransfer.files.length) handleParamsFile(e.dataTransfer.files[0]);
});
paramsFileInput.addEventListener('change', e => { if (e.target.files.length) handleParamsFile(e.target.files[0]); });

function handleParamsFile(file) {
  const reader = new FileReader();
  reader.onload = e => {
    try {
      const parsed = parseParamsR(e.target.result);
      Object.assign(AppState.params, parsed);
      AppState.paramsLoaded = true;
      document.getElementById('paramsLoadStatus').style.display = 'block';
      document.getElementById('paramsLoadStatus').innerHTML =
        `<div class="alert alert-success">Loaded ${Object.keys(parsed).length} parameters from ${esc(file.name)}</div>`;
      unlockAllParamSteps();
    } catch (err) {
      document.getElementById('paramsLoadStatus').style.display = 'block';
      document.getElementById('paramsLoadStatus').innerHTML =
        `<div class="alert alert-danger">Error parsing params.R: ${esc(err.message)}</div>`;
    }
  };
  reader.readAsText(file);
}

function loadDefaultParams() {
  AppState.params = getDefaultParams();
  AppState.paramsLoaded = true;

  // Apply recommendations from sample sheet analysis
  if (AppState.sampleSheet.detected.batchEqualsCondition) {
    AppState.params.batch_variable = 'sample_name';
  }

  document.getElementById('paramsLoadStatus').style.display = 'block';
  document.getElementById('paramsLoadStatus').innerHTML =
    `<div class="alert alert-success">Template loaded with recommended defaults. ${
      AppState.sampleSheet.detected.batchEqualsCondition ?
      '<br><strong>Note:</strong> batch_variable set to "sample_name" based on your confounded design.' : ''
    }</div>`;
  unlockAllParamSteps();
}

function unlockAllParamSteps() {
  ['b1','b2','b3','b4','b5','b6','b7','b8','b9'].forEach(s => unlockStep(s));
  completeStep('b0');
}

// ================================================================
// PARAMS.R PARSER
// ================================================================
function parseParamsR(text) {
  const params = {};

  // Step 1: Extract variable assignments BEFORE params <- list(...)
  // These are lines like: skip_all_filtering <- FALSE
  const varAssignments = {};
  const varLines = text.split('\n');
  for (const vl of varLines) {
    const trimmed = vl.trim();
    if (trimmed.startsWith('#') || !trimmed) continue;
    // Stop scanning once we hit params <- list(
    if (/params\s*<-\s*list\s*\(/.test(trimmed)) break;
    // Match: identifier <- value
    const assignMatch = trimmed.match(/^([a-zA-Z_][a-zA-Z0-9_.]*)\s*<-\s*(.+?)\s*$/);
    if (assignMatch) {
      const k = assignMatch[1];
      let v = assignMatch[2];
      // Remove trailing comment
      const ci = findCommentStart(v);
      if (ci >= 0) v = v.substring(0, ci).trim();
      varAssignments[k] = interpretRValue(v);
    }
  }

  // Step 2: Find the params list body using bracket counting (NOT greedy regex)
  const listStart = text.search(/params\s*<-\s*list\s*\(/);
  if (listStart < 0) return params;
  // Find the opening ( position
  let openParen = text.indexOf('(', listStart);
  if (openParen < 0) return params;

  // Count brackets to find matching close
  let depth = 1;
  let pos = openParen + 1;
  let inString = false, strChar = '';
  while (pos < text.length && depth > 0) {
    const ch = text[pos];
    if (inString) {
      if (ch === strChar && text[pos - 1] !== '\\') inString = false;
    } else {
      if (ch === '"' || ch === "'") { inString = true; strChar = ch; }
      else if (ch === '#') {
        // Skip to end of line
        while (pos < text.length && text[pos] !== '\n') pos++;
      }
      else if (ch === '(') depth++;
      else if (ch === ')') depth--;
    }
    if (depth > 0) pos++;
  }
  const inner = text.substring(openParen + 1, pos);

  // Step 3: Parse the list contents line by line
  const lines = inner.split('\n');
  let currentKey = null;
  let currentValue = '';
  let bracketDepth = 0;

  for (let i = 0; i < lines.length; i++) {
    let line = lines[i];
    const commentIdx = findCommentStart(line);
    if (commentIdx >= 0) line = line.substring(0, commentIdx);
    line = line.trim();
    if (!line) continue;

    if (currentKey === null) {
      const eqIdx = line.indexOf('=');
      if (eqIdx > 0) {
        currentKey = line.substring(0, eqIdx).trim();
        currentValue = line.substring(eqIdx + 1).trim();
        bracketDepth = countBrackets(currentValue);
        if (bracketDepth <= 0) {
          // Value complete on one line ‚Äî strip list-separator comma safely
          if (currentValue.endsWith(',')) currentValue = currentValue.slice(0, -1).trim();
          let val = interpretRValue(currentValue);
          // Resolve variable references
          if (typeof val === 'string' && val in varAssignments) {
            val = varAssignments[val];
          }
          params[currentKey] = val;
          currentKey = null;
          currentValue = '';
          bracketDepth = 0;
        }
        // else: multi-line value starting ‚Äî keep trailing comma as vector content
      }
    } else {
      // Continuation line ‚Äî don't strip commas (they're part of the value)
      currentValue += ' ' + line;
      bracketDepth += countBrackets(line);
      if (bracketDepth <= 0) {
        // Value complete ‚Äî now strip the final list-separator comma
        let finalVal = currentValue.trim();
        if (finalVal.endsWith(',')) finalVal = finalVal.slice(0, -1).trim();
        let val = interpretRValue(finalVal);
        if (typeof val === 'string' && val in varAssignments) {
          val = varAssignments[val];
        }
        params[currentKey] = val;
        currentKey = null;
        currentValue = '';
        bracketDepth = 0;
      }
    }
  }
  return params;
}

function findCommentStart(line) {
  let inString = false;
  let stringChar = '';
  for (let i = 0; i < line.length; i++) {
    const ch = line[i];
    if (inString) {
      if (ch === stringChar && line[i - 1] !== '\\') inString = false;
    } else {
      if (ch === '"' || ch === "'") { inString = true; stringChar = ch; }
      else if (ch === '#') return i;
    }
  }
  return -1;
}

function countBrackets(s) {
  let d = 0;
  let inString = false, stringChar = '';
  for (let i = 0; i < s.length; i++) {
    const ch = s[i];
    if (inString) {
      if (ch === stringChar && s[i - 1] !== '\\') inString = false;
    } else {
      if (ch === '"' || ch === "'") { inString = true; stringChar = ch; }
      else if (ch === '(' || ch === '[' || ch === '{') d++;
      else if (ch === ')' || ch === ']' || ch === '}') d--;
    }
  }
  return d;
}

function interpretRValue(val) {
  val = val.trim();
  if (val === 'TRUE' || val === 'T') return true;
  if (val === 'FALSE' || val === 'F') return false;
  if (val === 'NULL') return null;
  if (/^-?\d+L$/.test(val)) return parseInt(val);
  if (/^-?\d+\.?\d*(e[+-]?\d+)?$/.test(val)) return parseFloat(val);
  if ((val.startsWith('"') && val.endsWith('"')) || (val.startsWith("'") && val.endsWith("'")))
    return val.slice(1, -1);
  if (val.startsWith('c(') && val.endsWith(')')) {
    const inner = val.slice(2, -1);
    return inner.split(',').map(v => interpretRValue(v.trim()));
  }
  return val; // Return as-is for complex expressions
}

// ================================================================
// PARAMETER DEFINITIONS DATABASE
// ================================================================
function getParamDefinitions() {
  return [
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B1: PROJECT & INPUT
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'project_root', step: 'b1', group: 'Project Paths', type: 'text',
      label: 'Project Root Directory',
      desc: 'Base directory for the entire dataset. All other paths are relative to or derived from this.',
      detail: 'This should point to the top-level directory of your dataset, e.g., /path/to/Datasets/My_Dataset/. The pipeline uses this to locate scripts, configs, and output directories.',
      default: '/path/to/your/dataset' },
    { key: 'dataset_name', step: 'b1', group: 'Project Paths', type: 'text',
      label: 'Dataset Name',
      desc: 'Identifier used in output directory names (e.g., "Human_Covid_LV_ChP").',
      detail: 'This string is used to construct the output directory path: Output_dir_{dataset_name}/. Use underscores instead of spaces.',
      default: 'My_Dataset' },
    { key: 'input_dir', step: 'b1', group: 'Input Files', type: 'text',
      label: 'Input Directory',
      desc: 'Path to preprocessed input files (typically the DecontX correction output).',
      detail: 'The pipeline expects Seurat .rds objects from the preprocessing pipeline, typically from Step 8 (DecontX correction). This directory contains one file per sample.',
      default: '' },
    { key: 'input_file_pattern', step: 'b1', group: 'Input Files', type: 'text',
      label: 'Input File Pattern',
      desc: 'Filename pattern with {sample_name} placeholder.',
      detail: 'Use {sample_name} as a placeholder that gets replaced by each sample name from the sample sheet. Example: "{sample_name}_decontX_corrected.rds".',
      default: '{sample_name}_decontX_corrected.rds' },
    { key: 'files_in_subdirectories', step: 'b1', group: 'Input Files', type: 'boolean',
      label: 'Files in Subdirectories',
      desc: 'Whether each sample file is in its own subdirectory named after the sample.',
      detail: 'If TRUE, the pipeline looks for input_dir/sample_name/file_pattern. If FALSE, it looks for input_dir/file_pattern directly.',
      default: true },
    { key: 'counts_layer_to_use', step: 'b1', group: 'Input Files', type: 'select',
      label: 'Counts Layer',
      desc: 'Which counts layer to use from the input Seurat objects.',
      detail: '"auto" auto-detects (tries scCDC_corrected, then counts, then data). For objects with ambient RNA correction (scCDC + DecontX), use "scCDC_corrected".',
      options: ['auto', 'counts', 'scCDC_corrected', 'soupX_counts', 'decontX_counts'],
      default: 'auto' },
    { key: 'out_root', step: 'b1', group: 'Project Paths', type: 'text',
      label: 'Output Root Directory',
      desc: 'Base output directory for all pipeline results.',
      detail: 'The pipeline creates subdirectories for objects, plots, normalization, integration benchmarks, DE results, etc., all under this path.',
      default: '' },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B2: QC & FILTERING
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'skip_all_filtering', step: 'b2', group: 'Master Switches', type: 'boolean',
      label: 'Skip All Filtering',
      desc: 'Disable all QC filtering. Use only if your data is already fully filtered.',
      detail: 'When TRUE, the pipeline skips all cell-level and gene-level QC. Only use this if preprocessing already performed stringent filtering.',
      default: false },
    { key: 'apply_qc_filtering', step: 'b2', group: 'Master Switches', type: 'boolean',
      label: 'Apply QC Filtering',
      desc: 'Enable standard cell-level quality control (min/max genes, MT%).',
      detail: 'Filters cells based on number of detected genes (nFeature_RNA) and mitochondrial content (percent.mt). Recommended for most datasets.',
      default: true },

    // --- Min genes per cell ---
    { key: 'filter_by_min_features', step: 'b2', group: 'Min Genes per Cell', type: 'boolean',
      label: 'Filter by Min Features',
      desc: 'Enable filtering cells with too few detected genes.',
      detail: 'When TRUE, cells with nFeature_RNA below min_features will be removed. Disable to skip this specific filter while keeping other QC active.',
      default: true },
    { key: 'min_features', step: 'b2', group: 'Min Genes per Cell', type: 'number',
      label: 'Min Features Threshold',
      desc: 'Minimum number of genes detected per cell. Cells below this are removed.',
      detail: 'Typical values: 200‚Äì500 for scRNA-seq, 200‚Äì300 for snRNA-seq. Very low gene counts indicate empty droplets or debris.',
      default: 200, min: 0, max: 5000, inputStep: 50 },

    // --- Max genes per cell ---
    { key: 'filter_by_max_features', step: 'b2', group: 'Max Genes per Cell', type: 'boolean',
      label: 'Filter by Max Features',
      desc: 'Enable filtering cells with too many detected genes (potential doublets).',
      detail: 'When TRUE, cells with nFeature_RNA above max_features will be removed. Helps catch multiplets missed by dedicated doublet callers.',
      default: true },
    { key: 'max_features', step: 'b2', group: 'Max Genes per Cell', type: 'number',
      label: 'Max Features Threshold',
      desc: 'Maximum genes per cell. Cells above this may be doublets.',
      detail: 'Typical values: 5000‚Äì10000 for scRNA-seq, 5000‚Äì8000 for snRNA-seq. Very high gene counts may indicate multiplets.',
      default: 10000, min: 1000, max: 30000, inputStep: 500 },

    // --- Mitochondrial ---
    { key: 'filter_by_percent_mt', step: 'b2', group: 'Mitochondrial Content', type: 'boolean',
      label: 'Filter by Percent MT',
      desc: 'Enable filtering cells with high mitochondrial read percentage.',
      detail: 'When TRUE, cells exceeding max_percent_mt will be removed. High MT% indicates dying/damaged cells.',
      default: true },
    { key: 'max_percent_mt', step: 'b2', group: 'Mitochondrial Content', type: 'number',
      label: 'Max Mitochondrial % Threshold',
      desc: 'Maximum percentage of mitochondrial reads. High MT% indicates dying cells.',
      detail: 'Typical: 10‚Äì25% for scRNA-seq, 1‚Äì5% for snRNA-seq. Choroid plexus tissue may have higher baseline MT%.',
      default: 25, min: 0, max: 100, inputStep: 1 },

    // --- Gene-level QC ---
    { key: 'filter_genes_by_min_cells', step: 'b2', group: 'Gene-Level QC', type: 'boolean',
      label: 'Filter Genes by Min Cells',
      desc: 'Remove genes detected in fewer than N cells.',
      detail: 'Removes very rarely expressed genes that add noise. Standard practice for most analyses.',
      default: true },
    { key: 'min_cells_per_gene', step: 'b2', group: 'Gene-Level QC', type: 'number',
      label: 'Min Cells per Gene Threshold',
      desc: 'Minimum number of cells a gene must be expressed in to be kept.',
      detail: 'Typical: 3‚Äì10 cells. Higher values are more conservative. Genes in fewer cells contribute mostly noise.',
      default: 3, min: 1, max: 100, inputStep: 1 },

    // --- Doublet filtering ---
    { key: 'filter_doublets', step: 'b2', group: 'Doublet Filtering', type: 'boolean',
      label: 'Filter Doublets',
      desc: 'Remove predicted doublets from upstream preprocessing.',
      detail: 'Requires doublet annotations in the input objects (e.g., from scDblFinder, Scrublet, or DoubletFinder). The pipeline reads the doublet_column from metadata.',
      default: true },
    { key: 'doublet_column', step: 'b2', group: 'Doublet Filtering', type: 'text',
      label: 'Doublet Column',
      desc: 'Metadata column name containing doublet predictions.',
      detail: 'The column in Seurat metadata that contains doublet/singlet labels. Common values: "doublet_consensus", "scDblFinder.class", "DF.classifications".',
      default: 'doublet_consensus' },
    { key: 'doublet_value_to_remove', step: 'b2', group: 'Doublet Filtering', type: 'text',
      label: 'Doublet Value to Remove',
      desc: 'The value in the doublet column that identifies doublets.',
      detail: 'Cells with this value in the doublet column will be removed. Common: "Doublet", "doublet", TRUE.',
      default: 'Doublet' },
    { key: 'doublet_vote_column', step: 'b2', group: 'Doublet Filtering', type: 'text',
      label: 'Doublet Vote Column',
      desc: 'Metadata column containing integer vote counts from multiple doublet callers.',
      detail: 'When using consensus voting, this column should contain the number of doublet callers that flagged each cell. Common name: "doublet_votes".',
      default: 'doublet_votes' },
    { key: 'use_doublet_vote_threshold', step: 'b2', group: 'Doublet Filtering', type: 'boolean',
      label: 'Use Consensus Vote Threshold',
      desc: 'Use a consensus voting approach across multiple doublet callers.',
      detail: 'When TRUE, uses the doublet_vote_column (integer votes from multiple callers) instead of a single binary prediction. Cells with votes ‚â• threshold are called doublets.',
      default: false },
    { key: 'doublet_vote_threshold', step: 'b2', group: 'Doublet Filtering', type: 'number',
      label: 'Doublet Vote Threshold',
      desc: 'Minimum votes from multiple doublet callers to classify as doublet.',
      detail: 'Only used when use_doublet_vote_threshold is TRUE. With 3 callers, threshold=2 means 2/3 must agree.',
      default: 2, min: 1, max: 10, inputStep: 1 },

    // --- Hemoglobin filtering ---
    { key: 'filter_hemoglobin', step: 'b2', group: 'Hemoglobin Filtering', type: 'boolean',
      label: 'Filter Hemoglobin Genes',
      desc: 'Remove hemoglobin genes from the dataset.',
      detail: 'Hemoglobin genes indicate red blood cell contamination in tissue dissociation. Removing them prevents RBC contamination from driving clustering.',
      default: true },
    { key: 'max_percent_hb', step: 'b2', group: 'Hemoglobin Filtering', type: 'number',
      label: 'Max Hemoglobin % Threshold',
      desc: 'Maximum percentage of hemoglobin reads per cell. Cells above this are removed.',
      detail: 'Threshold for cell-level filtering based on hemoglobin gene percentage. Cells exceeding this value are removed as likely RBC contaminated. Typical: 1‚Äì5%.',
      default: 2, min: 0, max: 100, inputStep: 0.5 },
    { key: 'hemoglobin_pattern', step: 'b2', group: 'Hemoglobin Filtering', type: 'text',
      label: 'Hemoglobin Gene Pattern',
      desc: 'Regex pattern to identify hemoglobin genes.',
      detail: 'Regular expression matching hemoglobin gene names. Default "^HB[AB]-" matches human HBA1/2, HBB. For mouse use "^Hb[ab]-".',
      default: '^HB[AB]-' },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B3: NORMALIZATION
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'run_sctransform', step: 'b3', group: 'Normalization Methods', type: 'boolean',
      label: 'Run SCTransform',
      desc: 'Regularized negative binomial regression normalization (Hafemeister & Satija 2019).',
      detail: 'SCTransform models gene expression as a function of sequencing depth using regularized NB regression. Produces Pearson residuals as normalized values. Note: incompatible with ALRA imputation.',
      default: true },
    { key: 'run_scran', step: 'b3', group: 'Normalization Methods', type: 'boolean',
      label: 'Run scran',
      desc: 'Deconvolution-based size factor normalization (Lun et al. 2016).',
      detail: 'Computes pool-based size factors by deconvolving cell pools. More robust to zero-inflation than simple library size normalization.',
      default: true },
    { key: 'run_lognorm', step: 'b3', group: 'Normalization Methods', type: 'boolean',
      label: 'Run LogNormalize',
      desc: 'Standard Seurat log-normalization: log1p(counts / total * scale_factor).',
      detail: 'Simple and fast. Normalizes by total counts per cell, scales to 10,000, then log-transforms. Widely used baseline method.',
      default: true },
    { key: 'run_sckwarn', step: 'b3', group: 'Normalization Methods', type: 'boolean',
      label: 'Run scKWARN',
      desc: 'Kernel Weighted Adjusted Regularized Normalization.',
      detail: 'Local Adaptive Size Normalization (LocASN) computes adaptive per-cell scaling factors. Followed by log1p transformation.',
      default: true },
    { key: 'sct_vars_to_regress', step: 'b3', group: 'Normalization Options', type: 'multiselect',
      label: 'SCT Variables to Regress',
      desc: 'Metadata variables to regress out during SCTransform and ScaleData.',
      detail: 'Typically includes percent.mt. Be cautious about over-regressing ‚Äî only include genuine nuisance variables.',
      options: ['percent.mt', 'nFeature_RNA', 'nCount_RNA', 'S.Score', 'G2M.Score'],
      default: ['percent.mt'] },
    { key: 'sct_method', step: 'b3', group: 'Normalization Options', type: 'select',
      label: 'SCT Method',
      desc: 'GLM fitting method for SCTransform.',
      detail: '"glmGamPoi" is faster and recommended for large datasets. "poisson" is the original SCTransform method.',
      options: ['glmGamPoi', 'poisson', 'negativebinomial'],
      default: 'glmGamPoi' },
    { key: 'scran_min_mean', step: 'b3', group: 'Normalization Options', type: 'number',
      label: 'scran Min Mean',
      desc: 'Minimum mean expression for gene filtering in scran.',
      detail: 'Genes with mean expression below this threshold are excluded from size factor estimation. Default 0.1.',
      default: 0.1, min: 0, max: 1, inputStep: 0.01 },
    { key: 'nfeatures_integration', step: 'b3', group: 'Normalization Options', type: 'number',
      label: 'Number of Variable Features',
      desc: 'Number of highly variable genes to select for integration.',
      detail: 'More features capture more biological variation but also more noise. Typical: 2000‚Äì5000.',
      default: 3000, min: 500, max: 10000, inputStep: 500 },
    { key: 'run_normalization_benchmarking', step: 'b3', group: 'Benchmarking', type: 'boolean',
      label: 'Run Normalization Benchmarking',
      desc: 'Compare normalization methods using integration benchmarks and select the best by majority vote.',
      detail: 'Runs each normalization with multiple integration methods, computes batch correction metrics (batch variance, ASW, LISI), and selects the best normalization by majority vote.',
      default: true },
    { key: 'norm_benchmark_integration_methods', step: 'b3', group: 'Benchmarking', type: 'multiselect',
      label: 'Benchmark Integration Methods',
      desc: 'Which integration methods to use for normalization majority vote.',
      detail: 'Each method votes for the best normalization. More methods = more robust vote. Use 2+ methods for proper majority voting.',
      options: ['harmony', 'mnn', 'scvi', 'sccobra', 'concord'],
      default: ['harmony', 'mnn', 'scvi', 'sccobra', 'concord'] },
    { key: 'norm_benchmark_max_cells', step: 'b3', group: 'Benchmarking', type: 'number',
      label: 'Benchmark Max Cells',
      desc: 'Maximum cells to use for benchmarking (subsampled for speed). 0 for no limit.',
      detail: 'Subsampling speeds up benchmarking significantly. 5000‚Äì10000 is usually sufficient for reliable metric computation.',
      default: 5000, min: 0, max: 100000, inputStep: 1000 },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B4: IMPUTATION
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'imputation_method', step: 'b4', group: 'Method Selection', type: 'select',
      label: 'Imputation Method',
      desc: 'Which imputation method(s) to run. Imputed data is for visualization, not DE.',
      detail: '"afmf" runs afMF (Module 02b, counts-based), "alra" runs ALRA (Module 03b, normalized-data), "both" runs both, "none" skips imputation. ALRA auto-skips if SCTransform wins benchmarking.',
      options: ['none', 'afmf', 'alra', 'both'],
      default: 'both' },
    { key: 'use_afmf_for_normalization', step: 'b4', group: 'afMF Settings', type: 'boolean',
      label: 'Use afMF Counts for Normalization',
      desc: 'Use imputed counts from afMF as input for normalization (not recommended).',
      detail: 'afMF-imputed counts can introduce false positive expression values. Keep FALSE for standard DE analysis.',
      default: false },
    { key: 'afmf_max_iter', step: 'b4', group: 'afMF Settings', type: 'number',
      label: 'afMF Max Iterations',
      desc: 'Maximum iterations for afMF matrix factorization convergence.',
      detail: 'Higher values allow more convergence time but increase computation. Default 100 is usually sufficient.',
      default: 100, min: 10, max: 1000, inputStep: 10 },
    { key: 'afmf_tol', step: 'b4', group: 'afMF Settings', type: 'number',
      label: 'afMF Convergence Tolerance',
      desc: 'Convergence tolerance for afMF algorithm.',
      detail: 'Smaller values require stricter convergence. Default 1e-5 provides good balance between accuracy and speed.',
      default: 0.00001, min: 0, max: 0.01, inputStep: 0.00001 },
    { key: 'afmf_min_cells_expressing', step: 'b4', group: 'afMF Settings', type: 'number',
      label: 'afMF Min Cells Expressing',
      desc: 'Minimum cells expressing a gene for afMF imputation.',
      detail: 'Genes expressed in fewer cells than this threshold are not imputed. Default 10.',
      default: 10, min: 1, max: 100, inputStep: 1 },
    { key: 'use_alra_for_downstream', step: 'b4', group: 'ALRA Settings', type: 'boolean',
      label: 'Use ALRA for Downstream',
      desc: 'Use ALRA-imputed values for downstream analysis (not recommended for DE).',
      detail: 'ALRA imputation is useful for visualization but not recommended for differential expression as it can inflate significance.',
      default: false },
    { key: 'alra_q', step: 'b4', group: 'ALRA Settings', type: 'number',
      label: 'ALRA Power Iterations',
      desc: 'Number of power iterations for randomized SVD in ALRA.',
      detail: 'More iterations improve SVD accuracy at the cost of speed. Default 10.',
      default: 10, min: 1, max: 50, inputStep: 1 },
    { key: 'alra_quantile_prob', step: 'b4', group: 'ALRA Settings', type: 'number',
      label: 'ALRA Quantile Probability',
      desc: 'Quantile probability for ALRA thresholding.',
      detail: 'Controls how aggressively zeros are preserved. Lower = more conservative imputation. Default 0.001.',
      default: 0.001, min: 0.0001, max: 0.1, inputStep: 0.0001 },
    { key: 'alra_k', step: 'b4', group: 'ALRA Settings', type: 'text',
      label: 'ALRA Rank (k)',
      desc: 'Rank for SVD decomposition. Leave empty for automatic detection.',
      detail: 'When empty/NULL, ALRA automatically determines the optimal rank from eigenvalue distribution. Set manually only if auto-detection gives poor results.',
      default: '' },
    { key: 'alra_compatible_methods', step: 'b4', group: 'ALRA Settings', type: 'multiselect',
      label: 'ALRA Compatible Normalizations',
      desc: 'Which normalization methods are compatible with ALRA imputation.',
      detail: 'ALRA only works on log-normalized data. If the winning normalization method from benchmarking is NOT in this list (e.g., SCTransform wins), ALRA is automatically skipped.',
      options: ['LogNormalize', 'scran', 'scKWARN'],
      default: ['LogNormalize', 'scran'] },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B5: INTEGRATION
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'run_batch_integration', step: 'b5', group: 'Integration Control', type: 'boolean',
      label: 'Run Batch Integration',
      desc: 'Enable batch integration/correction. Disable if all samples are from the same batch.',
      detail: 'When TRUE, the pipeline runs integration methods (Harmony, CCA, etc.) to correct for technical batch effects.',
      default: true },
    { key: 'batch_variable', step: 'b5', group: 'Integration Control', type: 'select',
      label: 'Batch Variable',
      desc: 'Which metadata column to use for integration batch correction.',
      detail: '"batch" corrects processing batches, "sample_name" corrects per-sample. If batch=condition is confounded, use "sample_name".',
      options: [],
      default: 'sample_name' },
    { key: 'integration_selection_mode', step: 'b5', group: 'Integration Control', type: 'select',
      label: 'Integration Selection Mode',
      desc: 'Strategy for selecting the best integration method from benchmarking.',
      detail: '"balanced" (recommended): composite score across batch variance, ASW, and LISI. "batch_removal": aggressively minimizes batch effects. "conservative": prioritizes LISI score.',
      options: ['balanced', 'batch_removal', 'conservative'],
      default: 'balanced' },
    { key: 'celltype_column', step: 'b5', group: 'Integration Control', type: 'text',
      label: 'Cell Type Column',
      desc: 'Metadata column containing cell type annotations for bio conservation metrics.',
      detail: 'Used in integration benchmarking to evaluate biological conservation (cell type ASW, etc.). Must match a column name in your Seurat object metadata. Common values: "cluster_name_MapMyCells", "cell_type", "annotation".',
      default: 'cluster_name_MapMyCells' },
    { key: 'bio_weight', step: 'b5', group: 'Composite Score Weights', type: 'number',
      label: 'Biological Conservation Weight',
      desc: 'Weight for biological conservation in the scIB composite score (0‚Äì1).',
      detail: 'Controls how much biological conservation (cell type preservation) matters vs batch correction in the composite score used for integration method selection. Default 0.4 follows the scIB paper. bio_weight + batch_weight should equal 1.0.',
      default: 0.4, min: 0, max: 1, inputStep: 0.05 },
    { key: 'batch_weight', step: 'b5', group: 'Composite Score Weights', type: 'number',
      label: 'Batch Correction Weight',
      desc: 'Weight for batch correction in the scIB composite score (0‚Äì1).',
      detail: 'Controls how much batch correction quality matters vs biological conservation. Default 0.6 follows the scIB paper. bio_weight + batch_weight should equal 1.0.',
      default: 0.6, min: 0, max: 1, inputStep: 0.05 },
    { key: 'dims_use', step: 'b5', group: 'Integration Control', type: 'number',
      label: 'PCA Dimensions',
      desc: 'Number of PCA dimensions to use for integration and UMAP.',
      detail: 'Typical: 20‚Äì50. Higher values capture more variation but may include noise.',
      default: 30, min: 5, max: 100, inputStep: 5 },
    { key: 'vars_to_regress', step: 'b5', group: 'Integration Control', type: 'multiselect',
      label: 'Variables to Regress (ScaleData)',
      desc: 'Variables to regress out during ScaleData for integration.',
      detail: 'These variables are regressed out during ScaleData prior to PCA for integration. Separate from SCT regression. Typically includes percent.mt.',
      options: ['percent.mt', 'nFeature_RNA', 'nCount_RNA', 'S.Score', 'G2M.Score'],
      default: ['percent.mt'] },
    { key: 'integration_methods_r', step: 'b5', group: 'R Integration Methods', type: 'multiselect',
      label: 'R Integration Methods',
      desc: 'Which R-based integration methods to run.',
      detail: 'Harmony is fast and generally reliable. CCA and RPCA are Seurat native methods. FastMNN is from the batchelor package.',
      options: ['harmony', 'cca', 'rpca', 'fastmnn'],
      default: ['harmony', 'cca', 'rpca'] },
    { key: 'run_integration_benchmarking', step: 'b5', group: 'Integration Control', type: 'boolean',
      label: 'Run Integration Benchmarking',
      desc: 'Benchmark all integration methods and auto-select the best one.',
      detail: 'When TRUE, computes batch correction metrics for all methods and selects the winner. When FALSE, uses the first available method.',
      default: true },
    { key: 'run_python_integrations', step: 'b5', group: 'Python Integration Methods', type: 'boolean',
      label: 'Run Python Integrations',
      desc: 'Enable Python-based integration methods (scVI, Scanorama, BBKNN).',
      detail: 'Requires Python environment with scvi-tools installed. These methods often produce better results but are slower.',
      default: true },
    { key: 'integration_methods_python', step: 'b5', group: 'Python Integration Methods', type: 'multiselect',
      label: 'Python Integration Methods',
      desc: 'Which Python-based integration methods to run.',
      detail: 'scVI is a deep generative model. Scanorama uses panoramic stitching. BBKNN is batch-balanced k-NN.',
      options: ['scvi', 'scanorama', 'bbknn'],
      default: ['scvi', 'scanorama', 'bbknn'] },
    { key: 'run_sccobra', step: 'b5', group: 'Python Integration Methods', type: 'boolean',
      label: 'Run scCobra',
      desc: 'Enable scCobra contrastive learning integration.',
      detail: 'scCobra uses a contrastive learning framework for batch correction. Runs as a separate module (05b).',
      default: true },
    { key: 'run_concord', step: 'b5', group: 'CONCORD', type: 'boolean',
      label: 'Run CONCORD',
      desc: 'Enable CONCORD integration (Nature Biotechnology 2025).',
      detail: 'CONCORD learns a unified latent space via contrastive + concordance objectives. Requires concord Python package.',
      default: true },
    { key: 'concord_n_top_features', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Top Features',
      desc: 'Number of top features for CONCORD input.',
      detail: 'Number of highly variable genes used as CONCORD input. Default 2000.',
      default: 2000, min: 500, max: 10000, inputStep: 500 },
    { key: 'concord_n_latent', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Latent Dimensions',
      desc: 'Latent space dimensionality for CONCORD.',
      detail: 'Number of dimensions in the learned embedding. Default 30.',
      default: 30, min: 5, max: 200, inputStep: 5 },
    { key: 'concord_max_epochs', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Max Epochs',
      desc: 'Maximum training epochs for CONCORD.',
      detail: 'More epochs allow better convergence. Early stopping patience also applies. Default 200.',
      default: 200, min: 10, max: 1000, inputStep: 10 },
    { key: 'concord_batch_size', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Batch Size',
      desc: 'Mini-batch size for CONCORD training.',
      detail: 'Larger batches are more stable but use more memory. Default 256.',
      default: 256, min: 32, max: 2048, inputStep: 32 },
    { key: 'concord_lr', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Learning Rate',
      desc: 'Learning rate for CONCORD optimizer.',
      detail: 'Standard deep learning learning rate. Default 1e-3.',
      default: 0.001, min: 0.00001, max: 0.1, inputStep: 0.0001 },
    { key: 'concord_early_stopping_patience', step: 'b5', group: 'CONCORD', type: 'number',
      label: 'CONCORD Early Stopping Patience',
      desc: 'Epochs to wait without improvement before stopping.',
      detail: 'If validation loss does not improve for this many epochs, training stops early. Default 15.',
      default: 15, min: 1, max: 100, inputStep: 1 },
    { key: 'concord_preload_dense', step: 'b5', group: 'CONCORD', type: 'boolean',
      label: 'CONCORD Preload Dense',
      desc: 'Preload data as dense matrix for faster CONCORD training.',
      detail: 'Converts sparse input to dense before training. Faster but uses more memory. Recommended for datasets < 100k cells.',
      default: true },
    { key: 'concord_device', step: 'b5', group: 'CONCORD', type: 'select',
      label: 'CONCORD Device',
      desc: 'Compute device for CONCORD training.',
      detail: '"auto" selects GPU if available, falls back to CPU. "cuda" forces GPU. "cpu" forces CPU.',
      options: ['auto', 'cuda', 'cpu'],
      default: 'auto' },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B6: CLUSTERING
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // --- CHOIR ---
    { key: 'run_choir_clustering', step: 'b6', group: 'CHOIR Clustering', type: 'boolean',
      label: 'Run CHOIR Clustering',
      desc: 'Cluster Hierarchy Optimization by Iterative Random forests.',
      detail: 'CHOIR adaptively determines cluster granularity using random forests to assess whether clusters are biologically distinct. Recommended for unbiased cell type identification.',
      default: true },
    { key: 'choir_alpha', step: 'b6', group: 'CHOIR Clustering', type: 'number',
      label: 'CHOIR Alpha',
      desc: 'Significance threshold for cluster splitting decisions.',
      detail: 'Lower alpha = more conservative splitting (fewer clusters). Higher alpha = more liberal splitting. Default 0.05.',
      default: 0.05, min: 0.001, max: 0.5, inputStep: 0.005 },
    { key: 'choir_use_assay', step: 'b6', group: 'CHOIR Clustering', type: 'select',
      label: 'CHOIR Assay',
      desc: 'Which Seurat assay to use for CHOIR clustering.',
      detail: 'Typically "RNA" for standard analysis. "SCT" if using SCTransform-based workflow directly.',
      options: ['RNA', 'SCT'],
      default: 'RNA' },

    // --- scAURA ---
    { key: 'run_scaura_clustering', step: 'b6', group: 'scAURA Clustering', type: 'boolean',
      label: 'Run scAURA Clustering',
      desc: 'Graph debiased contrastive learning for unsupervised cell type discovery.',
      detail: 'scAURA uses debiased contrastive learning on an adaptive k-NN graph, followed by K-means and optional SSC (Self-Supervised Clustering) refinement. Can run alongside CHOIR.',
      default: true },
    { key: 'scaura_k_clusters', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA K Clusters',
      desc: 'Number of clusters for K-means on learned embeddings.',
      detail: 'The number of clusters scAURA will produce. Set based on expected cell type diversity in your dataset.',
      default: 7, min: 2, max: 50, inputStep: 1 },
    { key: 'scaura_kmax', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Kmax',
      desc: 'Maximum k for adaptive k-NN graph construction.',
      detail: 'Controls neighborhood size in the adaptive graph. Larger = smoother representations.',
      default: 40, min: 5, max: 100, inputStep: 5 },
    { key: 'scaura_hidden_dim', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Hidden Dimension',
      desc: 'Hidden layer dimension in the GCN encoder.',
      detail: 'Determines the capacity of the graph neural network. Default 64.',
      default: 64, min: 16, max: 512, inputStep: 16 },
    { key: 'scaura_tau', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Tau',
      desc: 'Temperature for contrastive loss.',
      detail: 'Lower values produce sharper similarity distributions. Typical range: 0.1‚Äì1.0. Default 0.7.',
      default: 0.7, min: 0.05, max: 2.0, inputStep: 0.05 },
    { key: 'scaura_tau_plus', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Tau Plus',
      desc: 'Temperature for positive pairs in debiased contrastive loss.',
      detail: 'Controls the debiasing strength. Default 0.1.',
      default: 0.1, min: 0.01, max: 1.0, inputStep: 0.01 },
    { key: 'scaura_pe', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Edge Perturbation',
      desc: 'Probability of edge perturbation for graph augmentation.',
      detail: 'Controls how much the graph structure is perturbed during augmentation. Default 0.3.',
      default: 0.3, min: 0, max: 1.0, inputStep: 0.05 },
    { key: 'scaura_pf', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Feature Masking',
      desc: 'Probability of feature masking for augmentation.',
      detail: 'Controls how much input features are masked during augmentation. Default 0.3.',
      default: 0.3, min: 0, max: 1.0, inputStep: 0.05 },
    { key: 'scaura_epochs', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Training Epochs',
      desc: 'Number of training epochs for contrastive learning.',
      detail: 'More epochs = better convergence but longer training. Default 100.',
      default: 100, min: 10, max: 1000, inputStep: 10 },
    { key: 'scaura_lr', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Learning Rate',
      desc: 'Learning rate for scAURA optimizer.',
      detail: 'Standard deep learning learning rate. Default 1e-3.',
      default: 0.001, min: 0.00001, max: 0.1, inputStep: 0.0001 },
    { key: 'scaura_self_train', step: 'b6', group: 'scAURA Clustering', type: 'boolean',
      label: 'scAURA Self-Training (SSC)',
      desc: 'Enable SSC refinement after K-means.',
      detail: 'Self-Supervised Clustering refinement can improve cluster assignments after initial K-means. Recommended.',
      default: true },
    { key: 'scaura_n_top_genes', step: 'b6', group: 'scAURA Clustering', type: 'number',
      label: 'scAURA Top Genes',
      desc: 'Number of highly variable genes for scAURA input.',
      detail: 'Number of HVGs used as input features for scAURA. Default 2000.',
      default: 2000, min: 500, max: 10000, inputStep: 500 },
    { key: 'scaura_use_gpu', step: 'b6', group: 'scAURA Clustering', type: 'boolean',
      label: 'scAURA Use GPU',
      desc: 'Use GPU acceleration for scAURA training.',
      detail: 'Enable if CUDA-capable GPU is available. Falls back to CPU if not available.',
      default: true },

    // --- Clustering Source ---
    { key: 'scice_clustering_source', step: 'b6', group: 'Clustering Source', type: 'select',
      label: 'Clustering Source for Downstream',
      desc: 'Which primary clustering method feeds into subclustering and DE.',
      detail: '"auto" selects CHOIR > scAURA > none. "both" subclusters BOTH independently, creating suffixed columns.',
      options: ['auto', 'choir', 'scaura', 'both'],
      default: 'auto' },

    // --- Leiden ---
    { key: 'run_leiden_clustering', step: 'b6', group: 'Leiden Clustering', type: 'boolean',
      label: 'Run Leiden Clustering',
      desc: 'Standard graph-based Leiden community detection.',
      detail: 'Leiden is the most widely used clustering algorithm for scRNA-seq. Multiple resolutions can be tested.',
      default: true },
    { key: 'leiden_resolutions', step: 'b6', group: 'Leiden Clustering', type: 'text',
      label: 'Leiden Resolution(s)',
      desc: 'Comma-separated resolution values to test (e.g., "0.1, 0.3, 0.5, 0.8, 1.0").',
      detail: 'Higher resolution = more clusters. The pipeline runs clustering at each resolution. Typical: 0.1‚Äì1.5.',
      default: '0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1.0' },
    { key: 'leiden_algorithm', step: 'b6', group: 'Leiden Clustering', type: 'select',
      label: 'Leiden Algorithm',
      desc: 'Graph algorithm variant for Leiden clustering.',
      detail: '1 = original Louvain, 2 = Louvain with multilevel refinement, 3 = SLM, 4 = Leiden (recommended). Leiden (4) guarantees connected communities.',
      options: ['1', '2', '3', '4'],
      default: '4' },
    { key: 'final_resolution', step: 'b6', group: 'Leiden Clustering', type: 'number',
      label: 'Final Leiden Resolution',
      desc: 'Resolution to use as the primary Leiden clustering result.',
      detail: 'This resolution is used as the main Leiden result for downstream analysis. Should be one of the values in leiden_resolutions.',
      default: 0.5, min: 0.01, max: 5.0, inputStep: 0.1 },
    { key: 'leiden_n_neighbors', step: 'b6', group: 'Leiden Clustering', type: 'number',
      label: 'Leiden N Neighbors',
      desc: 'Number of nearest neighbors for SNN graph construction.',
      detail: 'Controls neighborhood size for the shared nearest neighbor graph. Default 20.',
      default: 20, min: 5, max: 100, inputStep: 5 },
    { key: 'run_clustering_quality', step: 'b6', group: 'Leiden Clustering', type: 'boolean',
      label: 'Run Clustering Quality Metrics',
      desc: 'Compute clustering quality metrics (silhouette score, etc.).',
      detail: 'When TRUE, computes quality metrics across all tested resolutions to help select optimal clustering.',
      default: true },

    // --- scICE Subclustering ---
    { key: 'run_scice_subclustering', step: 'b6', group: 'scICE Subclustering', type: 'boolean',
      label: 'Run scICE Subclustering',
      desc: 'Julia-based iterative subclustering using scICE.',
      detail: 'scICE performs iterative subclustering to identify fine-grained cell states within initial clusters. Requires Julia environment.',
      default: true },
    { key: 'scice_k_min', step: 'b6', group: 'scICE Subclustering', type: 'number',
      label: 'scICE Min K',
      desc: 'Minimum number of subclusters to test.',
      detail: 'scICE tests k values from k_min to k_max and selects optimal k using information criterion.',
      default: 2, min: 2, max: 10, inputStep: 1 },
    { key: 'scice_k_max', step: 'b6', group: 'scICE Subclustering', type: 'number',
      label: 'scICE Max K',
      desc: 'Maximum number of subclusters to test.',
      detail: 'Upper bound for subclustering granularity. Default 15.',
      default: 15, min: 3, max: 50, inputStep: 1 },
    { key: 'scice_ic_threshold', step: 'b6', group: 'scICE Subclustering', type: 'number',
      label: 'scICE IC Threshold',
      desc: 'Information criterion threshold for accepting subclustering.',
      detail: 'A split is accepted if IC ratio > threshold. Values close to 1 are more conservative. Default 1.005.',
      default: 1.005, min: 1.0, max: 1.5, inputStep: 0.001 },
    { key: 'scice_min_cells', step: 'b6', group: 'scICE Subclustering', type: 'number',
      label: 'scICE Min Cells',
      desc: 'Minimum cells per cluster for subclustering to be attempted.',
      detail: 'Clusters with fewer cells than this threshold are not subclustered. Default 100.',
      default: 100, min: 10, max: 1000, inputStep: 10 },
    { key: 'scice_target_clusters', step: 'b6', group: 'scICE Subclustering', type: 'text',
      label: 'scICE Target Clusters',
      desc: 'Specific clusters to subcluster, or empty for all clusters.',
      detail: 'Comma-separated list of cluster IDs to subcluster (e.g., "0, 2, 5"). Leave empty or "NULL" to subcluster all clusters that meet the min_cells threshold.',
      default: '' },

    // --- IDclust Subclustering ---
    { key: 'run_idclust_subclustering', step: 'b6', group: 'IDclust Subclustering', type: 'boolean',
      label: 'Run IDclust Subclustering',
      desc: 'Iterative Differential Clustering (Prompsy et al., NAR 2024).',
      detail: 'IDclust recursively splits clusters, validating each split with DE testing. Only biologically meaningful splits (with sufficient DEGs) are retained. Can run alongside scICE.',
      default: true },
    { key: 'idclust_logFC_th', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust logFC Threshold',
      desc: 'Log2 fold-change threshold for DE validation of splits.',
      detail: 'Minimum log2FC for a gene to count as differentially expressed when validating subclustering. Default log2(1.5) ‚âà 0.585.',
      default: 0.585, min: 0.1, max: 2.0, inputStep: 0.01 },
    { key: 'idclust_qval_th', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Q-value Threshold',
      desc: 'Adjusted p-value threshold for DE validation.',
      detail: 'Genes with adjusted p-value below this are considered significant. Default 0.01.',
      default: 0.01, min: 0.0001, max: 0.1, inputStep: 0.001 },
    { key: 'idclust_min_DEGs', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Min DEGs',
      desc: 'Minimum DEGs required to validate a cluster split.',
      detail: 'A split is only retained if at least this many genes pass the FC+pval thresholds. Default 5.',
      default: 5, min: 1, max: 50, inputStep: 1 },
    { key: 'idclust_max_depth', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Max Recursion Depth',
      desc: 'Maximum recursion depth for iterative subclustering.',
      detail: 'Limits how deep the recursive splitting can go. Default 10.',
      default: 10, min: 1, max: 30, inputStep: 1 },
    { key: 'idclust_resolution', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Resolution',
      desc: 'Louvain resolution for IDclust subclustering steps.',
      detail: 'Resolution parameter used in subsequent splitting iterations. Default 0.8.',
      default: 0.8, min: 0.01, max: 3.0, inputStep: 0.1 },
    { key: 'idclust_min_cells', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Min Cells',
      desc: 'Minimum cells per cluster for IDclust subclustering.',
      detail: 'Clusters with fewer cells than this are not further split. Default 100.',
      default: 100, min: 10, max: 1000, inputStep: 10 },
    { key: 'idclust_target_clusters', step: 'b6', group: 'IDclust Subclustering', type: 'text',
      label: 'IDclust Target Clusters',
      desc: 'Specific clusters to subcluster, or empty for all.',
      detail: 'Comma-separated list of cluster IDs. Leave empty or "NULL" for all clusters.',
      default: '' },
    { key: 'idclust_min_frac_assigned', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Min Fraction Assigned',
      desc: 'Minimum fraction of cells that must be assigned to a subcluster.',
      detail: 'Subclusters with fewer than this fraction of the parent cluster cells are merged back. Default 0.1 (10%).',
      default: 0.1, min: 0.01, max: 0.5, inputStep: 0.01 },
    { key: 'idclust_n_dims', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust PCA Dimensions',
      desc: 'Number of PCA dimensions used within each IDclust iteration.',
      detail: 'Dimensionality reduction within each subclustering step. Default 50.',
      default: 50, min: 5, max: 100, inputStep: 5 },
    { key: 'idclust_starting_resolution', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Starting Resolution',
      desc: 'Initial Louvain resolution for the first IDclust split.',
      detail: 'Lower = fewer initial subclusters. Subsequent iterations use idclust_resolution. Default 0.1.',
      default: 0.1, min: 0.01, max: 2.0, inputStep: 0.05 },
    { key: 'idclust_starting_k', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust Starting K (Neighbors)',
      desc: 'Number of nearest neighbors for SNN graph in the first iteration.',
      detail: 'Controls initial graph granularity. Default 100.',
      default: 100, min: 10, max: 500, inputStep: 10 },
    { key: 'idclust_k', step: 'b6', group: 'IDclust Subclustering', type: 'number',
      label: 'IDclust K (Neighbors)',
      desc: 'Number of nearest neighbors for SNN graph in subsequent iterations.',
      detail: 'Controls graph granularity after the first iteration. Default 100.',
      default: 100, min: 10, max: 500, inputStep: 10 },
    { key: 'idclust_plotting', step: 'b6', group: 'IDclust Subclustering', type: 'boolean',
      label: 'IDclust Plotting',
      desc: 'Generate UMAP plots at each IDclust recursion step.',
      detail: 'When TRUE, produces diagnostic plots showing each split decision. Useful for debugging but increases runtime.',
      default: true },

    // --- Unified Subclustering ---
    { key: 'subclustering_methods', step: 'b6', group: 'Unified Subclustering Control', type: 'multiselect',
      label: 'Subclustering Methods',
      desc: 'Which subclustering methods to run.',
      detail: 'Select which subclustering methods to execute. Running both provides complementary results.',
      options: ['scice', 'idclust'],
      default: ['scice', 'idclust'] },
    { key: 'subclustering_source', step: 'b6', group: 'Unified Subclustering Control', type: 'select',
      label: 'Subclustering Source',
      desc: 'Which primary clustering provides input for subclustering.',
      detail: '"auto" auto-detects from Module 05. "both" subclusters from both CHOIR and scAURA independently.',
      options: ['auto', 'choir', 'scaura', 'both'],
      default: 'both' },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B7: DIFFERENTIAL EXPRESSION
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'de_comparison_variable', step: 'b7', group: 'DE Setup', type: 'select',
      label: 'Comparison Variable',
      desc: 'Which metadata variable to compare for differential expression.',
      detail: 'Typically "sex" for sex-based comparisons or "condition" for disease vs control.',
      options: [],
      default: 'sex' },
    { key: 'de_group1', step: 'b7', group: 'DE Setup', type: 'text',
      label: 'Group 1 (Numerator)',
      desc: 'First group for comparison. Positive log2FC = higher in this group.',
      detail: 'Genes with positive log fold-change are upregulated in Group 1 relative to Group 2.',
      default: 'Male' },
    { key: 'de_group2', step: 'b7', group: 'DE Setup', type: 'text',
      label: 'Group 2 (Denominator)',
      desc: 'Second group for comparison. Negative log2FC = higher in this group.',
      detail: 'Genes with negative log fold-change are upregulated in Group 2 relative to Group 1.',
      default: 'Female' },
    { key: 'de_comparison_scope', step: 'b7', group: 'DE Setup', type: 'select',
      label: 'Comparison Scope',
      desc: 'Whether to run DE across the whole dataset or per-cluster.',
      detail: '"whole_dataset" runs one DE analysis across all cells. "per_cluster" runs DE separately within each cluster.',
      options: ['whole_dataset', 'per_cluster'],
      default: 'whole_dataset' },
    { key: 'de_covariates', step: 'b7', group: 'DE Setup', type: 'multiselect',
      label: 'DE Covariates',
      desc: 'Variables to include as covariates in the DE model.',
      detail: 'Statistically controlled for in the DE model. Always include batch if confounded. percent.mt and nFeature_RNA control for technical variation.',
      options: ['percent.mt', 'nFeature_RNA', 'nCount_RNA', 'batch', 'condition'],
      default: ['percent.mt', 'nFeature_RNA', 'batch'] },
    { key: 'de_target_clusters', step: 'b7', group: 'DE Setup', type: 'text',
      label: 'DE Target Clusters',
      desc: 'Specific clusters to run DE on, or empty for all.',
      detail: 'Comma-separated list of cluster IDs (e.g., "0, 2, 5"). Only used when de_comparison_scope is "per_cluster". Leave empty for all clusters.',
      default: '' },

    // --- DE Methods ---
    { key: 'run_mast', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run MAST',
      desc: 'Model-based Analysis of Single-cell Transcriptomics (cell-level hurdle model).',
      detail: 'MAST uses a two-part hurdle model for zero-inflated expression data. Cell-level analysis gives higher power but is susceptible to pseudoreplication.',
      default: true },
    { key: 'run_dream', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run DREAM',
      desc: 'Mixed-effects model from variancePartition (recommended for small n).',
      detail: 'DREAM fits a linear mixed-effects model accounting for both cell-level and sample-level variation. Best choice for datasets with few samples.',
      default: true },
    { key: 'run_pseudobulk_edger', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run Pseudobulk edgeR',
      desc: 'Pseudobulk analysis using edgeR.',
      detail: 'Aggregates cells per sample into pseudobulk profiles. Gold standard for avoiding pseudoreplication.',
      default: true },
    { key: 'run_pseudobulk_deseq2', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run Pseudobulk DESeq2',
      desc: 'Pseudobulk analysis using DESeq2.',
      detail: 'DESeq2 negative binomial model with shrinkage estimators. Good cross-validation with edgeR.',
      default: true },
    { key: 'run_permutation', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run Permutation Test',
      desc: 'Non-parametric permutation-based DE testing.',
      detail: 'Shuffles sample labels to build null distribution. Validates top hits from parametric methods.',
      default: true },
    { key: 'run_negative_control', step: 'b7', group: 'DE Methods', type: 'boolean',
      label: 'Run Negative Control',
      desc: 'Run negative control DE analysis (same-group comparison).',
      detail: 'Compares samples within the same group (e.g., Male vs Male) to estimate false positive rate.',
      default: true },

    // --- DE Thresholds ---
    { key: 'de_logfc_threshold', step: 'b7', group: 'DE Thresholds', type: 'number',
      label: 'DE Log2FC Threshold',
      desc: 'Minimum log2 fold-change for a gene to be considered DE.',
      detail: 'Genes with absolute log2FC below this are not reported as significant. Default 0.5 (‚âà1.4-fold change).',
      default: 0.5, min: 0, max: 5, inputStep: 0.1 },
    { key: 'de_pval_threshold', step: 'b7', group: 'DE Thresholds', type: 'number',
      label: 'DE P-value Threshold',
      desc: 'Adjusted p-value threshold for significance.',
      detail: 'Genes with adjusted p-value above this are not reported as significant. Default 0.05.',
      default: 0.05, min: 0.0001, max: 0.5, inputStep: 0.001 },
    { key: 'de_min_pct', step: 'b7', group: 'DE Thresholds', type: 'number',
      label: 'DE Min Percent Expressed',
      desc: 'Minimum fraction of cells expressing a gene in either group.',
      detail: 'Genes expressed in fewer cells than this fraction are skipped. Default 0.1 (10%).',
      default: 0.1, min: 0, max: 1, inputStep: 0.05 },

    // --- CLTS ---
    { key: 'run_clts_renormalization', step: 'b7', group: 'CLTS Re-normalization', type: 'boolean',
      label: 'Run CLTS Re-normalization',
      desc: 'Count based on Linearized Transcriptome Size (Lu et al., Nat Commun 2025).',
      detail: 'CLTS removes composition bias between groups by re-normalizing within cell types. Useful when cell type composition differs systematically between conditions/sexes.',
      default: true },
    { key: 'clts_clustering_source', step: 'b7', group: 'CLTS Re-normalization', type: 'select',
      label: 'CLTS Clustering Source',
      desc: 'Which clustering to use for CLTS cell type grouping.',
      detail: '"scice" uses scICE subclusters (default). "both" creates separate _redeconv objects for scICE and Leiden. "all" creates for scICE, Leiden, and CHOIR.',
      options: ['scice', 'leiden', 'choir', 'both', 'all'],
      default: 'scice' },
    { key: 'clts_cluster_column', step: 'b7', group: 'CLTS Re-normalization', type: 'text',
      label: 'CLTS Cluster Column',
      desc: 'Metadata column name containing cluster assignments for CLTS.',
      detail: 'The column in Seurat metadata that contains cluster IDs used for CLTS grouping. "auto" selects based on clts_clustering_source.',
      default: 'auto' },
    { key: 'clts_min_cells_per_cluster', step: 'b7', group: 'CLTS Re-normalization', type: 'number',
      label: 'CLTS Min Cells per Cluster',
      desc: 'Minimum cells per cluster to include in CLTS regression.',
      detail: 'Clusters with fewer cells are excluded from CLTS size factor estimation. Default 50.',
      default: 50, min: 10, max: 500, inputStep: 10 },
    { key: 'clts_baseline_sample', step: 'b7', group: 'CLTS Re-normalization', type: 'text',
      label: 'CLTS Baseline Sample',
      desc: 'Baseline sample for CLTS normalization. "auto" selects highest correlation.',
      detail: '"auto" automatically selects the sample with highest correlation to the average. Or specify a specific sample name.',
      default: 'auto' },
    { key: 'clts_run_benchmark', step: 'b7', group: 'CLTS Re-normalization', type: 'boolean',
      label: 'CLTS Run Benchmark',
      desc: 'Compare marker detection between original and CLTS normalization.',
      detail: 'When TRUE, runs FindAllMarkers on both original and CLTS-normalized objects and compares results.',
      default: true },
    { key: 'clts_marker_logfc_threshold', step: 'b7', group: 'CLTS Re-normalization', type: 'number',
      label: 'CLTS Marker logFC Threshold',
      desc: 'Log2FC threshold for marker gene detection in CLTS benchmark.',
      detail: 'Used in FindAllMarkers when running CLTS benchmark. Default 0.5.',
      default: 0.5, min: 0, max: 5, inputStep: 0.1 },
    { key: 'clts_marker_pval_threshold', step: 'b7', group: 'CLTS Re-normalization', type: 'number',
      label: 'CLTS Marker P-value Threshold',
      desc: 'Adjusted p-value threshold for marker gene detection in CLTS benchmark.',
      detail: 'Used in FindAllMarkers when running CLTS benchmark. Default 0.05.',
      default: 0.05, min: 0.0001, max: 0.5, inputStep: 0.001 },
    { key: 'clts_marker_min_pct', step: 'b7', group: 'CLTS Re-normalization', type: 'number',
      label: 'CLTS Marker Min Pct',
      desc: 'Minimum fraction of cells expressing marker genes in CLTS benchmark.',
      detail: 'Used in FindAllMarkers when running CLTS benchmark. Default 0.25.',
      default: 0.25, min: 0, max: 1, inputStep: 0.05 },

    // --- DE Objects ---
    { key: 'de_object_sources', step: 'b7', group: 'DE Object Sources', type: 'multiselect',
      label: 'DE Object Sources',
      desc: 'Which normalized objects to use for DE analysis.',
      detail: 'Run DE on multiple objects in parallel. "_redeconv" suffixed objects are CLTS-renormalized. Running both enables cross-normalization comparison.',
      options: ['scice', 'scice_redeconv', 'leiden', 'leiden_redeconv', 'choir', 'choir_redeconv', 'idclust', 'idclust_redeconv'],
      default: ['scice', 'scice_redeconv'] },
    { key: 'de_run_cross_object_comparison', step: 'b7', group: 'DE Object Sources', type: 'boolean',
      label: 'Run Cross-Object Comparison',
      desc: 'Compare DE results across different normalization/clustering objects.',
      detail: 'When multiple de_object_sources are specified, compares overlap and concordance of DE results.',
      default: true },

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // B8: VISUALIZATION, GENES & ENVIRONMENT PATHS
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    { key: 'random_seed', step: 'b8', group: 'General', type: 'number',
      label: 'Random Seed',
      desc: 'Seed for reproducible random operations (UMAP, subsampling, etc.).',
      detail: 'Set to any integer for reproducibility across runs.',
      default: 42, min: 1, max: 999999, inputStep: 1 },
    { key: 'integration_normalization_method', step: 'b8', group: 'General', type: 'select',
      label: 'Integration Normalization Method',
      desc: 'Which normalization to use for Module 04. "auto" uses Module 03 winner.',
      detail: '"auto" (recommended) automatically uses the best normalization from Module 03 benchmarking.',
      options: ['auto', 'LogNormalize', 'SCTransform', 'scran', 'scKWARN'],
      default: 'auto' },
    { key: 'max_cells_plot', step: 'b8', group: 'General', type: 'number',
      label: 'Max Cells for Plots',
      desc: 'Maximum cells to display in UMAP and other scatter plots.',
      detail: 'Subsamples cells for plotting to prevent huge file sizes. Set to 0 for no limit.',
      default: 50000, min: 0, max: 500000, inputStep: 5000 },
    { key: 'sex_marker_genes', step: 'b8', group: 'Genes of Interest', type: 'text',
      label: 'Sex Marker Genes',
      desc: 'Comma-separated list of sex-linked marker genes for validation plots.',
      detail: 'Used to generate feature plots validating sex annotation. Typical: Xist, Tsix, Ddx3y, Eif2s3y, Kdm5d, Uty.',
      default: 'Xist, Tsix, Ddx3y, Eif2s3y, Kdm5d, Uty' },
    { key: 'cp_marker_genes', step: 'b8', group: 'Genes of Interest', type: 'text',
      label: 'Choroid Plexus Marker Genes',
      desc: 'Comma-separated list of choroid plexus marker genes.',
      detail: 'Markers for validating choroid plexus epithelial cell identity.',
      default: 'Ttr, Folr1, Aqp1, Cldn1, Otx2, Enpp2' },
    { key: 'genes_of_interest', step: 'b8', group: 'Genes of Interest', type: 'text',
      label: 'Additional Genes of Interest',
      desc: 'Comma-separated list of additional genes to plot.',
      detail: 'Custom genes for feature plots, violin plots, and dot plots in the visualization module.',
      default: 'Xist, Tsix, Ddx3y, Ttr, Folr1, Aqp1' },
    { key: 'fibroblast_markers', step: 'b8', group: 'Genes of Interest', type: 'text',
      label: 'Fibroblast Marker Genes',
      desc: 'Comma-separated list of fibroblast/stromal marker genes.',
      detail: 'Markers for identifying fibroblast/mesenchymal cells in heterogeneous tissue.',
      default: 'Col1a1, Col3a1, Dcn, Pdgfra, Vim, Fn1' },
    { key: 'plot_formats', step: 'b8', group: 'Plot Settings', type: 'multiselect',
      label: 'Plot Output Formats',
      desc: 'File formats for saving plots.',
      detail: 'Select which formats to generate. PDF is vector-based (publication quality). PNG is raster (for presentations).',
      options: ['png', 'pdf', 'tiff', 'svg'],
      default: ['png', 'pdf'] },
    { key: 'plot_dpi', step: 'b8', group: 'Plot Settings', type: 'number',
      label: 'Plot DPI',
      desc: 'Resolution (dots per inch) for raster plot outputs.',
      detail: 'Standard: 300 DPI for publication, 150 for screen. Higher = larger files.',
      default: 300, min: 72, max: 600, inputStep: 50 },
    { key: 'plot_width_in', step: 'b8', group: 'Plot Settings', type: 'number',
      label: 'Plot Width (inches)',
      desc: 'Default width for saved plots in inches.',
      detail: 'Standard width for output plots. 7 is typical for single-panel figures.',
      default: 7, min: 2, max: 20, inputStep: 0.5 },
    { key: 'plot_height_in', step: 'b8', group: 'Plot Settings', type: 'number',
      label: 'Plot Height (inches)',
      desc: 'Default height for saved plots in inches.',
      detail: 'Standard height for output plots. 5 is typical for single-panel figures.',
      default: 5, min: 2, max: 20, inputStep: 0.5 },
    { key: 'tiff_compression', step: 'b8', group: 'Plot Settings', type: 'select',
      label: 'TIFF Compression',
      desc: 'Compression method for TIFF output files.',
      detail: 'LZW is lossless and widely compatible. Only relevant when "tiff" is included in plot_formats.',
      options: ['lzw', 'none', 'rle', 'jpeg', 'zip', 'deflate'],
      default: 'lzw' },
    { key: 'unified_python', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'Python Path',
      desc: 'Path to Python interpreter with scVI, scCobra, Concord installed.',
      detail: 'The reticulate package uses this Python for all Python-based methods.',
      default: '/path/to/python' },
    { key: 'afmf_python', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'afMF Python Path',
      desc: 'Path to Python interpreter for the afMF imputation conda environment.',
      detail: 'Dedicated conda env for afMF SCImputation. Run setup_afMF_env.sh to create.',
      default: '~/.conda/envs/afMF_SCImputation_env/bin/python' },
    { key: 'scaura_python', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'scAURA Python Path',
      desc: 'Path to Python interpreter for scAURA.',
      detail: 'Python environment with PyTorch and scAURA dependencies.',
      default: '/path/to/python' },
    { key: 'scaura_repo_path', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'scAURA Repository Path',
      desc: 'Path to cloned scAURA GitHub repository.',
      detail: 'Clone from https://github.com/bozdaglab/scAURA',
      default: '/path/to/scAURA' },
    { key: 'julia_bin', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'Julia Binary Path',
      desc: 'Path to Julia binary for scICE subclustering.',
      detail: 'scICE requires Julia with the scICE.jl package installed.',
      default: '~/julia/bin/julia' },
    { key: 'scice_env', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'scICE Julia Environment',
      desc: 'Path to the Julia environment containing scICE packages.',
      detail: 'Directory where scICE Julia packages are installed.',
      default: 'file.path(Sys.getenv("HOME"), "julia", "julia_envs", "scICE_env")' },
    { key: 'scice_pkg_dir', step: 'b8', group: 'Environment Paths', type: 'text',
      label: 'scICE Package Directory',
      desc: 'Path to the scICE Julia package source code.',
      detail: 'Directory containing the scICE.jl source files.',
      default: 'file.path(Sys.getenv("HOME"), "julia", "julia_envs", "scICE_env", "scICE")' },
  ];
}

function getDefaultParams() {
  const defs = getParamDefinitions();
  const p = {};
  defs.forEach(d => { p[d.key] = d.default; });
  return p;
}

// ================================================================
// RENDER PARAMETER STEPS (B1‚ÄìB8)
// ================================================================
const stepTitles = {
  b1: ['Project & Input Configuration', 'Configure project paths and input file locations.'],
  b2: ['Quality Control & Filtering', 'Set cell and gene filtering thresholds.'],
  b3: ['Normalization Settings', 'Choose normalization methods and benchmarking strategy.'],
  b4: ['Imputation Settings', 'Configure optional imputation for visualization.'],
  b5: ['Integration Settings', 'Configure batch correction and integration methods.'],
  b6: ['Clustering Settings', 'Configure clustering algorithms and parameters.'],
  b7: ['Differential Expression', 'Set up DE comparisons, methods, and covariates.'],
  b8: ['Visualization & Environment', 'General settings, paths, and environment configuration.'],
};

function renderParamStep(stepId) {
  const panel = document.getElementById(`step-${stepId}`);
  const [title, subtitle] = stepTitles[stepId];
  const defs = getParamDefinitions().filter(d => d.step === stepId);
  const groups = [...new Set(defs.map(d => d.group))];

  // Dynamically populate select options from sample sheet
  populateDynamicOptions(defs);

  const approvedCount = defs.filter(d => AppState.paramApproved[d.key]).length;

  let html = `<div class="step-header"><h2>${title}</h2><p>${subtitle}</p></div>`;

  html += `<div class="approve-all-bar">
    <span class="status">${approvedCount} / ${defs.length} parameters confirmed</span>
    <button class="btn btn-success btn-sm" onclick="approveAllInStep('${stepId}')">‚úì Approve All in This Section</button>
  </div>`;

  groups.forEach(group => {
    html += `<div class="param-group-title">${group}</div>`;
    defs.filter(d => d.group === group).forEach(d => {
      html += renderParamRow(d);
    });
  });

  const prevStep = AppState.stepsOrder[AppState.stepsOrder.indexOf(stepId) - 1];
  const nextStep = AppState.stepsOrder[AppState.stepsOrder.indexOf(stepId) + 1];

  html += `<div class="step-navigation">
    <button class="btn" onclick="goToStep('${prevStep}')">‚Üê Back</button>
    <button class="btn btn-primary btn-lg" onclick="goToStep('${nextStep}')">Continue ‚Üí</button>
  </div>`;

  panel.innerHTML = html;
}

function populateDynamicOptions(defs) {
  const { headers, columnRoles } = AppState.sampleSheet;
  const metaCols = headers.length > 0 ? headers : ['batch', 'sample_name', 'condition'];

  defs.forEach(d => {
    if (d.key === 'batch_variable') {
      d.options = metaCols;
    }
    if (d.key === 'de_comparison_variable') {
      d.options = metaCols;
    }
    if (d.key === 'de_covariates') {
      d.options = ['percent.mt', 'nFeature_RNA', 'nCount_RNA', ...metaCols.filter(c => !['sample_name', 'sample_id'].includes(c.toLowerCase()))];
      d.options = [...new Set(d.options)];
    }
  });
}

function renderParamRow(def) {
  const val = AppState.params[def.key] ?? def.default;
  const approved = AppState.paramApproved[def.key];
  const statusCls = approved ? 'approved' : '';
  const statusIcon = approved ? '‚úÖ' : '‚óã';

  // Check for context-aware warnings
  let warningHtml = '';
  if (def.key === 'batch_variable' && AppState.sampleSheet.detected.batchEqualsCondition && val === 'batch') {
    warningHtml = `<div class="param-warning">‚ö† Batch is confounded with condition. Consider using "sample_name" instead.</div>`;
  }
  if (def.key === 'run_normalization_benchmarking') {
    const normMethods = ['run_sctransform', 'run_scran', 'run_lognorm', 'run_sckwarn'];
    const enabledCount = normMethods.filter(k => AppState.params[k]).length;
    if (enabledCount < 2) {
      warningHtml = `<div class="param-warning">‚ö† At least 2 normalization methods must be enabled for benchmarking to be meaningful.</div>`;
    }
  }

  let inputHtml = '';
  if (def.type === 'boolean') {
    inputHtml = `<select class="param-input select" id="param-${def.key}" onchange="onParamChange('${def.key}', this.value === 'true')">
      <option value="true" ${val === true ? 'selected' : ''}>TRUE</option>
      <option value="false" ${val === false ? 'selected' : ''}>FALSE</option>
    </select>`;
  } else if (def.type === 'select') {
    const opts = (def.options || []).map(o =>
      `<option value="${esc(o)}" ${val === o ? 'selected' : ''}>${esc(o)}</option>`
    ).join('');
    inputHtml = `<select class="param-input select" id="param-${def.key}" onchange="onParamChange('${def.key}', this.value)">${opts}</select>`;
  } else if (def.type === 'number') {
    inputHtml = `<input type="number" class="param-input" id="param-${def.key}" value="${val ?? ''}"
      ${def.min !== undefined ? `min="${def.min}"` : ''} ${def.max !== undefined ? `max="${def.max}"` : ''}
      ${def.inputStep !== undefined ? `step="${def.inputStep}"` : ''}
      onchange="onParamChange('${def.key}', parseFloat(this.value))">`;
  } else if (def.type === 'multiselect') {
    const selected = Array.isArray(val) ? val : [val];
    inputHtml = `<div class="chip-container" id="param-${def.key}">`;
    (def.options || []).forEach(o => {
      const sel = selected.includes(o) ? 'selected' : '';
      inputHtml += `<span class="chip ${sel}" onclick="toggleChip('${def.key}', '${esc(o)}', this)">${esc(o)}</span>`;
    });
    inputHtml += '</div>';
  } else {
    inputHtml = `<input type="text" class="param-input" id="param-${def.key}" value="${esc(String(val ?? ''))}"
      onchange="onParamChange('${def.key}', this.value)">`;
  }

  return `<div class="param-row ${statusCls}" id="row-${def.key}">
    <div class="param-info">
      <div class="param-name"><span class="status-icon">${statusIcon}</span> ${def.key}</div>
      <div class="param-desc">${def.desc}</div>
      <div class="param-input-row">${inputHtml}</div>
      ${warningHtml}
      <button class="param-detail-toggle" onclick="toggleDetail('${def.key}')">Show details</button>
      <div class="param-detail" id="detail-${def.key}">${def.detail}</div>
    </div>
    <div class="param-actions">
      <button class="btn btn-success btn-sm" onclick="approveParam('${def.key}')">‚úì Confirm</button>
      <button class="btn btn-sm" onclick="resetParam('${def.key}')">‚Ü∫ Reset</button>
    </div>
  </div>`;
}

// ================================================================
// PARAMETER INTERACTION HANDLERS
// ================================================================
function onParamChange(key, value) {
  AppState.params[key] = value;
  AppState.paramApproved[key] = false;
  const row = document.getElementById(`row-${key}`);
  if (row) {
    row.classList.remove('approved');
    row.classList.add('modified');
    const icon = row.querySelector('.status-icon');
    if (icon) icon.textContent = '‚úèÔ∏è';
  }
}

function approveParam(key) {
  AppState.paramApproved[key] = true;
  const row = document.getElementById(`row-${key}`);
  if (row) {
    row.classList.remove('modified');
    row.classList.add('approved');
    const icon = row.querySelector('.status-icon');
    if (icon) icon.textContent = '‚úÖ';
  }
  updateStepApprovalCount();
}

function resetParam(key) {
  const def = getParamDefinitions().find(d => d.key === key);
  if (!def) return;
  AppState.params[key] = def.default;
  AppState.paramApproved[key] = false;
  // Re-render the current step
  renderParamStep(AppState.currentStep);
}

function approveAllInStep(stepId) {
  const defs = getParamDefinitions().filter(d => d.step === stepId);
  defs.forEach(d => {
    AppState.paramApproved[d.key] = true;
  });
  renderParamStep(stepId);
  completeStep(stepId);
}

function updateStepApprovalCount() {
  const stepId = AppState.currentStep;
  const defs = getParamDefinitions().filter(d => d.step === stepId);
  const approved = defs.filter(d => AppState.paramApproved[d.key]).length;
  const bar = document.querySelector('.approve-all-bar .status');
  if (bar) bar.textContent = `${approved} / ${defs.length} parameters confirmed`;
  if (approved === defs.length) completeStep(stepId);
}

function toggleDetail(key) {
  const detail = document.getElementById(`detail-${key}`);
  if (detail) detail.classList.toggle('open');
}

function toggleChip(paramKey, value, el) {
  el.classList.toggle('selected');
  const container = document.getElementById(`param-${paramKey}`);
  const selected = [...container.querySelectorAll('.chip.selected')].map(c => c.textContent);
  AppState.params[paramKey] = selected;
  AppState.paramApproved[paramKey] = false;
}

// ================================================================
// B9: FINAL REVIEW & EXPORT
// ================================================================
function renderFinalReview() {
  let html = '';

  // Validation
  const checks = validateParamsR();
  html += '<div class="card"><div class="card-header">‚úÖ Validation Results</div>';
  html += '<ul class="validation-list">';
  checks.forEach(c => {
    const icons = { pass: '‚úÖ', warn: '‚ö†Ô∏è', fail: '‚ùå' };
    html += `<li class="validation-item validation-${c.level}">
      <span class="validation-icon">${icons[c.level]}</span><span>${c.msg}</span></li>`;
  });
  html += '</ul></div>';

  // Approval summary
  const defs = getParamDefinitions();
  const approved = defs.filter(d => AppState.paramApproved[d.key]).length;
  const total = defs.length;
  html += `<div class="alert ${approved === total ? 'alert-success' : 'alert-warning'}">
    <strong>${approved} / ${total}</strong> parameters confirmed.
    ${approved < total ? 'Unconfirmed parameters will use their current values.' : 'All parameters confirmed!'}
  </div>`;

  // Generate both versions
  const fullCode = generateFullParamsR();
  const flatCode = generateParamsRCode();

  // Count how many CFG tags were replaced
  const templateText = document.getElementById('paramsTemplate').textContent;
  const totalTags = (templateText.match(/<<CFG:\w+>>/g) || []).length;
  const injectedCount = Object.keys(AppState.params).length;

  html += `<div class="alert alert-info">
    <strong>Template-based export:</strong> Your ${injectedCount} configured values are injected into the full ${totalTags}-tag pipeline template.
    All infrastructure code, environment detection, sample sheet loading, validation functions, and configuration summary are preserved.
  </div>`;

  // Preview tabs
  html += `<div style="display:flex; gap:8px; margin-bottom:12px;">
    <button class="btn btn-sm" id="tabFull" onclick="switchPreviewTab('full')" style="background:var(--accent-primary);border-color:var(--accent-primary);color:#fff;">Full Template</button>
    <button class="btn btn-sm" id="tabFlat" onclick="switchPreviewTab('flat')">Flat Params Only</button>
    <button class="btn btn-sm" id="tabDiff" onclick="switchPreviewTab('diff')">Changed Values</button>
  </div>`;

  // Full template preview
  html += `<div class="card" id="previewFull"><div class="card-header">üìú Full params.R (${fullCode.split('\n').length} lines)</div>
    <div class="code-preview" style="max-height:600px;">${highlightR(fullCode)}</div></div>`;

  // Flat preview (hidden by default)
  html += `<div class="card" id="previewFlat" style="display:none;"><div class="card-header">üìã Flat Params List</div>
    <div class="code-preview" style="max-height:600px;">${highlightR(flatCode)}</div></div>`;

  // Diff preview (hidden by default)
  html += `<div class="card" id="previewDiff" style="display:none;"><div class="card-header">üîÑ Changed Values (non-default)</div>
    <div id="diffContent"></div></div>`;

  // Rebuild panel
  const panel = document.getElementById('step-b9');
  const header = panel.querySelector('.step-header');

  panel.innerHTML = '';
  panel.appendChild(header);

  const content = document.createElement('div');
  content.innerHTML = html;
  panel.appendChild(content);

  // Build the diff view content
  buildDiffView();

  const btnDiv = document.createElement('div');
  btnDiv.style.cssText = 'display:flex; gap:12px; margin-top:24px; flex-wrap:wrap;';
  btnDiv.innerHTML = `<button class="btn btn-success btn-lg" onclick="downloadFullParamsR()">‚¨á Download Full params.R</button>
    <button class="btn btn-lg" onclick="copyFullParamsR()">üìã Copy Full to Clipboard</button>
    <button class="btn btn-sm" onclick="downloadFlatParamsR()" title="Minimal params list without pipeline infrastructure">‚¨á Flat params only</button>`;
  panel.appendChild(btnDiv);

  const navDiv = document.createElement('div');
  navDiv.className = 'step-navigation';
  navDiv.innerHTML = `<button class="btn" onclick="goToStep('b8')">‚Üê Back</button><span></span>`;
  panel.appendChild(navDiv);
}

function switchPreviewTab(tab) {
  document.getElementById('previewFull').style.display = tab === 'full' ? '' : 'none';
  document.getElementById('previewFlat').style.display = tab === 'flat' ? '' : 'none';
  document.getElementById('previewDiff').style.display = tab === 'diff' ? '' : 'none';

  document.getElementById('tabFull').style.cssText = tab === 'full' ? 'background:var(--accent-primary);border-color:var(--accent-primary);color:#fff;' : '';
  document.getElementById('tabFlat').style.cssText = tab === 'flat' ? 'background:var(--accent-primary);border-color:var(--accent-primary);color:#fff;' : '';
  document.getElementById('tabDiff').style.cssText = tab === 'diff' ? 'background:var(--accent-primary);border-color:var(--accent-primary);color:#fff;' : '';
}

function buildDiffView() {
  const container = document.getElementById('diffContent');
  if (!container) return;

  const defs = getParamDefinitions();
  const p = AppState.params;
  let html = '<div style="font-family:var(--font-mono); font-size:0.82rem;">';
  let changeCount = 0;

  defs.forEach(d => {
    const current = p[d.key];
    const def = d.default;
    const currentR = rValTemplate(current, d.key);
    const defaultR = rValTemplate(def, d.key);

    if (currentR !== defaultR) {
      changeCount++;
      html += `<div style="padding:8px 12px; margin-bottom:6px; background:var(--bg-card); border:1px solid var(--border-primary); border-radius:var(--radius-sm); border-left:3px solid var(--warning);">
        <span style="color:var(--text-accent);">${d.key}</span><br>
        <span style="color:var(--text-muted); text-decoration:line-through;">${esc(defaultR)}</span>
        <span style="color:var(--text-muted);"> ‚Üí </span>
        <span style="color:var(--success);">${esc(currentR)}</span>
      </div>`;
    }
  });

  if (changeCount === 0) {
    html += '<div class="alert alert-success">All parameters match their defaults.</div>';
  } else {
    html = `<div class="alert alert-info" style="margin-bottom:12px;"><strong>${changeCount}</strong> parameter(s) changed from defaults.</div>` + html;
  }

  html += '</div>';
  container.innerHTML = html;
}

function validateParamsR() {
  const checks = [];
  const p = AppState.params;

  // Required string params not empty
  ['project_root', 'dataset_name'].forEach(k => {
    const val = p[k];
    const ok = val && String(val).trim() !== '' && val !== '/path/to/your/dataset';
    checks.push({ pass: ok, msg: `${k} is set`, level: ok ? 'pass' : 'warn' });
  });

  // At least 2 norm methods for benchmarking
  if (p.run_normalization_benchmarking) {
    const normCount = ['run_sctransform','run_scran','run_lognorm','run_sckwarn'].filter(k => p[k]).length;
    checks.push({ pass: normCount >= 2, msg: `At least 2 normalization methods enabled (found ${normCount})`,
      level: normCount >= 2 ? 'pass' : 'fail' });
  }

  // At least 1 DE method
  const deCount = ['run_mast','run_dream','run_pseudobulk_edger','run_pseudobulk_deseq2','run_permutation'].filter(k => p[k]).length;
  checks.push({ pass: deCount >= 1, msg: `At least 1 DE method enabled (found ${deCount})`,
    level: deCount >= 1 ? 'pass' : 'warn' });

  // At least 1 clustering method
  const clusterCount = ['run_choir_clustering','run_scaura_clustering','run_leiden_clustering'].filter(k => p[k]).length;
  checks.push({ pass: clusterCount >= 1, msg: `At least 1 clustering method enabled (found ${clusterCount})`,
    level: clusterCount >= 1 ? 'pass' : 'fail' });

  // Subclustering requires clustering
  if (p.run_scice_subclustering || p.run_idclust_subclustering) {
    const hasUpstream = p.run_choir_clustering || p.run_scaura_clustering;
    checks.push({ pass: hasUpstream, msg: 'Subclustering enabled requires CHOIR or scAURA upstream',
      level: hasUpstream ? 'pass' : 'warn' });
  }

  // IDclust starting resolution < resolution
  if (p.run_idclust_subclustering) {
    const startRes = p.idclust_starting_resolution ?? 0.1;
    const mainRes = p.idclust_resolution ?? 0.8;
    checks.push({ pass: startRes <= mainRes,
      msg: `IDclust starting_resolution (${startRes}) ‚â§ resolution (${mainRes})`,
      level: startRes <= mainRes ? 'pass' : 'warn' });
  }

  // scICE + IDclust depth sanity
  if (p.run_idclust_subclustering && (p.idclust_max_depth ?? 10) > 15) {
    checks.push({ pass: false, msg: `IDclust max_depth is very high (${p.idclust_max_depth}), may cause excessive runtime`,
      level: 'warn' });
  }

  // CLTS + DE object consistency
  if (p.run_clts_renormalization) {
    const deSources = Array.isArray(p.de_object_sources) ? p.de_object_sources : [];
    const hasRedeconv = deSources.some(s => s.includes('_redeconv'));
    checks.push({ pass: hasRedeconv, msg: 'CLTS enabled and _redeconv included in DE object sources',
      level: hasRedeconv ? 'pass' : 'warn' });
  }

  // Batch variable check
  if (AppState.sampleSheet.detected.batchEqualsCondition && p.batch_variable === 'batch') {
    checks.push({ pass: false, msg: 'batch_variable is "batch" but batch=condition confounding detected',
      level: 'warn' });
  } else {
    checks.push({ pass: true, msg: 'batch_variable configuration looks appropriate', level: 'pass' });
  }

  // DE covariates include batch
  const covs = Array.isArray(p.de_covariates) ? p.de_covariates : [];
  const hasBatchCov = covs.includes('batch') || covs.includes('condition');
  checks.push({ pass: hasBatchCov, msg: 'DE covariates include batch or condition',
    level: hasBatchCov ? 'pass' : 'warn' });

  // Python path check
  const pyPath = p.unified_python || '';
  const pyOk = pyPath !== '' && pyPath !== '/path/to/python';
  if (p.run_python_integrations || p.run_concord) {
    checks.push({ pass: pyOk, msg: 'Python path is set (required for Python integrations)',
      level: pyOk ? 'pass' : 'warn' });
  }

  return checks;
}

// ================================================================
// GENERATE params.R CODE
// ================================================================
function generateParamsRCode() {
  const p = AppState.params;
  const timestamp = new Date().toISOString().split('T')[0];

  const rVal = (v, key) => {
    if (v === null || v === undefined) return 'NULL';
    if (v === true) return 'TRUE';
    if (v === false) return 'FALSE';
    if (Array.isArray(v)) {
      // Sanitize array elements: fix cases where two quoted strings got merged without comma
      const cleaned = [];
      v.forEach(el => {
        if (typeof el === 'string') {
          // Split merged quoted strings like: '"Uty" "Ttr"' into separate elements
          const merged = el.match(/"[^"]*"/g) || el.match(/'[^']*'/g);
          if (merged && merged.length > 1) {
            merged.forEach(m => cleaned.push(m.replace(/^["']|["']$/g, '')));
            return;
          }
          // Also handle space-separated unquoted values (parsing artifact)
          const parts = el.trim().split(/\s+/);
          if (parts.length > 1) {
            parts.forEach(p => cleaned.push(p));
            return;
          }
        }
        cleaned.push(el);
      });
      if (cleaned.length === 0) return 'c()';
      return `c(${cleaned.map(x => typeof x === 'number' ? x : `"${x}"`).join(', ')})`;
    }
    if (typeof v === 'number') return String(v);
    // Keys where empty string means NULL in R
    const nullableKeys = ['scice_target_clusters','idclust_target_clusters','de_target_clusters','clts_cluster_column','alra_k'];
    if (nullableKeys.includes(key) && (v === '' || v === 'NULL')) return 'NULL';
    // Keys that should be exported as integers even if stored as strings
    const intKeys = ['leiden_algorithm'];
    if (intKeys.includes(key) && !isNaN(parseInt(v))) return String(parseInt(v));
    // Detect R expressions ‚Äî export verbatim without quotes
    // Matches: function calls like file.path(...), log2(...), Sys.getenv(...), tryCatch(...)
    // Also: if (...) ... else ...
    if (typeof v === 'string') {
      const trimV = v.trim();
      if (/^[a-zA-Z_.][a-zA-Z0-9_.]*\s*\(/.test(trimV) || /^if\s*\(/.test(trimV)) return trimV;
    }
    // Handle comma-separated text fields that should become R vectors
    const vectorKeys = ['leiden_resolutions','sex_marker_genes','cp_marker_genes','genes_of_interest','fibroblast_markers','scice_target_clusters','idclust_target_clusters','de_target_clusters'];
    if (vectorKeys.includes(key) && typeof v === 'string' && v.includes(',')) {
      const items = v.split(',').map(s => s.trim()).filter(Boolean);
      // Check if all items are numeric
      if (items.every(s => !isNaN(parseFloat(s)))) {
        return `c(${items.join(', ')})`;
      }
      return `c(${items.map(s => `"${s}"`).join(', ')})`;
    }
    return `"${String(v).replace(/"/g, '\\"')}"`;
  };

  const sections = [
    { title: 'Project & Input Configuration', keys: ['project_root','dataset_name','input_dir','input_file_pattern','files_in_subdirectories','counts_layer_to_use','out_root'] },
    { title: 'QC & Filtering', keys: ['skip_all_filtering','apply_qc_filtering','filter_by_min_features','filter_by_max_features','filter_by_percent_mt','min_features','max_features','max_percent_mt','filter_genes_by_min_cells','min_cells_per_gene','filter_doublets','doublet_column','doublet_value_to_remove','doublet_vote_column','use_doublet_vote_threshold','doublet_vote_threshold','filter_hemoglobin','max_percent_hb','hemoglobin_pattern'] },
    { title: 'Normalization', keys: ['run_sctransform','run_scran','run_lognorm','run_sckwarn','sct_vars_to_regress','sct_method','scran_min_mean','nfeatures_integration','run_normalization_benchmarking','norm_benchmark_integration_methods','norm_benchmark_max_cells'] },
    { title: 'Imputation', keys: ['imputation_method','use_afmf_for_normalization','afmf_max_iter','afmf_tol','afmf_min_cells_expressing','use_alra_for_downstream','alra_q','alra_quantile_prob','alra_k','alra_compatible_methods'] },
    { title: 'Integration', keys: ['run_batch_integration','batch_variable','integration_selection_mode','celltype_column','bio_weight','batch_weight','dims_use','vars_to_regress','integration_methods_r','run_integration_benchmarking','run_python_integrations','integration_methods_python','run_sccobra','run_concord','concord_n_top_features','concord_n_latent','concord_max_epochs','concord_batch_size','concord_lr','concord_early_stopping_patience','concord_preload_dense','concord_device'] },
    { title: 'CHOIR Clustering', keys: ['run_choir_clustering','choir_alpha','choir_use_assay'] },
    { title: 'scAURA Clustering', keys: ['run_scaura_clustering','scaura_k_clusters','scaura_kmax','scaura_hidden_dim','scaura_tau','scaura_tau_plus','scaura_pe','scaura_pf','scaura_epochs','scaura_lr','scaura_self_train','scaura_n_top_genes','scaura_use_gpu'] },
    { title: 'Clustering Source & Leiden', keys: ['scice_clustering_source','run_leiden_clustering','leiden_resolutions','leiden_algorithm','final_resolution','leiden_n_neighbors','run_clustering_quality'] },
    { title: 'scICE Subclustering', keys: ['run_scice_subclustering','scice_k_min','scice_k_max','scice_ic_threshold','scice_min_cells','scice_target_clusters'] },
    { title: 'IDclust Subclustering', keys: ['run_idclust_subclustering','idclust_logFC_th','idclust_qval_th','idclust_min_DEGs','idclust_max_depth','idclust_resolution','idclust_min_cells','idclust_target_clusters','idclust_min_frac_assigned','idclust_n_dims','idclust_starting_resolution','idclust_starting_k','idclust_k','idclust_plotting'] },
    { title: 'Unified Subclustering', keys: ['subclustering_methods','subclustering_source'] },
    { title: 'Differential Expression', keys: ['de_comparison_variable','de_group1','de_group2','de_comparison_scope','de_covariates','de_target_clusters','run_mast','run_dream','run_pseudobulk_edger','run_pseudobulk_deseq2','run_permutation','run_negative_control','de_logfc_threshold','de_pval_threshold','de_min_pct'] },
    { title: 'CLTS Re-normalization', keys: ['run_clts_renormalization','clts_clustering_source','clts_cluster_column','clts_min_cells_per_cluster','clts_baseline_sample','clts_run_benchmark','clts_marker_logfc_threshold','clts_marker_pval_threshold','clts_marker_min_pct'] },
    { title: 'DE Object Sources', keys: ['de_object_sources','de_run_cross_object_comparison'] },
    { title: 'Visualization & Genes', keys: ['random_seed','integration_normalization_method','max_cells_plot','sex_marker_genes','cp_marker_genes','fibroblast_markers','genes_of_interest','plot_formats','plot_dpi','plot_width_in','plot_height_in','tiff_compression'] },
    { title: 'Environment Paths', keys: ['unified_python','afmf_python','scaura_python','scaura_repo_path','julia_bin','scice_env','scice_pkg_dir'] },
  ];

  let code = `# ==============================================================================\n`;
  code += `# params.R ‚Äî Pipeline Configuration\n`;
  code += `# Generated by scRNA-seq Pipeline Configurator on ${timestamp}\n`;
  code += `# ==============================================================================\n\n`;
  code += `params <- list(\n`;

  const allEntries = [];

  sections.forEach((sec, si) => {
    allEntries.push({ type: 'comment', text: `  # --- ${sec.title} ---` });
    sec.keys.forEach(key => {
      if (p.hasOwnProperty(key)) {
        allEntries.push({ type: 'param', key, value: rVal(p[key], key) });
      }
    });
    allEntries.push({ type: 'blank' });
  });

  // Also include any extra params loaded from file but not in our definitions
  const definedKeys = new Set(sections.flatMap(s => s.keys));
  const extraKeys = Object.keys(p).filter(k => !definedKeys.has(k));
  if (extraKeys.length > 0) {
    allEntries.push({ type: 'comment', text: '  # --- Additional Parameters (from loaded file) ---' });
    extraKeys.forEach(key => {
      allEntries.push({ type: 'param', key, value: rVal(p[key], key) });
    });
  }

  // Remove trailing blank
  while (allEntries.length > 0 && allEntries[allEntries.length - 1].type === 'blank') allEntries.pop();

  allEntries.forEach((entry, i) => {
    if (entry.type === 'comment') {
      code += entry.text + '\n';
    } else if (entry.type === 'blank') {
      code += '\n';
    } else if (entry.type === 'param') {
      const isLast = !allEntries.slice(i + 1).some(e => e.type === 'param');
      const comma = isLast ? '' : ',';
      const padding = Math.max(1, 35 - entry.key.length);
      code += `  ${entry.key}${' '.repeat(padding)}= ${entry.value}${comma}\n`;
    }
  });

  code += `)\n`;
  return code;
}



// ================================================================
// GENERATE FULL params.R FROM TEMPLATE (TAG-BASED)
// ================================================================

/**
 * Converts a JS value to R syntax for template injection.
 * Similar to rVal but used specifically for the template-based export.
 */
function rValTemplate(v, key) {
  if (v === null || v === undefined) return 'NULL';
  if (v === true) return 'TRUE';
  if (v === false) return 'FALSE';
  if (Array.isArray(v)) {
    const cleaned = [];
    v.forEach(el => {
      if (typeof el === 'string') {
        // Split merged quoted strings like: '"Uty" "Ttr"' into separate elements
        const merged = el.match(/"[^"]*"/g) || el.match(/'[^']*'/g);
        if (merged && merged.length > 1) {
          merged.forEach(m => cleaned.push(m.replace(/^["']|["']$/g, '')));
          return;
        }
      }
      cleaned.push(el);
    });
    if (cleaned.length === 0) return 'c()';
    if (cleaned.every(x => typeof x === 'number')) {
      return `c(${cleaned.join(', ')})`;
    }
    return `c(${cleaned.map(x => typeof x === 'number' ? x : `"${x}"`).join(', ')})`;
  }
  if (typeof v === 'number') return String(v);

  // Keys where empty string means NULL in R
  const nullableKeys = ['scice_target_clusters','idclust_target_clusters','de_target_clusters','clts_cluster_column','alra_k'];
  if (nullableKeys.includes(key) && (v === '' || v === 'NULL')) return 'NULL';

  // Keys that should be exported as integers
  const intKeys = ['leiden_algorithm'];
  if (intKeys.includes(key) && !isNaN(parseInt(v))) return String(parseInt(v));

  // Detect R expressions ‚Äî export verbatim without quotes
  if (typeof v === 'string') {
    const trimV = v.trim();
    if (/^[a-zA-Z_.][a-zA-Z0-9_.]*\s*\(/.test(trimV) || /^if\s*\(/.test(trimV)) return trimV;
  }

  // Handle comma-separated text fields that should become R vectors
  const vectorKeys = ['leiden_resolutions','sex_marker_genes','cp_marker_genes','genes_of_interest','fibroblast_markers','scice_target_clusters','idclust_target_clusters','de_target_clusters'];
  if (vectorKeys.includes(key) && typeof v === 'string' && v.includes(',')) {
    const items = v.split(',').map(s => s.trim()).filter(Boolean);
    if (items.every(s => !isNaN(parseFloat(s)))) {
      return `c(${items.join(', ')})`;
    }
    return `c(${items.map(s => `"${s}"`).join(', ')})`;
  }

  return `"${String(v).replace(/"/g, '\\"')}"`;
}

/**
 * Generate the full params.R by injecting configured values into the template.
 * Only lines with <<CFG:param_name>> tags are modified.
 * All infrastructure, logic, validation, and comments are preserved verbatim.
 */
function generateFullParamsR() {
  const p = AppState.params;
  const templateText = document.getElementById('paramsTemplate').textContent;
  const lines = templateText.split('\n');

  // Tag-to-param-key mapping for tags that don't match the param key directly
  const tagToParam = {
    'legacy_input_dir': 'input_dir',
    'legacy_input_file_pattern': 'input_file_pattern',
    'legacy_files_in_subdirectories': 'files_in_subdirectories',
  };

  const result = lines.map(line => {
    // Check if line has a CFG tag
    const tagMatch = line.match(/<<CFG:(\w+)>>/);
    if (!tagMatch) return line;

    const tag = tagMatch[1];
    const paramKey = tagToParam[tag] || tag;

    // Skip if we don't have a configured value for this param
    if (!p.hasOwnProperty(paramKey)) return line;

    const value = p[paramKey];
    const rValue = rValTemplate(value, paramKey);

    // --- Replacement strategy ---
    // Use findCommentStart() to properly locate the first unquoted #,
    // preserving inline documentation comments like:
    //   alra_k = NULL,  # SVD rank (NULL = auto-detect)  # <<CFG:alra_k>>
    //   batch_variable = "sample_name",  # Instead of "batch",  # <<CFG:batch_variable>>

    const commentIdx = findCommentStart(line);
    if (commentIdx < 0) return line; // shouldn't happen for tagged lines

    const codePart = line.substring(0, commentIdx);
    const commentPart = line.substring(commentIdx);

    // Find the assignment operator in the code part
    const arrowIdx = codePart.indexOf('<-');
    let opEnd;
    if (arrowIdx >= 0) {
      opEnd = arrowIdx + 2; // after '<-'
    } else {
      // For list entries: find '=' after param name
      const eqMatch = codePart.match(/^(\s*[\w.]+\s*)=/);
      if (eqMatch) {
        opEnd = eqMatch[1].length + 1; // after '='
      } else {
        return line; // can't parse, keep original
      }
    }

    const prefix = codePart.substring(0, opEnd); // e.g. "  batch_variable ="
    const valueArea = codePart.substring(opEnd);  // e.g. ' "sample_name",      '

    // Check if value area has a trailing comma (list entry separator)
    const hasComma = valueArea.trim().endsWith(',');
    const comma = hasComma ? ',' : '';

    return `${prefix} ${rValue}${comma}  ${commentPart}`;
  });

  return result.join('\n');
}

function highlightR(code) {
  return code
    .replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;')
    .replace(/(#[^\n]*)/g, '<span class="comment">$1</span>')
    .replace(/("(?:[^"\\]|\\.)*")/g, '<span class="string">$1</span>')
    .replace(/\b(TRUE|FALSE|NULL|params|list|c)\b/g, '<span class="keyword">$1</span>')
    .replace(/\b(\d+\.?\d*(?:e[+-]?\d+)?)\b/g, '<span class="number">$1</span>');
}

// ================================================================
// DOWNLOAD & CLIPBOARD
// ================================================================
function downloadFile(content, filename, mimeType) {
  const blob = new Blob([content], { type: mimeType });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url; a.download = filename;
  document.body.appendChild(a); a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}

function downloadFullParamsR() {
  const code = generateFullParamsR();
  downloadFile(code, 'params.R', 'text/plain');
}

function copyFullParamsR() {
  const code = generateFullParamsR();
  navigator.clipboard.writeText(code).then(() => {
    alert('Full params.R copied to clipboard!');
  }).catch(() => {
    const ta = document.createElement('textarea');
    ta.value = code; document.body.appendChild(ta);
    ta.select(); document.execCommand('copy');
    document.body.removeChild(ta);
    alert('Full params.R copied to clipboard!');
  });
}

function downloadFlatParamsR() {
  const code = generateParamsRCode();
  downloadFile(code, 'params_flat.R', 'text/plain');
}

// Keep backward-compatible names
function downloadParamsR() { downloadFullParamsR(); }
function copyParamsR() { copyFullParamsR(); }

// ================================================================
// SESSION SAVE / LOAD
// ================================================================
function exportState() {
  const state = {
    sampleSheet: AppState.sampleSheet,
    params: AppState.params,
    paramApproved: AppState.paramApproved,
    paramsLoaded: AppState.paramsLoaded,
  };
  downloadFile(JSON.stringify(state, null, 2), 'pipeline_config_session.json', 'application/json');
}

function importState() {
  const input = document.createElement('input');
  input.type = 'file'; input.accept = '.json';
  input.onchange = e => {
    const reader = new FileReader();
    reader.onload = ev => {
      try {
        const state = JSON.parse(ev.target.result);
        Object.assign(AppState.sampleSheet, state.sampleSheet || {});
        Object.assign(AppState.params, state.params || {});
        Object.assign(AppState.paramApproved, state.paramApproved || {});
        AppState.paramsLoaded = state.paramsLoaded || false;
        if (AppState.paramsLoaded) unlockAllParamSteps();
        if (AppState.sampleSheet.rows.length > 0) {
          ['a2','a3','a4','a5'].forEach(s => unlockStep(s));
          completeStep('a1');
        }
        alert('Session restored successfully!');
      } catch (err) {
        alert('Error loading session: ' + err.message);
      }
    };
    reader.readAsText(e.target.files[0]);
  };
  input.click();
}

// ================================================================
// UTILITY
// ================================================================
function esc(s) {
  const el = document.createElement('span');
  el.textContent = String(s ?? '');
  return el.innerHTML;
}

// ================================================================
// INIT
// ================================================================
updateProgress();
</script>
</body>
</html>
