{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnnData Inspection, Analysis & MapMyCells Export\n",
    "\n",
    "This notebook provides a comprehensive workflow for:\n",
    "1. **Inspecting** an AnnData `.h5ad` file structure (obs, var, layers, obsm, uns, etc.)\n",
    "2. **Analyzing** the counts layer to verify data type (raw UMI counts vs normalized)\n",
    "3. **Exporting** a simplified AnnData suitable for MapMyCells or other downstream tools\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# USER CONFIGURATION - Edit these paths and options as needed\n",
    "# ============================================================\n",
    "\n",
    "# Path to input AnnData file\n",
    "INPUT_H5AD = \"/scicore/home/doetsch/kaiser0001/Single_cell_paper/Output_dir_Single_cell_paper/Single_cell_clustering/10_Downstream_Analysis_All_Samples/final_output_object.h5ad\"\n",
    "\n",
    "# Layer containing raw counts (for analysis and export)\n",
    "COUNTS_LAYER = \"counts\"\n",
    "\n",
    "# === Counts Analysis Options ===\n",
    "ANALYSIS_SEED = 123           # Random seed for reproducibility\n",
    "ANALYSIS_N_CELLS = 1000       # Number of random cells to sample for analysis\n",
    "\n",
    "# === MapMyCells Export Options ===\n",
    "# If None: use adata.obs_names as barcodes\n",
    "# If set to a column name (e.g. \"barcode_cellranger\"): use that column instead\n",
    "BARCODE_SOURCE_OBS_COLUMN = None\n",
    "\n",
    "# Gene name conversion to mouse-style casing (e.g., \"CD74\" -> \"Cd74\")\n",
    "CONVERT_GENE_NAMES_TO_MOUSE_CASE = False\n",
    "\n",
    "# Apply conversion to:\n",
    "#   \"all\"          -> convert every gene name\n",
    "#   \"only_allcaps\" -> convert only genes that are fully uppercase\n",
    "MOUSE_CASE_APPLY_MODE = \"all\"\n",
    "\n",
    "# If conversion yields duplicates, make unique by appending _2, _3, ...\n",
    "MAKE_GENE_NAMES_UNIQUE_IF_NEEDED = True\n",
    "\n",
    "# Overwrite output if it exists\n",
    "OVERWRITE_OUTPUT = True\n",
    "\n",
    "# Print output var preview after export\n",
    "PRINT_OUTPUT_VAR = True\n",
    "OUTPUT_VAR_N_PREVIEW = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scipy.sparse as sp\n",
    "import h5py\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "print(f\"anndata version: {ad.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Helper Functions\n",
    "\n",
    "Utility functions used throughout the notebook for inspection, analysis, and export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper functions for AnnData inspection\n",
    "# ============================================================\n",
    "\n",
    "def _dtype_of(x):\n",
    "    \"\"\"Get dtype of array-like object (works for backed arrays, sparse, memmaps).\"\"\"\n",
    "    try:\n",
    "        return str(x.dtype)\n",
    "    except Exception:\n",
    "        return type(x).__name__\n",
    "\n",
    "\n",
    "def _shape_of(x):\n",
    "    \"\"\"Get shape of array-like object.\"\"\"\n",
    "    try:\n",
    "        return tuple(x.shape)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _summarize_mapping(m, max_items=200):\n",
    "    \"\"\"Summarize keys of a mapping, truncating if too many.\"\"\"\n",
    "    keys = list(m.keys())\n",
    "    if len(keys) > max_items:\n",
    "        keys = keys[:max_items] + [\"...\"]\n",
    "    return keys\n",
    "\n",
    "\n",
    "def _print_uns(obj, indent=0, max_depth=6, max_list_items=30):\n",
    "    \"\"\"Recursively print the structure of uns (unstructured annotations).\"\"\"\n",
    "    pad = \" \" * indent\n",
    "    if indent // 2 >= max_depth:\n",
    "        print(f\"{pad}… (max depth reached)\")\n",
    "        return\n",
    "\n",
    "    if isinstance(obj, Mapping):\n",
    "        for k in list(obj.keys()):\n",
    "            v = obj[k]\n",
    "            if isinstance(v, (Mapping, Sequence)) and not isinstance(v, (str, bytes, bytearray)):\n",
    "                print(f\"{pad}{k}: {type(v).__name__}\")\n",
    "                _print_uns(v, indent=indent + 2, max_depth=max_depth, max_list_items=max_list_items)\n",
    "            else:\n",
    "                s = repr(v)\n",
    "                if len(s) > 120:\n",
    "                    s = s[:117] + \"...\"\n",
    "                print(f\"{pad}{k}: {type(v).__name__} = {s}\")\n",
    "    elif isinstance(obj, Sequence) and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        n = len(obj)\n",
    "        print(f\"{pad}[list/tuple] len={n}\")\n",
    "        for i, v in enumerate(obj[:max_list_items]):\n",
    "            if isinstance(v, (Mapping, Sequence)) and not isinstance(v, (str, bytes, bytearray)):\n",
    "                print(f\"{pad}- [{i}] {type(v).__name__}\")\n",
    "                _print_uns(v, indent=indent + 2, max_depth=max_depth, max_list_items=max_list_items)\n",
    "            else:\n",
    "                s = repr(v)\n",
    "                if len(s) > 120:\n",
    "                    s = s[:117] + \"...\"\n",
    "                print(f\"{pad}- [{i}] {type(v).__name__} = {s}\")\n",
    "        if n > max_list_items:\n",
    "            print(f\"{pad}… ({n - max_list_items} more items)\")\n",
    "    else:\n",
    "        s = repr(obj)\n",
    "        if len(s) > 120:\n",
    "            s = s[:117] + \"...\"\n",
    "        print(f\"{pad}{type(obj).__name__} = {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper functions for counts layer analysis\n",
    "# ============================================================\n",
    "\n",
    "def summarize_values(x, label):\n",
    "    \"\"\"\n",
    "    Summarize numerical values with statistics useful for determining\n",
    "    whether data represents raw counts or normalized values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Array of values to summarize\n",
    "    label : str\n",
    "        Label for the summary output\n",
    "    \"\"\"\n",
    "    if x.size == 0:\n",
    "        print(f\"{label}: empty\")\n",
    "        return\n",
    "    \n",
    "    x = x[np.isfinite(x)]\n",
    "    print(f\"{label}: n={x.size}\")\n",
    "    print(f\"  min={x.min():.6g}  max={x.max():.6g}  mean={x.mean():.6g}  median={np.median(x):.6g}\")\n",
    "    print(f\"  p1={np.quantile(x, 0.01):.6g}  p99={np.quantile(x, 0.99):.6g}\")\n",
    "    \n",
    "    # Check for integer-like values\n",
    "    frac = np.abs(x - np.round(x))\n",
    "    nonint = np.sum(frac > 1e-6)\n",
    "    neg = np.sum(x < -1e-12)\n",
    "    between01 = np.sum((x > 1e-12) & (x < 1 - 1e-6))\n",
    "    \n",
    "    print(f\"  non-integer-like (|x-round(x)|>1e-6): {nonint}  ({100*nonint/x.size:.3f}%)\")\n",
    "    print(f\"  negatives: {neg}  ({100*neg/x.size:.3f}%)\")\n",
    "    print(f\"  values in (0,1): {between01}  ({100*between01/x.size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Helper functions for MapMyCells export\n",
    "# ============================================================\n",
    "\n",
    "def mouse_case(name: str) -> str:\n",
    "    \"\"\"Convert gene name to mouse-style casing (first letter upper, rest lower).\"\"\"\n",
    "    if not name:\n",
    "        return name\n",
    "    return name[0].upper() + name[1:].lower()\n",
    "\n",
    "\n",
    "def make_unique(names: list[str]) -> list[str]:\n",
    "    \"\"\"Make names unique by appending _2, _3, ... for duplicates.\"\"\"\n",
    "    seen: dict[str, int] = {}\n",
    "    out: list[str] = []\n",
    "    for n in names:\n",
    "        if n not in seen:\n",
    "            seen[n] = 1\n",
    "            out.append(n)\n",
    "        else:\n",
    "            seen[n] += 1\n",
    "            out.append(f\"{n}_{seen[n]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def ensure_csr(x) -> sp.csr_matrix:\n",
    "    \"\"\"Convert matrix to CSR sparse format if not already.\"\"\"\n",
    "    if sp.isspmatrix_csr(x):\n",
    "        return x\n",
    "    if sp.isspmatrix(x):\n",
    "        return x.tocsr()\n",
    "    return sp.csr_matrix(x)\n",
    "\n",
    "\n",
    "def assert_csr_equal(a: sp.csr_matrix, b: sp.csr_matrix, label: str = \"X\") -> None:\n",
    "    \"\"\"Assert that two CSR matrices are equal.\"\"\"\n",
    "    if not (sp.isspmatrix_csr(a) and sp.isspmatrix_csr(b)):\n",
    "        raise AssertionError(f\"{label}: not CSR on both sides (types: {type(a)} vs {type(b)})\")\n",
    "\n",
    "    if a.shape != b.shape:\n",
    "        raise AssertionError(f\"{label}: shape mismatch {a.shape} vs {b.shape}\")\n",
    "    if a.nnz != b.nnz:\n",
    "        raise AssertionError(f\"{label}: nnz mismatch {a.nnz} vs {b.nnz}\")\n",
    "\n",
    "    if not np.array_equal(a.indptr, b.indptr):\n",
    "        raise AssertionError(f\"{label}: indptr differs\")\n",
    "    if not np.array_equal(a.indices, b.indices):\n",
    "        raise AssertionError(f\"{label}: indices differ\")\n",
    "\n",
    "    if not np.array_equal(a.data, b.data):\n",
    "        diff = np.max(np.abs(a.data.astype(np.float64) - b.data.astype(np.float64)))\n",
    "        raise AssertionError(f\"{label}: data differs (max abs diff {diff})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load AnnData File (Backed Mode)\n",
    "\n",
    "Load the h5ad file in read-only backed mode to avoid loading full matrices into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load AnnData in backed (read-only) mode\n",
    "# ============================================================\n",
    "\n",
    "if not os.path.exists(INPUT_H5AD):\n",
    "    raise FileNotFoundError(f\"Input file not found: {INPUT_H5AD}\")\n",
    "\n",
    "print(f\"Loading AnnData (backed='r'): {INPUT_H5AD}\")\n",
    "adata = ad.read_h5ad(INPUT_H5AD, backed=\"r\")\n",
    "print(f\"Loaded successfully!\")\n",
    "print(f\"  Shape: {adata.n_obs} cells × {adata.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. AnnData Structure Inspection\n",
    "\n",
    "Comprehensive inspection of the AnnData object structure including all slots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Basic AnnData information\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== BASIC ===\")\n",
    "print(f\"path: {INPUT_H5AD}\")\n",
    "print(f\"AnnData: {adata}\")\n",
    "print(f\"n_obs x n_vars: {adata.n_obs} x {adata.n_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Main Matrix (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Main expression matrix (X)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== X ===\")\n",
    "print(f\"X type: {type(adata.X).__name__}\")\n",
    "print(f\"X shape: {_shape_of(adata.X)}\")\n",
    "print(f\"X dtype: {_dtype_of(adata.X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Observation (Cell) Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Observation (cell) annotations\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== obs (cell annotations) ===\")\n",
    "print(f\"obs shape: {adata.obs.shape} | columns: {len(adata.obs.columns)}\")\n",
    "obs_cols = list(adata.obs.columns)\n",
    "print(f\"obs columns (first 80): {obs_cols[:80]}\" + (\" ...\" if len(obs_cols) > 80 else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Preview obs dataframe\n",
    "# ============================================================\n",
    "\n",
    "print(\"obs head (first 5 rows, first 10 columns):\")\n",
    "display(adata.obs.iloc[:5, :min(10, len(adata.obs.columns))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Variable (Gene) Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Variable (gene) annotations\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== var (gene annotations) ===\")\n",
    "print(f\"var shape: {adata.var.shape} | columns: {len(adata.var.columns)}\")\n",
    "var_cols = list(adata.var.columns)\n",
    "print(f\"var columns (first 80): {var_cols[:80]}\" + (\" ...\" if len(var_cols) > 80 else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Preview var dataframe\n",
    "# ============================================================\n",
    "\n",
    "print(\"var head (first 10 rows):\")\n",
    "display(adata.var.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Multidimensional Observation Annotations (obsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# obsm - embeddings, dimensionality reductions, etc.\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== obsm ===\")\n",
    "if len(adata.obsm.keys()) == 0:\n",
    "    print(\"(none)\")\n",
    "else:\n",
    "    for k in adata.obsm.keys():\n",
    "        v = adata.obsm[k]\n",
    "        print(f\"{k}: type={type(v).__name__} shape={_shape_of(v)} dtype={_dtype_of(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Multidimensional Variable Annotations (varm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# varm - gene-level multidimensional annotations\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== varm ===\")\n",
    "if len(adata.varm.keys()) == 0:\n",
    "    print(\"(none)\")\n",
    "else:\n",
    "    for k in adata.varm.keys():\n",
    "        v = adata.varm[k]\n",
    "        print(f\"{k}: type={type(v).__name__} shape={_shape_of(v)} dtype={_dtype_of(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Layers (Alternative Expression Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# layers - alternative expression matrices (counts, normalized, etc.)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== layers (ALL) ===\")\n",
    "if len(adata.layers.keys()) == 0:\n",
    "    print(\"(none)\")\n",
    "else:\n",
    "    for k in adata.layers.keys():\n",
    "        v = adata.layers[k]\n",
    "        print(f\"{k}: type={type(v).__name__} shape={_shape_of(v)} dtype={_dtype_of(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Pairwise Observation Annotations (obsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# obsp - pairwise cell annotations (e.g., connectivity graphs)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== obsp ===\")\n",
    "if len(adata.obsp.keys()) == 0:\n",
    "    print(\"(none)\")\n",
    "else:\n",
    "    for k in adata.obsp.keys():\n",
    "        v = adata.obsp[k]\n",
    "        print(f\"{k}: type={type(v).__name__} shape={_shape_of(v)} dtype={_dtype_of(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Pairwise Variable Annotations (varp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# varp - pairwise gene annotations\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== varp ===\")\n",
    "if len(adata.varp.keys()) == 0:\n",
    "    print(\"(none)\")\n",
    "else:\n",
    "    for k in adata.varp.keys():\n",
    "        v = adata.varp[k]\n",
    "        print(f\"{k}: type={type(v).__name__} shape={_shape_of(v)} dtype={_dtype_of(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Raw Data Slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# raw - original data before filtering/normalization\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== raw ===\")\n",
    "if adata.raw is None:\n",
    "    print(\"(raw is None)\")\n",
    "else:\n",
    "    print(f\"raw.X type: {type(adata.raw.X).__name__}\")\n",
    "    try:\n",
    "        print(f\"raw shape: {adata.raw.n_obs} x {adata.raw.n_vars}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(f\"raw.var columns (first 80): {list(adata.raw.var.columns)[:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Unstructured Annotations (uns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# uns - unstructured annotations (top-level keys)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== uns (top-level keys) ===\")\n",
    "uns_keys = list(adata.uns.keys())\n",
    "print(f\"uns keys (first 200): {uns_keys[:200]}\" + (\" ...\" if len(uns_keys) > 200 else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# uns - recursive preview of nested structure\n",
    "# ============================================================\n",
    "\n",
    "print(\"=== uns (recursive preview) ===\")\n",
    "_print_uns(adata.uns, indent=0, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Counts Layer Analysis\n",
    "\n",
    "Analyze the counts layer to determine if it contains raw UMI counts or normalized/corrected values.\n",
    "\n",
    "**Interpretation guide:**\n",
    "- **Raw UMI counts**: Almost all values are integers, no negatives, essentially none in (0,1)\n",
    "- **Corrected/normalized**: Many fractional values; often lots in (0,1); sometimes negatives (method-dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Analyze counts layer using h5py for efficient random sampling\n",
    "# ============================================================\n",
    "\n",
    "rng = np.random.default_rng(ANALYSIS_SEED)\n",
    "\n",
    "with h5py.File(INPUT_H5AD, \"r\") as f:\n",
    "    # Check if layer exists\n",
    "    if \"layers\" not in f or COUNTS_LAYER not in f[\"layers\"]:\n",
    "        raise KeyError(f\"Layer '{COUNTS_LAYER}' not found. Available layers: {list(f['layers'].keys()) if 'layers' in f else 'none'}\")\n",
    "    \n",
    "    g = f[\"layers\"][COUNTS_LAYER]\n",
    "    enc = g.attrs.get(\"encoding-type\", None)\n",
    "    shape = g.attrs.get(\"shape\", None)\n",
    "    \n",
    "    print(f\"File: {INPUT_H5AD}\")\n",
    "    print(f\"Layer '{COUNTS_LAYER}' encoding-type: {enc}\")\n",
    "    print(f\"shape (from attrs): {shape}\")\n",
    "    \n",
    "    data = g[\"data\"]\n",
    "    indices = g[\"indices\"]\n",
    "    indptr = g[\"indptr\"]\n",
    "    \n",
    "    nnz = int(data.shape[0])\n",
    "    n_rows = int(shape[0])\n",
    "    n_cols = int(shape[1])\n",
    "    \n",
    "    print(f\"CSR: n_rows={n_rows}  n_cols={n_cols}  nnz={nnz}\")\n",
    "    print(f\"  data dtype={data.dtype}  indices dtype={indices.dtype}  indptr dtype={indptr.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Sample random cells and collect nonzero values\n",
    "# ============================================================\n",
    "\n",
    "with h5py.File(INPUT_H5AD, \"r\") as f:\n",
    "    g = f[\"layers\"][COUNTS_LAYER]\n",
    "    shape = g.attrs.get(\"shape\", None)\n",
    "    data = g[\"data\"]\n",
    "    indptr = g[\"indptr\"]\n",
    "    \n",
    "    n_rows = int(shape[0])\n",
    "    \n",
    "    # Select random subset of cells\n",
    "    n_subset = min(ANALYSIS_N_CELLS, n_rows)\n",
    "    cell_idx = rng.choice(n_rows, size=n_subset, replace=False)\n",
    "    cell_idx.sort()\n",
    "    print(f\"Using random subset of {n_subset} cells for analysis\")\n",
    "    \n",
    "    # Read indptr for selected cells to get data ranges\n",
    "    indptr_starts = np.array([indptr[i] for i in cell_idx], dtype=np.int64)\n",
    "    indptr_ends = np.array([indptr[i + 1] for i in cell_idx], dtype=np.int64)\n",
    "    \n",
    "    # Collect all nonzero values from subset cells\n",
    "    all_values = []\n",
    "    row_sums = np.empty(n_subset, dtype=np.float64)\n",
    "    row_nnz = np.empty(n_subset, dtype=np.int64)\n",
    "    \n",
    "    for i, (start, end) in enumerate(zip(indptr_starts, indptr_ends)):\n",
    "        row_nnz[i] = end - start\n",
    "        if end == start:\n",
    "            row_sums[i] = 0.0\n",
    "        else:\n",
    "            row_data = np.asarray(data[start:end], dtype=np.float64)\n",
    "            all_values.append(row_data)\n",
    "            row_sums[i] = float(row_data.sum())\n",
    "    \n",
    "    all_values = np.concatenate(all_values) if all_values else np.array([], dtype=np.float64)\n",
    "    print(f\"Total nonzero values in subset: {all_values.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Summarize nonzero values from sampled cells\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "summarize_values(all_values, f\"Nonzero values from {n_subset} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Row sparsity statistics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nRow sparsity (subset):\")\n",
    "print(f\"  row nnz: min={row_nnz.min()}  median={np.median(row_nnz):.6g}  max={row_nnz.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Per-cell totals (library size proxy)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "summarize_values(row_sums, f\"Per-cell totals ({n_subset} cells)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Interpretation guide\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HOW TO INTERPRET:\")\n",
    "print(\"  Raw UMI counts: almost all values are integers, no negatives,\")\n",
    "print(\"                  essentially none in (0,1).\")\n",
    "print(\"  Corrected/normalized: many fractional values; often lots in (0,1);\")\n",
    "print(\"                        sometimes negatives (method-dependent).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Export Simplified AnnData for MapMyCells\n",
    "\n",
    "Create a minimal AnnData suitable for MapMyCells or similar tools:\n",
    "- `X` = counts layer (CSR sparse)\n",
    "- `obs` = barcodes only (as obs_names)\n",
    "- `var` = gene names only (stored in `adata.var['gene_name']` and as var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Define output path\n",
    "# ============================================================\n",
    "\n",
    "base, _ = os.path.splitext(INPUT_H5AD)\n",
    "OUTPUT_H5AD = f\"{base}_for_MapMyCells.h5ad\"\n",
    "\n",
    "print(f\"Output will be written to: {OUTPUT_H5AD}\")\n",
    "\n",
    "if os.path.exists(OUTPUT_H5AD) and not OVERWRITE_OUTPUT:\n",
    "    raise FileExistsError(f\"Output exists and OVERWRITE_OUTPUT=False: {OUTPUT_H5AD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Extract barcodes\n",
    "# ============================================================\n",
    "\n",
    "if BARCODE_SOURCE_OBS_COLUMN is None:\n",
    "    barcodes = adata.obs_names.astype(str).to_numpy()\n",
    "    barcode_source = \"obs_names\"\n",
    "else:\n",
    "    if BARCODE_SOURCE_OBS_COLUMN not in adata.obs.columns:\n",
    "        raise KeyError(\n",
    "            f\"BARCODE_SOURCE_OBS_COLUMN='{BARCODE_SOURCE_OBS_COLUMN}' not in adata.obs columns\"\n",
    "        )\n",
    "    barcodes = adata.obs[BARCODE_SOURCE_OBS_COLUMN].astype(str).to_numpy()\n",
    "    barcode_source = f\"obs['{BARCODE_SOURCE_OBS_COLUMN}']\"\n",
    "\n",
    "if len(barcodes) != adata.n_obs:\n",
    "    raise ValueError(f\"Barcode length mismatch: {len(barcodes)} vs n_obs={adata.n_obs}\")\n",
    "\n",
    "print(f\"Barcode source: {barcode_source}\")\n",
    "print(f\"Number of barcodes: {len(barcodes)}\")\n",
    "print(f\"Sample barcodes: {barcodes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Extract and optionally convert gene names\n",
    "# ============================================================\n",
    "\n",
    "genes_orig = adata.var_names.astype(str).to_numpy()\n",
    "genes = genes_orig.copy()\n",
    "\n",
    "if CONVERT_GENE_NAMES_TO_MOUSE_CASE:\n",
    "    if MOUSE_CASE_APPLY_MODE not in {\"all\", \"only_allcaps\"}:\n",
    "        raise ValueError(\"MOUSE_CASE_APPLY_MODE must be 'all' or 'only_allcaps'\")\n",
    "    \n",
    "    print(f\"Converting gene names to mouse case (mode={MOUSE_CASE_APPLY_MODE})...\")\n",
    "    for i, g in enumerate(genes):\n",
    "        if MOUSE_CASE_APPLY_MODE == \"all\":\n",
    "            genes[i] = mouse_case(g)\n",
    "        else:\n",
    "            genes[i] = mouse_case(g) if g.isupper() else g\n",
    "\n",
    "if MAKE_GENE_NAMES_UNIQUE_IF_NEEDED and (len(set(genes.tolist())) != len(genes)):\n",
    "    print(\"WARNING: Gene names are not unique after conversion. Making unique with suffixes _2, _3, ...\")\n",
    "    genes = np.asarray(make_unique(genes.tolist()), dtype=str)\n",
    "\n",
    "print(f\"Number of genes: {len(genes)}\")\n",
    "print(f\"Sample genes: {genes[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load counts layer into memory\n",
    "# ============================================================\n",
    "\n",
    "if COUNTS_LAYER not in adata.layers.keys():\n",
    "    raise KeyError(f\"Layer '{COUNTS_LAYER}' not present. Available layers: {list(adata.layers.keys())}\")\n",
    "\n",
    "print(f\"Loading counts layer '{COUNTS_LAYER}' into memory (sparse CSR expected)...\")\n",
    "counts = ensure_csr(adata.layers[COUNTS_LAYER])\n",
    "\n",
    "if counts.shape != (adata.n_obs, adata.n_vars):\n",
    "    raise ValueError(f\"counts layer shape {counts.shape} != (n_obs,n_vars)=({adata.n_obs},{adata.n_vars})\")\n",
    "\n",
    "print(f\"Counts matrix: {counts.shape}, nnz={counts.nnz}, dtype={counts.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Build minimal AnnData\n",
    "# ============================================================\n",
    "\n",
    "print(\"Building minimal AnnData...\")\n",
    "\n",
    "obs_new = pd.DataFrame(index=pd.Index(barcodes, name=\"barcode\"))\n",
    "var_new = pd.DataFrame(index=pd.Index(genes, name=\"gene\"))\n",
    "var_new[\"gene_name\"] = genes\n",
    "\n",
    "adata_export = ad.AnnData(X=counts, obs=obs_new, var=var_new)\n",
    "\n",
    "print(f\"New AnnData: {adata_export}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Write simplified h5ad\n",
    "# ============================================================\n",
    "\n",
    "if os.path.exists(OUTPUT_H5AD) and OVERWRITE_OUTPUT:\n",
    "    os.remove(OUTPUT_H5AD)\n",
    "\n",
    "print(f\"Writing simplified h5ad: {OUTPUT_H5AD}\")\n",
    "adata_export.write_h5ad(OUTPUT_H5AD, compression=\"gzip\")\n",
    "print(\"Write complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Validate Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Reload and validate output\n",
    "# ============================================================\n",
    "\n",
    "print(\"Reloading output and validating...\")\n",
    "adata_reloaded = ad.read_h5ad(OUTPUT_H5AD)\n",
    "\n",
    "# Validate dimensions\n",
    "if adata_reloaded.n_obs != adata.n_obs or adata_reloaded.n_vars != adata.n_vars:\n",
    "    raise AssertionError(f\"n_obs/n_vars mismatch: ({adata_reloaded.n_obs},{adata_reloaded.n_vars}) vs ({adata.n_obs},{adata.n_vars})\")\n",
    "print(\"✓ Dimensions match\")\n",
    "\n",
    "# Validate barcodes\n",
    "if not np.array_equal(adata_reloaded.obs_names.astype(str).to_numpy(), barcodes.astype(str)):\n",
    "    raise AssertionError(\"Barcode validation failed: output obs_names differ from expected barcodes\")\n",
    "print(\"✓ Barcodes match\")\n",
    "\n",
    "# Validate gene_name column\n",
    "if \"gene_name\" not in adata_reloaded.var.columns:\n",
    "    raise AssertionError(\"Gene validation failed: 'gene_name' column missing in output adata.var\")\n",
    "print(\"✓ gene_name column present\")\n",
    "\n",
    "if not np.array_equal(adata_reloaded.var[\"gene_name\"].astype(str).to_numpy(), genes.astype(str)):\n",
    "    raise AssertionError(\"Gene validation failed: output var['gene_name'] differs from expected\")\n",
    "print(\"✓ Gene names match\")\n",
    "\n",
    "# Validate counts matrix\n",
    "x_out = ensure_csr(adata_reloaded.X)\n",
    "assert_csr_equal(counts, x_out, label=\"counts/X\")\n",
    "print(\"✓ Counts matrix matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Export summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUCCESS ✅\")\n",
    "print(f\"  Barcode source: {barcode_source}\")\n",
    "print(f\"  Input n_obs x n_vars: {adata.n_obs} x {adata.n_vars}\")\n",
    "print(f\"  Output file: {OUTPUT_H5AD}\")\n",
    "print(f\"  Output X: CSR nnz={x_out.nnz}, dtype={x_out.data.dtype}\")\n",
    "print(f\"  Gene conversion: {CONVERT_GENE_NAMES_TO_MOUSE_CASE} (mode={MOUSE_CASE_APPLY_MODE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Preview output var dataframe\n",
    "# ============================================================\n",
    "\n",
    "if PRINT_OUTPUT_VAR:\n",
    "    print(\"\\n=== OUTPUT adata.var INFO ===\")\n",
    "    print(f\"adata_reloaded.var shape: {adata_reloaded.var.shape}\")\n",
    "    print(f\"adata_reloaded.var columns: {list(adata_reloaded.var.columns)}\")\n",
    "    print(f\"\\nHead ({OUTPUT_VAR_N_PREVIEW}):\")\n",
    "    display(adata_reloaded.var.head(OUTPUT_VAR_N_PREVIEW))\n",
    "    \n",
    "    print(\"\\nvar_names preview:\")\n",
    "    print(list(adata_reloaded.var_names[:min(OUTPUT_VAR_N_PREVIEW, adata_reloaded.n_vars)]))\n",
    "    \n",
    "    # Heuristic: count all-caps gene names\n",
    "    vn = adata_reloaded.var_names.astype(str)\n",
    "    allcaps = np.sum([s.isupper() for s in vn[:10000]])\n",
    "    print(f\"\\nHeuristic (first 10k genes): all-caps var_names count = {allcaps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Close backed file handle\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    adata.file.close()\n",
    "    print(\"Backed file handle closed.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"\\nNotebook complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
